{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyNYp4Qic64U"
      },
      "source": [
        "## **Acquire MNIST Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ7X5WAZdC15",
        "outputId": "56fce4c0-1b3f-4b2e-ff41-5f225001c725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
        "\n",
        "# Flatten the images\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "x_train_full = x_train.copy()\n",
        "y_train_full = y_train.copy()\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "sxhhLs-sVkVn",
        "outputId": "ee63a8d5-4768-492b-fd05-3b1651793edc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "(x_train_plt, y_train_plt), _ = mnist.load_data()\n",
        "\n",
        "unique_indices = []\n",
        "for label in range(10):\n",
        "    index = np.where(y_train_plt == label)[0][0]\n",
        "    unique_indices.append(index)\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "for i, index in enumerate(unique_indices):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(x_train_plt[index], cmap='gray')\n",
        "    plt.title(f'Label: {y_train_plt[index]}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8NqKLmDdMgQ"
      },
      "source": [
        "## **Claim 1 (6.1.1): Dropout NN performs better than Standard NN on MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5FJxvet6ZehL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oePcLfeicoHb"
      },
      "source": [
        "### Standard NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA-jCnDsdWWP"
      },
      "outputs": [],
      "source": [
        "# Start building the model\n",
        "standard_model = Sequential()\n",
        "\n",
        "# First hidden layer with sigmoid activation\n",
        "standard_model.add(Dense(800, activation='sigmoid'))\n",
        "\n",
        "# Second hidden layer with sigmoid activation\n",
        "standard_model.add(Dense(800, activation='sigmoid'))\n",
        "\n",
        "# Output layer with softmax activation for classification\n",
        "standard_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "standard_model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUw2H20MdsEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b498fbb-e9a0-4e8e-dde3-704c314a2eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 7s 4ms/step - loss: 0.3960 - accuracy: 0.8808 - val_loss: 0.2112 - val_accuracy: 0.9363\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1712 - accuracy: 0.9485 - val_loss: 0.1502 - val_accuracy: 0.9534\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1095 - accuracy: 0.9661 - val_loss: 0.1227 - val_accuracy: 0.9603\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0793 - accuracy: 0.9753 - val_loss: 0.1105 - val_accuracy: 0.9651\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0563 - accuracy: 0.9821 - val_loss: 0.1020 - val_accuracy: 0.9704\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.0946 - val_accuracy: 0.9723\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 0.0945 - val_accuracy: 0.9747\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.0969 - val_accuracy: 0.9728\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.1015 - val_accuracy: 0.9753\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.1154 - val_accuracy: 0.9749\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.1494 - val_accuracy: 0.9688\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1217 - val_accuracy: 0.9750\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.1264 - val_accuracy: 0.9750\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.1342 - val_accuracy: 0.9732\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1185 - val_accuracy: 0.9777\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1186 - val_accuracy: 0.9775\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1349 - val_accuracy: 0.9753\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1289 - val_accuracy: 0.9772\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1334 - val_accuracy: 0.9769\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1434 - val_accuracy: 0.9752\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1215 - val_accuracy: 0.9790\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1243 - val_accuracy: 0.9810\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.1503 - val_accuracy: 0.9776\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1470 - val_accuracy: 0.9768\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1241 - val_accuracy: 0.9792\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1479 - val_accuracy: 0.9762\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1234 - val_accuracy: 0.9801\n",
            "Epoch 28/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.1334 - val_accuracy: 0.9798\n",
            "Epoch 29/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1269 - val_accuracy: 0.9795\n",
            "Epoch 30/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1512 - val_accuracy: 0.9767\n",
            "Epoch 31/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1391 - val_accuracy: 0.9781\n",
            "Epoch 32/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.1295 - val_accuracy: 0.9782\n",
            "Epoch 33/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 7.5223e-04 - accuracy: 0.9998 - val_loss: 0.1348 - val_accuracy: 0.9807\n",
            "Epoch 34/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.1590 - val_accuracy: 0.9783\n",
            "Epoch 35/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.1200 - val_accuracy: 0.9809\n",
            "Epoch 36/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 8.7946e-04 - accuracy: 0.9997 - val_loss: 0.1298 - val_accuracy: 0.9802\n",
            "Epoch 37/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1364 - val_accuracy: 0.9802\n",
            "Epoch 38/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1397 - val_accuracy: 0.9786\n",
            "Epoch 39/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1437 - val_accuracy: 0.9807\n",
            "Epoch 40/100\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 8.1048e-04 - accuracy: 0.9997 - val_loss: 0.1519 - val_accuracy: 0.9784\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1391 - val_accuracy: 0.9798\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1475 - val_accuracy: 0.9803\n",
            "Epoch 43/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1864 - val_accuracy: 0.9756\n",
            "Epoch 44/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1608 - val_accuracy: 0.9789\n",
            "Epoch 45/100\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1817 - val_accuracy: 0.9760\n",
            "Epoch 46/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1768 - val_accuracy: 0.9786\n",
            "Epoch 47/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1526 - val_accuracy: 0.9800\n",
            "Epoch 48/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.1478 - val_accuracy: 0.9822\n",
            "Epoch 49/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 6.9626e-04 - accuracy: 0.9998 - val_loss: 0.2338 - val_accuracy: 0.9749\n",
            "Epoch 50/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1600 - val_accuracy: 0.9796\n",
            "Epoch 51/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1723 - val_accuracy: 0.9794\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1671 - val_accuracy: 0.9787\n",
            "Epoch 53/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1775 - val_accuracy: 0.9786\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1892 - val_accuracy: 0.9772\n",
            "Epoch 55/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1801 - val_accuracy: 0.9793\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1827 - val_accuracy: 0.9805\n",
            "Epoch 57/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1743 - val_accuracy: 0.9809\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1864 - val_accuracy: 0.9776\n",
            "Epoch 59/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1833 - val_accuracy: 0.9795\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 5.5821e-04 - accuracy: 0.9999 - val_loss: 0.1688 - val_accuracy: 0.9802\n",
            "Epoch 61/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.2170 - val_accuracy: 0.9765\n",
            "Epoch 62/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1790 - val_accuracy: 0.9802\n",
            "Epoch 63/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1580 - val_accuracy: 0.9799\n",
            "Epoch 64/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.9691e-05 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9811\n",
            "Epoch 65/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.3626e-06 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9817\n",
            "Epoch 66/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.0875e-06 - accuracy: 1.0000 - val_loss: 0.1456 - val_accuracy: 0.9819\n",
            "Epoch 67/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 7.7213e-07 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9818\n",
            "Epoch 68/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 5.3657e-07 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9818\n",
            "Epoch 69/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 3.6103e-07 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9818\n",
            "Epoch 70/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.4308e-07 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9817\n",
            "Epoch 71/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6147e-07 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9819\n",
            "Epoch 72/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0743e-07 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9821\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 7.1105e-08 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9823\n",
            "Epoch 74/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 4.8152e-08 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9822\n",
            "Epoch 75/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 3.3459e-08 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9825\n",
            "Epoch 76/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3767e-08 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9825\n",
            "Epoch 77/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7357e-08 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9825\n",
            "Epoch 78/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3217e-08 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9825\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.0404e-08 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9827\n",
            "Epoch 80/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 8.4072e-09 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9826\n",
            "Epoch 81/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 7.0125e-09 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9826\n",
            "Epoch 82/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9825\n",
            "Epoch 83/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 5.2273e-09 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9826\n",
            "Epoch 84/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 4.6223e-09 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9825\n",
            "Epoch 85/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 4.1217e-09 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9825\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 3.7134e-09 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9825\n",
            "Epoch 87/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 3.3945e-09 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9824\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 3.1173e-09 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9824\n",
            "Epoch 89/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.8670e-09 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9824\n",
            "Epoch 90/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.6673e-09 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9824\n",
            "Epoch 91/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.4974e-09 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9824\n",
            "Epoch 92/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.3514e-09 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9824\n",
            "Epoch 93/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.1964e-09 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9825\n",
            "Epoch 94/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 2.0742e-09 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9825\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.9968e-09 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9825\n",
            "Epoch 96/100\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.8716e-09 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9825\n",
            "Epoch 97/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9825\n",
            "Epoch 98/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7017e-09 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9825\n",
            "Epoch 99/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6212e-09 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9825\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5527e-09 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79d512cd8580>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "standard_model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM4jMl_eeGBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8f773a-10e3-47eb-eb19-05df5f3cfe16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1824 - accuracy: 0.9829\n",
            "Test Accuracy for Standard NN: 98.29%\n",
            "Error Percentage for Standard NN: 1.71%\n"
          ]
        }
      ],
      "source": [
        "_, test_accuracy_standard = standard_model.evaluate(x_test, y_test)\n",
        "error_percentage_standard = round((1 - test_accuracy_standard) * 100, 2)\n",
        "\n",
        "print(f\"Test Accuracy for Standard NN: {test_accuracy_standard * 100:.2f}%\")\n",
        "print(f\"Error Percentage for Standard NN: {error_percentage_standard}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdPg4MYPr2LH"
      },
      "source": [
        "### Dropout NN with Logistic Unit Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72fOR8hlruqU"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "dropout_model = Sequential()\n",
        "\n",
        "# Apply dropout to the input with p = 0.8 (keeping 20% of the inputs)\n",
        "dropout_model.add(Dropout(0.2, input_shape=(784,)))\n",
        "\n",
        "# First hidden layer\n",
        "dropout_model.add(Dense(1024, activation='sigmoid'))\n",
        "dropout_model.add(Dropout(0.5))\n",
        "\n",
        "# Second hidden layer\n",
        "dropout_model.add(Dense(1024, activation='sigmoid'))\n",
        "dropout_model.add(Dropout(0.5))\n",
        "\n",
        "# Third hidden layer\n",
        "dropout_model.add(Dense(1024, activation='sigmoid'))\n",
        "dropout_model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "dropout_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "dropout_model.compile(optimizer = 'adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBNwvrbYruqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404f854d-b44f-4e61-9422-52eb2c79d13a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 7s 4ms/step - loss: 0.6279 - accuracy: 0.7921 - val_loss: 0.2551 - val_accuracy: 0.9187\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2731 - accuracy: 0.9155 - val_loss: 0.1706 - val_accuracy: 0.9467\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2118 - accuracy: 0.9349 - val_loss: 0.1359 - val_accuracy: 0.9556\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1794 - accuracy: 0.9456 - val_loss: 0.1275 - val_accuracy: 0.9616\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.1545 - accuracy: 0.9520 - val_loss: 0.1096 - val_accuracy: 0.9639\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1400 - accuracy: 0.9561 - val_loss: 0.0991 - val_accuracy: 0.9695\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1242 - accuracy: 0.9620 - val_loss: 0.0915 - val_accuracy: 0.9724\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.1161 - accuracy: 0.9643 - val_loss: 0.0883 - val_accuracy: 0.9734\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1017 - accuracy: 0.9679 - val_loss: 0.0957 - val_accuracy: 0.9724\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1001 - accuracy: 0.9691 - val_loss: 0.0847 - val_accuracy: 0.9750\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0952 - accuracy: 0.9706 - val_loss: 0.0868 - val_accuracy: 0.9759\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0846 - accuracy: 0.9733 - val_loss: 0.0768 - val_accuracy: 0.9778\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0823 - accuracy: 0.9747 - val_loss: 0.0908 - val_accuracy: 0.9753\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0777 - accuracy: 0.9757 - val_loss: 0.0743 - val_accuracy: 0.9788\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0756 - accuracy: 0.9768 - val_loss: 0.0707 - val_accuracy: 0.9800\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0691 - accuracy: 0.9782 - val_loss: 0.0784 - val_accuracy: 0.9803\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0690 - accuracy: 0.9783 - val_loss: 0.0755 - val_accuracy: 0.9809\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0682 - accuracy: 0.9792 - val_loss: 0.0722 - val_accuracy: 0.9817\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0664 - accuracy: 0.9796 - val_loss: 0.0728 - val_accuracy: 0.9799\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0649 - accuracy: 0.9794 - val_loss: 0.0698 - val_accuracy: 0.9803\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0633 - accuracy: 0.9806 - val_loss: 0.0760 - val_accuracy: 0.9799\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0590 - accuracy: 0.9818 - val_loss: 0.0734 - val_accuracy: 0.9815\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0525 - accuracy: 0.9829 - val_loss: 0.0715 - val_accuracy: 0.9817\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0584 - accuracy: 0.9826 - val_loss: 0.0746 - val_accuracy: 0.9812\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0561 - accuracy: 0.9828 - val_loss: 0.0784 - val_accuracy: 0.9810\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0512 - accuracy: 0.9834 - val_loss: 0.0793 - val_accuracy: 0.9820\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0546 - accuracy: 0.9833 - val_loss: 0.0753 - val_accuracy: 0.9816\n",
            "Epoch 28/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0528 - accuracy: 0.9835 - val_loss: 0.0726 - val_accuracy: 0.9829\n",
            "Epoch 29/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0487 - accuracy: 0.9848 - val_loss: 0.0753 - val_accuracy: 0.9822\n",
            "Epoch 30/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.0718 - val_accuracy: 0.9806\n",
            "Epoch 31/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0478 - accuracy: 0.9852 - val_loss: 0.0916 - val_accuracy: 0.9790\n",
            "Epoch 32/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0481 - accuracy: 0.9850 - val_loss: 0.0766 - val_accuracy: 0.9832\n",
            "Epoch 33/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.0810 - val_accuracy: 0.9826\n",
            "Epoch 34/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 0.0818 - val_accuracy: 0.9816\n",
            "Epoch 35/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.0805 - val_accuracy: 0.9824\n",
            "Epoch 36/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0441 - accuracy: 0.9858 - val_loss: 0.0811 - val_accuracy: 0.9824\n",
            "Epoch 37/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0417 - accuracy: 0.9872 - val_loss: 0.0748 - val_accuracy: 0.9833\n",
            "Epoch 38/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.0881 - val_accuracy: 0.9801\n",
            "Epoch 39/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.0980 - val_accuracy: 0.9794\n",
            "Epoch 40/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.0870 - val_accuracy: 0.9819\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0404 - accuracy: 0.9877 - val_loss: 0.0874 - val_accuracy: 0.9826\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0400 - accuracy: 0.9882 - val_loss: 0.0844 - val_accuracy: 0.9816\n",
            "Epoch 43/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0390 - accuracy: 0.9883 - val_loss: 0.0932 - val_accuracy: 0.9820\n",
            "Epoch 44/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0419 - accuracy: 0.9873 - val_loss: 0.0815 - val_accuracy: 0.9829\n",
            "Epoch 45/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0410 - accuracy: 0.9876 - val_loss: 0.0764 - val_accuracy: 0.9842\n",
            "Epoch 46/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0401 - accuracy: 0.9882 - val_loss: 0.0824 - val_accuracy: 0.9837\n",
            "Epoch 47/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0378 - accuracy: 0.9893 - val_loss: 0.0773 - val_accuracy: 0.9845\n",
            "Epoch 48/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0890 - val_accuracy: 0.9814\n",
            "Epoch 49/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0390 - accuracy: 0.9889 - val_loss: 0.0749 - val_accuracy: 0.9848\n",
            "Epoch 50/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0365 - accuracy: 0.9894 - val_loss: 0.0851 - val_accuracy: 0.9822\n",
            "Epoch 51/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0398 - accuracy: 0.9883 - val_loss: 0.0926 - val_accuracy: 0.9806\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.0788 - val_accuracy: 0.9832\n",
            "Epoch 53/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0362 - accuracy: 0.9891 - val_loss: 0.0922 - val_accuracy: 0.9820\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0369 - accuracy: 0.9891 - val_loss: 0.0858 - val_accuracy: 0.9833\n",
            "Epoch 55/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.0862 - val_accuracy: 0.9830\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.0816 - val_accuracy: 0.9840\n",
            "Epoch 57/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0363 - accuracy: 0.9897 - val_loss: 0.0912 - val_accuracy: 0.9831\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.0968 - val_accuracy: 0.9821\n",
            "Epoch 59/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.0864 - val_accuracy: 0.9841\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0319 - accuracy: 0.9901 - val_loss: 0.0874 - val_accuracy: 0.9848\n",
            "Epoch 61/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0366 - accuracy: 0.9892 - val_loss: 0.0862 - val_accuracy: 0.9834\n",
            "Epoch 62/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0347 - accuracy: 0.9901 - val_loss: 0.0898 - val_accuracy: 0.9841\n",
            "Epoch 63/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0330 - accuracy: 0.9902 - val_loss: 0.0847 - val_accuracy: 0.9837\n",
            "Epoch 64/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 0.0921 - val_accuracy: 0.9831\n",
            "Epoch 65/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 0.0866 - val_accuracy: 0.9841\n",
            "Epoch 66/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0319 - accuracy: 0.9904 - val_loss: 0.0994 - val_accuracy: 0.9837\n",
            "Epoch 67/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0355 - accuracy: 0.9901 - val_loss: 0.0867 - val_accuracy: 0.9844\n",
            "Epoch 68/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.0980 - val_accuracy: 0.9843\n",
            "Epoch 69/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0350 - accuracy: 0.9900 - val_loss: 0.0975 - val_accuracy: 0.9829\n",
            "Epoch 70/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.0909 - val_accuracy: 0.9844\n",
            "Epoch 71/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.0994 - val_accuracy: 0.9832\n",
            "Epoch 72/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0343 - accuracy: 0.9903 - val_loss: 0.0939 - val_accuracy: 0.9828\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.0914 - val_accuracy: 0.9839\n",
            "Epoch 74/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.0919 - val_accuracy: 0.9844\n",
            "Epoch 75/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.0892 - val_accuracy: 0.9842\n",
            "Epoch 76/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0299 - accuracy: 0.9914 - val_loss: 0.0967 - val_accuracy: 0.9826\n",
            "Epoch 77/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0350 - accuracy: 0.9901 - val_loss: 0.0932 - val_accuracy: 0.9826\n",
            "Epoch 78/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 0.0898 - val_accuracy: 0.9845\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.0994 - val_accuracy: 0.9828\n",
            "Epoch 80/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0290 - accuracy: 0.9917 - val_loss: 0.0908 - val_accuracy: 0.9838\n",
            "Epoch 81/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.0886 - val_accuracy: 0.9849\n",
            "Epoch 82/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0335 - accuracy: 0.9905 - val_loss: 0.0925 - val_accuracy: 0.9832\n",
            "Epoch 83/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0891 - val_accuracy: 0.9842\n",
            "Epoch 84/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.1003 - val_accuracy: 0.9822\n",
            "Epoch 85/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 0.0989 - val_accuracy: 0.9839\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 0.0920 - val_accuracy: 0.9840\n",
            "Epoch 87/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.0960 - val_accuracy: 0.9844\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.1024 - val_accuracy: 0.9827\n",
            "Epoch 89/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0307 - accuracy: 0.9919 - val_loss: 0.1040 - val_accuracy: 0.9838\n",
            "Epoch 90/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.1001 - val_accuracy: 0.9845\n",
            "Epoch 91/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0316 - accuracy: 0.9916 - val_loss: 0.1008 - val_accuracy: 0.9828\n",
            "Epoch 92/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.0997 - val_accuracy: 0.9846\n",
            "Epoch 93/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0289 - accuracy: 0.9919 - val_loss: 0.0997 - val_accuracy: 0.9849\n",
            "Epoch 94/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.0988 - val_accuracy: 0.9843\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0302 - accuracy: 0.9914 - val_loss: 0.0944 - val_accuracy: 0.9831\n",
            "Epoch 96/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.1015 - val_accuracy: 0.9834\n",
            "Epoch 97/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 0.1037 - val_accuracy: 0.9840\n",
            "Epoch 98/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.1013 - val_accuracy: 0.9837\n",
            "Epoch 99/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.0998 - val_accuracy: 0.9851\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0293 - accuracy: 0.9914 - val_loss: 0.1011 - val_accuracy: 0.9850\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79d512c57340>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dropout_model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guvQhmkpruqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0900260f-dc62-4a62-e286-53196b1ef298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9838\n",
            "Test Accuracy: 0.9837999939918518\n",
            "Error Percentage: 1.62%\n"
          ]
        }
      ],
      "source": [
        "_, test_accuracy_dropout_log = dropout_model.evaluate(x_test, y_test)\n",
        "error_percentage_dropout_log = round((1 - test_accuracy_dropout_log) * 100, 2)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy_dropout_log}\")\n",
        "print(f\"Error Percentage: {error_percentage_dropout_log}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout NN with ReLU Unit Type"
      ],
      "metadata": {
        "id": "7HHzwai03lNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "def get_sgd_optimizer():\n",
        "  \"\"\"\n",
        "  This function returns the SGD optimizer used in the Dropout paper\n",
        "  for the neural net tested on the MNIST dataset using the ReLU\n",
        "  activation function.\n",
        "  \"\"\"\n",
        "  lr_schedule = ExponentialDecay(\n",
        "      initial_learning_rate=0.1,\n",
        "      decay_steps=100000,\n",
        "      decay_rate=0.5,\n",
        "      staircase=False\n",
        "  )\n",
        "\n",
        "  optimizer = SGD(\n",
        "      learning_rate=lr_schedule,\n",
        "      momentum=0.5\n",
        "  )\n",
        "\n",
        "  return optimizer"
      ],
      "metadata": {
        "id": "dGyLKHULJY9c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHJmHar8t1aB"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Get SGD optimizer for ReLU used in the paper\n",
        "sgd_optimizer = get_sgd_optimizer()\n",
        "\n",
        "dropout_model = Sequential()\n",
        "\n",
        "# Apply dropout to the input with p = 0.8 (keeping 20% of the inputs)\n",
        "dropout_model.add(Dropout(0.2, input_shape=(784,)))\n",
        "\n",
        "# First hidden layer\n",
        "dropout_model.add(Dense(1024, activation='relu'))\n",
        "dropout_model.add(Dropout(0.5))\n",
        "\n",
        "# Second hidden layer\n",
        "dropout_model.add(Dense(1024, activation='relu'))\n",
        "dropout_model.add(Dropout(0.5))\n",
        "\n",
        "# Third hidden layer\n",
        "dropout_model.add(Dense(1024, activation='relu'))\n",
        "dropout_model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "dropout_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "dropout_model.compile(optimizer=sgd_optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xiN_2F-YKMH6",
        "outputId": "bfb94540-858f-4432-ff2e-5eb227cfb542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 6s 117ms/step - loss: 2.3919 - accuracy: 0.1250 - val_loss: 2.4345 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.1373 - accuracy: 0.2500 - val_loss: 2.1965 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.0334 - accuracy: 0.2875 - val_loss: 2.2558 - val_accuracy: 0.2000\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.9480 - accuracy: 0.3250 - val_loss: 2.1276 - val_accuracy: 0.2000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.6165 - accuracy: 0.5000 - val_loss: 1.4566 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1791 - accuracy: 0.6625 - val_loss: 1.4554 - val_accuracy: 0.5500\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.9973 - accuracy: 0.7125 - val_loss: 1.1955 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.7088 - accuracy: 0.8500 - val_loss: 1.2120 - val_accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6606 - accuracy: 0.7875 - val_loss: 1.0604 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4499 - accuracy: 0.8625 - val_loss: 2.8734 - val_accuracy: 0.2000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4179 - accuracy: 0.6125 - val_loss: 1.1395 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.7391 - accuracy: 0.7875 - val_loss: 0.8030 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3231 - accuracy: 0.9250 - val_loss: 1.1009 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3252 - accuracy: 0.8750 - val_loss: 1.1415 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2829 - accuracy: 0.9750 - val_loss: 0.9383 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1278 - accuracy: 0.9875 - val_loss: 0.9477 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1512 - accuracy: 0.9625 - val_loss: 1.0575 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0723 - accuracy: 0.9875 - val_loss: 0.9833 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0598 - accuracy: 0.9875 - val_loss: 1.2585 - val_accuracy: 0.6500\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0598 - accuracy: 0.9875 - val_loss: 1.3084 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0991 - accuracy: 0.9500 - val_loss: 1.0658 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1486 - accuracy: 0.9625 - val_loss: 1.3179 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0795 - accuracy: 0.9750 - val_loss: 0.9976 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1396 - accuracy: 0.9750 - val_loss: 0.9342 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1131 - accuracy: 0.9500 - val_loss: 1.1996 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1134 - accuracy: 0.9625 - val_loss: 1.0185 - val_accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1112 - accuracy: 0.9875 - val_loss: 1.2857 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0773 - accuracy: 0.9750 - val_loss: 1.0746 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0298 - accuracy: 0.9875 - val_loss: 1.0216 - val_accuracy: 0.8000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0603 - accuracy: 0.9750 - val_loss: 1.1367 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0492 - accuracy: 0.9750 - val_loss: 1.1745 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0933 - accuracy: 0.9750 - val_loss: 1.3042 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 1.0555 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.0659 - val_accuracy: 0.8000\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.1798 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.2515 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0529 - accuracy: 0.9750 - val_loss: 1.4687 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 1.4505 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0764 - accuracy: 0.9750 - val_loss: 1.1788 - val_accuracy: 0.8000\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0702 - accuracy: 0.9625 - val_loss: 1.1873 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2055 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.1197 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0490 - accuracy: 0.9875 - val_loss: 1.0916 - val_accuracy: 0.8500\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.1398 - val_accuracy: 0.8500\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.0651 - val_accuracy: 0.8500\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.0620 - val_accuracy: 0.8000\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.0846 - val_accuracy: 0.8000\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.1108 - val_accuracy: 0.8000\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0357 - accuracy: 0.9875 - val_loss: 1.2268 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.0617 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0014 - val_accuracy: 0.8000\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.0412 - val_accuracy: 0.8000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1355 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1207 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.0639 - val_accuracy: 0.8000\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0696 - accuracy: 0.9875 - val_loss: 1.4516 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 1.1671 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.2105 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2952 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2866 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3010 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3086 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3388 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3005 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0834 - val_accuracy: 0.8500\n",
            "Epoch 70/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3d141f5bddc8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdropout_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1830\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m                         )\n\u001b[0;32m-> 1832\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1833\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_tune_steps_per_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m             for (\n\u001b[0m\u001b[1;32m   2262\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m             \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    742\u001b[0m             self._flat_output_types)\n\u001b[1;32m    743\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3418\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3420\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3421\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3422\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_a3Oznrt9Ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3134a385-0474-4c94-9731-771cb7882503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3015 - accuracy: 0.0990\n",
            "Test Accuracy: 0.0989999994635582\n",
            "Error Percentage: 90.1%\n"
          ]
        }
      ],
      "source": [
        "_, test_accuracy_dropout_relu = dropout_model.evaluate(x_test, y_test)\n",
        "error_percentage_dropout_relu = round((1 - test_accuracy_dropout_relu) * 100, 2)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy_dropout_relu}\")\n",
        "print(f\"Error Percentage: {error_percentage_dropout_relu}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCJR29l_spDH"
      },
      "source": [
        "### Compare Standard NN and Dropout NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIegbJmRuHf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "52bdf933-f032-4fe0-bc84-e4c808aa5b84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Results from the paper\n",
        "error_percentage_standard_paper = 1.60\n",
        "error_percentage_dropout_log_paper = 1.35\n",
        "error_percentage_dropout_relu_paper = 1.25\n",
        "\n",
        "data = {\n",
        "    'Model': ['Standard NN', 'Dropout NN (Logistic)', 'Dropout NN (ReLU)'],\n",
        "    'Our Results (%)': [error_percentage_standard, error_percentage_dropout_log, error_percentage_dropout_relu],\n",
        "    'Paper Results (%)': [error_percentage_standard_paper, error_percentage_dropout_log_paper, error_percentage_dropout_relu_paper]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 2))\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "ax.table(cellText=df.values, colLabels=df.columns, cellLoc = 'center', loc='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Claim 2 (6.5): After training Neurel nets with different regularization techniques on the MNIST dataset, dropout combined with max-norm regularization gives the lowest generalization error**"
      ],
      "metadata": {
        "id": "53lhXiv61DzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
      ],
      "metadata": {
        "id": "yMARJx4C15LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(regularization=None):\n",
        "\n",
        "    \"\"\"\n",
        "    This function builds the network architecture (784-1024-1024-2048-10)\n",
        "    model given the regularizatio method.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    if 'dropout' in regularization:\n",
        "        model.add(Dropout(0.2, input_shape=(784,)))\n",
        "\n",
        "    model.add(Dense(1024, input_shape=(784,), activation='relu',\n",
        "                    kernel_constraint=MaxNorm(3.5) if 'maxnorm' in regularization else None,\n",
        "                    kernel_regularizer=l2(0.001) if 'l2' in regularization else None))\n",
        "\n",
        "    if 'dropout' in regularization:\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(1024, activation='relu',\n",
        "                    kernel_constraint=MaxNorm(3.5) if 'maxnorm' in regularization else None,\n",
        "                    kernel_regularizer=l2(0.001) if 'l2' in regularization else None))\n",
        "\n",
        "    if 'dropout' in regularization:\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(2048, activation='relu',\n",
        "                    kernel_constraint=MaxNorm(5) if 'maxnorm' in regularization else None,\n",
        "                    kernel_regularizer=l2(0.001) if 'l2' in regularization else None))\n",
        "\n",
        "    if 'dropout' in regularization:\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "5za51CJb9jUy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regularizations = ['l2', 'maxnorm', 'dropout_l2', 'dropout_maxnorm']\n",
        "error_percentages = {}\n",
        "\n",
        "for reg in regularizations:\n",
        "\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    model = build_model(regularization=reg)\n",
        "\n",
        "    sgd_optimizer = get_sgd_optimizer()\n",
        "\n",
        "    model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "    # Evaluate the model\n",
        "    _, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "    error_percentages[reg] = (1 - test_accuracy) * 100\n",
        "    print(f\"{reg}: Test Error Percentage = {error_percentages[reg]:.2f}%\")"
      ],
      "metadata": {
        "id": "K_12zKxu_j-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698f5c47-fb60-4968-cec7-9b10bf5c875b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 2.4174 - accuracy: 0.9176 - val_loss: 1.4535 - val_accuracy: 0.9584\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.0181 - accuracy: 0.9583 - val_loss: 0.6936 - val_accuracy: 0.9631\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5233 - accuracy: 0.9657 - val_loss: 0.4266 - val_accuracy: 0.9579\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3361 - accuracy: 0.9692 - val_loss: 0.3086 - val_accuracy: 0.9641\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2686 - accuracy: 0.9677 - val_loss: 0.2643 - val_accuracy: 0.9665\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2374 - accuracy: 0.9708 - val_loss: 0.2400 - val_accuracy: 0.9671\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2244 - accuracy: 0.9718 - val_loss: 0.2356 - val_accuracy: 0.9687\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2183 - accuracy: 0.9718 - val_loss: 0.2358 - val_accuracy: 0.9680\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2167 - accuracy: 0.9718 - val_loss: 0.2327 - val_accuracy: 0.9682\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2184 - accuracy: 0.9721 - val_loss: 0.2520 - val_accuracy: 0.9591\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2131 - accuracy: 0.9734 - val_loss: 0.2237 - val_accuracy: 0.9703\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2121 - accuracy: 0.9729 - val_loss: 0.2254 - val_accuracy: 0.9713\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2111 - accuracy: 0.9735 - val_loss: 0.2532 - val_accuracy: 0.9637\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2089 - accuracy: 0.9743 - val_loss: 0.2181 - val_accuracy: 0.9728\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2068 - accuracy: 0.9744 - val_loss: 0.2082 - val_accuracy: 0.9754\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2074 - accuracy: 0.9746 - val_loss: 0.2493 - val_accuracy: 0.9643\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2088 - accuracy: 0.9743 - val_loss: 0.2295 - val_accuracy: 0.9710\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2052 - accuracy: 0.9739 - val_loss: 0.2071 - val_accuracy: 0.9756\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2014 - accuracy: 0.9756 - val_loss: 0.2537 - val_accuracy: 0.9595\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2051 - accuracy: 0.9745 - val_loss: 0.2562 - val_accuracy: 0.9602\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1991 - accuracy: 0.9750 - val_loss: 0.2155 - val_accuracy: 0.9727\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2033 - accuracy: 0.9747 - val_loss: 0.2251 - val_accuracy: 0.9708\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2015 - accuracy: 0.9754 - val_loss: 0.2332 - val_accuracy: 0.9676\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2023 - accuracy: 0.9750 - val_loss: 0.2233 - val_accuracy: 0.9707\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2001 - accuracy: 0.9752 - val_loss: 0.2476 - val_accuracy: 0.9611\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1976 - accuracy: 0.9760 - val_loss: 0.2278 - val_accuracy: 0.9682\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2001 - accuracy: 0.9743 - val_loss: 0.2395 - val_accuracy: 0.9656\n",
            "Epoch 28/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1985 - accuracy: 0.9761 - val_loss: 0.2423 - val_accuracy: 0.9637\n",
            "Epoch 29/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1956 - accuracy: 0.9763 - val_loss: 0.2361 - val_accuracy: 0.9640\n",
            "Epoch 30/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1974 - accuracy: 0.9759 - val_loss: 0.3422 - val_accuracy: 0.9378\n",
            "Epoch 31/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1908 - accuracy: 0.9778 - val_loss: 0.2047 - val_accuracy: 0.9736\n",
            "Epoch 32/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1852 - accuracy: 0.9790 - val_loss: 0.2021 - val_accuracy: 0.9721\n",
            "Epoch 33/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1879 - accuracy: 0.9773 - val_loss: 0.2362 - val_accuracy: 0.9645\n",
            "Epoch 34/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1895 - accuracy: 0.9782 - val_loss: 0.2205 - val_accuracy: 0.9714\n",
            "Epoch 35/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1912 - accuracy: 0.9768 - val_loss: 0.2287 - val_accuracy: 0.9684\n",
            "Epoch 36/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1851 - accuracy: 0.9785 - val_loss: 0.2151 - val_accuracy: 0.9687\n",
            "Epoch 37/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1844 - accuracy: 0.9782 - val_loss: 0.2157 - val_accuracy: 0.9692\n",
            "Epoch 38/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1830 - accuracy: 0.9792 - val_loss: 0.2360 - val_accuracy: 0.9624\n",
            "Epoch 39/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1861 - accuracy: 0.9776 - val_loss: 0.2362 - val_accuracy: 0.9625\n",
            "Epoch 40/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1830 - accuracy: 0.9784 - val_loss: 0.2133 - val_accuracy: 0.9705\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1800 - accuracy: 0.9794 - val_loss: 0.2078 - val_accuracy: 0.9709\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1809 - accuracy: 0.9789 - val_loss: 0.2209 - val_accuracy: 0.9668\n",
            "Epoch 43/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1790 - accuracy: 0.9790 - val_loss: 0.2191 - val_accuracy: 0.9692\n",
            "Epoch 44/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1772 - accuracy: 0.9795 - val_loss: 0.2455 - val_accuracy: 0.9592\n",
            "Epoch 45/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1744 - accuracy: 0.9795 - val_loss: 0.2146 - val_accuracy: 0.9693\n",
            "Epoch 46/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1786 - accuracy: 0.9796 - val_loss: 0.2130 - val_accuracy: 0.9700\n",
            "Epoch 47/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1737 - accuracy: 0.9804 - val_loss: 0.1867 - val_accuracy: 0.9766\n",
            "Epoch 48/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1726 - accuracy: 0.9801 - val_loss: 0.1904 - val_accuracy: 0.9753\n",
            "Epoch 49/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1743 - accuracy: 0.9796 - val_loss: 0.2139 - val_accuracy: 0.9680\n",
            "Epoch 50/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1696 - accuracy: 0.9805 - val_loss: 0.1974 - val_accuracy: 0.9728\n",
            "Epoch 51/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1684 - accuracy: 0.9815 - val_loss: 0.1908 - val_accuracy: 0.9770\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1689 - accuracy: 0.9806 - val_loss: 0.1918 - val_accuracy: 0.9748\n",
            "Epoch 53/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1668 - accuracy: 0.9812 - val_loss: 0.2100 - val_accuracy: 0.9686\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1665 - accuracy: 0.9819 - val_loss: 0.1830 - val_accuracy: 0.9767\n",
            "Epoch 55/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1619 - accuracy: 0.9827 - val_loss: 0.1823 - val_accuracy: 0.9772\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1664 - accuracy: 0.9811 - val_loss: 0.1842 - val_accuracy: 0.9761\n",
            "Epoch 57/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1626 - accuracy: 0.9825 - val_loss: 0.1806 - val_accuracy: 0.9786\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1608 - accuracy: 0.9817 - val_loss: 0.1963 - val_accuracy: 0.9744\n",
            "Epoch 59/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1636 - accuracy: 0.9813 - val_loss: 0.1814 - val_accuracy: 0.9773\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1636 - accuracy: 0.9816 - val_loss: 0.2167 - val_accuracy: 0.9669\n",
            "Epoch 61/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1575 - accuracy: 0.9830 - val_loss: 0.1858 - val_accuracy: 0.9754\n",
            "Epoch 62/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1532 - accuracy: 0.9830 - val_loss: 0.1802 - val_accuracy: 0.9764\n",
            "Epoch 63/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1584 - accuracy: 0.9816 - val_loss: 0.1954 - val_accuracy: 0.9720\n",
            "Epoch 64/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1566 - accuracy: 0.9825 - val_loss: 0.1914 - val_accuracy: 0.9726\n",
            "Epoch 65/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1568 - accuracy: 0.9825 - val_loss: 0.2144 - val_accuracy: 0.9641\n",
            "Epoch 66/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1515 - accuracy: 0.9845 - val_loss: 0.1945 - val_accuracy: 0.9715\n",
            "Epoch 67/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1554 - accuracy: 0.9822 - val_loss: 0.1777 - val_accuracy: 0.9761\n",
            "Epoch 68/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1508 - accuracy: 0.9832 - val_loss: 0.2035 - val_accuracy: 0.9692\n",
            "Epoch 69/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1503 - accuracy: 0.9836 - val_loss: 0.1948 - val_accuracy: 0.9734\n",
            "Epoch 70/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1466 - accuracy: 0.9852 - val_loss: 0.1724 - val_accuracy: 0.9769\n",
            "Epoch 71/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1497 - accuracy: 0.9834 - val_loss: 0.2033 - val_accuracy: 0.9703\n",
            "Epoch 72/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.1466 - accuracy: 0.9847 - val_loss: 0.2007 - val_accuracy: 0.9709\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1439 - accuracy: 0.9853 - val_loss: 0.1941 - val_accuracy: 0.9703\n",
            "Epoch 74/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1447 - accuracy: 0.9849 - val_loss: 0.1753 - val_accuracy: 0.9768\n",
            "Epoch 75/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1444 - accuracy: 0.9841 - val_loss: 0.1937 - val_accuracy: 0.9718\n",
            "Epoch 76/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1413 - accuracy: 0.9859 - val_loss: 0.1991 - val_accuracy: 0.9705\n",
            "Epoch 77/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1450 - accuracy: 0.9843 - val_loss: 0.1847 - val_accuracy: 0.9739\n",
            "Epoch 78/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1427 - accuracy: 0.9851 - val_loss: 0.1965 - val_accuracy: 0.9704\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1394 - accuracy: 0.9856 - val_loss: 0.1716 - val_accuracy: 0.9749\n",
            "Epoch 80/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1383 - accuracy: 0.9859 - val_loss: 0.1733 - val_accuracy: 0.9760\n",
            "Epoch 81/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1351 - accuracy: 0.9874 - val_loss: 0.1630 - val_accuracy: 0.9786\n",
            "Epoch 82/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1343 - accuracy: 0.9862 - val_loss: 0.1748 - val_accuracy: 0.9737\n",
            "Epoch 83/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1352 - accuracy: 0.9860 - val_loss: 0.1731 - val_accuracy: 0.9764\n",
            "Epoch 84/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1345 - accuracy: 0.9858 - val_loss: 0.1672 - val_accuracy: 0.9775\n",
            "Epoch 85/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1381 - accuracy: 0.9854 - val_loss: 0.1693 - val_accuracy: 0.9777\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1338 - accuracy: 0.9863 - val_loss: 0.1770 - val_accuracy: 0.9738\n",
            "Epoch 87/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1326 - accuracy: 0.9866 - val_loss: 0.1772 - val_accuracy: 0.9747\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1299 - accuracy: 0.9873 - val_loss: 0.1682 - val_accuracy: 0.9771\n",
            "Epoch 89/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1328 - accuracy: 0.9861 - val_loss: 0.1691 - val_accuracy: 0.9779\n",
            "Epoch 90/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1276 - accuracy: 0.9880 - val_loss: 0.1601 - val_accuracy: 0.9788\n",
            "Epoch 91/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1293 - accuracy: 0.9869 - val_loss: 0.1702 - val_accuracy: 0.9745\n",
            "Epoch 92/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1239 - accuracy: 0.9887 - val_loss: 0.1866 - val_accuracy: 0.9699\n",
            "Epoch 93/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1280 - accuracy: 0.9874 - val_loss: 0.1633 - val_accuracy: 0.9757\n",
            "Epoch 94/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1247 - accuracy: 0.9880 - val_loss: 0.1595 - val_accuracy: 0.9780\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1245 - accuracy: 0.9879 - val_loss: 0.1490 - val_accuracy: 0.9818\n",
            "Epoch 96/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1261 - accuracy: 0.9873 - val_loss: 0.1839 - val_accuracy: 0.9705\n",
            "Epoch 97/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1216 - accuracy: 0.9888 - val_loss: 0.1696 - val_accuracy: 0.9735\n",
            "Epoch 98/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1192 - accuracy: 0.9887 - val_loss: 0.1714 - val_accuracy: 0.9734\n",
            "Epoch 99/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1234 - accuracy: 0.9875 - val_loss: 0.1683 - val_accuracy: 0.9736\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1191 - accuracy: 0.9892 - val_loss: 0.1582 - val_accuracy: 0.9777\n",
            "l2: Test Error Percentage = 2.23%\n",
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 9s 4ms/step - loss: 0.2555 - accuracy: 0.9204 - val_loss: 0.1223 - val_accuracy: 0.9612\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0983 - accuracy: 0.9692 - val_loss: 0.1010 - val_accuracy: 0.9694\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0595 - accuracy: 0.9807 - val_loss: 0.1885 - val_accuracy: 0.9477\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0410 - accuracy: 0.9869 - val_loss: 0.0843 - val_accuracy: 0.9756\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.1023 - val_accuracy: 0.9743\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0809 - val_accuracy: 0.9795\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0860 - val_accuracy: 0.9787\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.0825 - val_accuracy: 0.9799\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1137 - val_accuracy: 0.9763\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0746 - val_accuracy: 0.9842\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0799 - val_accuracy: 0.9838\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 3.8710e-04 - accuracy: 0.9999 - val_loss: 0.0776 - val_accuracy: 0.9846\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1153e-04 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9842\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 8.5758e-05 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9844\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 7.2228e-05 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9843\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 6.2316e-05 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9843\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 5.5655e-05 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9843\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 5.0218e-05 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9842\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 4.5899e-05 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9843\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 4.2375e-05 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9843\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 3.9388e-05 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9844\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 3.6895e-05 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9844\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 3.4765e-05 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9845\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 3.2841e-05 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9844\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 3.1167e-05 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9844\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.9698e-05 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9843\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.8371e-05 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9844\n",
            "Epoch 28/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 2.7151e-05 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9844\n",
            "Epoch 29/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.6092e-05 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9844\n",
            "Epoch 30/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.5087e-05 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9844\n",
            "Epoch 31/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.4193e-05 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9843\n",
            "Epoch 32/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3381e-05 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9844\n",
            "Epoch 33/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.2614e-05 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9843\n",
            "Epoch 34/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.1903e-05 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9844\n",
            "Epoch 35/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 2.1262e-05 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9843\n",
            "Epoch 36/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0667e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9843\n",
            "Epoch 37/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0102e-05 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9843\n",
            "Epoch 38/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9577e-05 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9843\n",
            "Epoch 39/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9076e-05 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9843\n",
            "Epoch 40/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8628e-05 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9843\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8190e-05 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9844\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7786e-05 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9844\n",
            "Epoch 43/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.7408e-05 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9844\n",
            "Epoch 44/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7031e-05 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9844\n",
            "Epoch 45/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6703e-05 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9844\n",
            "Epoch 46/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6377e-05 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9844\n",
            "Epoch 47/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6069e-05 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9844\n",
            "Epoch 48/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.5780e-05 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9844\n",
            "Epoch 49/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5503e-05 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9844\n",
            "Epoch 50/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.5237e-05 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9844\n",
            "Epoch 51/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4986e-05 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9844\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4750e-05 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9844\n",
            "Epoch 53/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4516e-05 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9846\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4307e-05 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9844\n",
            "Epoch 55/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4089e-05 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9846\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3898e-05 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9845\n",
            "Epoch 57/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3705e-05 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9845\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3520e-05 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9845\n",
            "Epoch 59/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3345e-05 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9845\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3177e-05 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9847\n",
            "Epoch 61/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3018e-05 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9847\n",
            "Epoch 62/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2861e-05 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9847\n",
            "Epoch 63/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2713e-05 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9847\n",
            "Epoch 64/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2568e-05 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9847\n",
            "Epoch 65/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.2430e-05 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9847\n",
            "Epoch 66/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2296e-05 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9847\n",
            "Epoch 67/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2168e-05 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9847\n",
            "Epoch 68/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2045e-05 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9847\n",
            "Epoch 69/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1925e-05 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9847\n",
            "Epoch 70/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1810e-05 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9847\n",
            "Epoch 71/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1698e-05 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9847\n",
            "Epoch 72/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1595e-05 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9847\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1489e-05 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9847\n",
            "Epoch 74/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1389e-05 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9847\n",
            "Epoch 75/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1293e-05 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9847\n",
            "Epoch 76/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1199e-05 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9847\n",
            "Epoch 77/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1108e-05 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9847\n",
            "Epoch 78/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1022e-05 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9847\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.0936e-05 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9847\n",
            "Epoch 80/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.0853e-05 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9847\n",
            "Epoch 81/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0771e-05 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9847\n",
            "Epoch 82/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0697e-05 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9847\n",
            "Epoch 83/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.0623e-05 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9847\n",
            "Epoch 84/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0548e-05 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9847\n",
            "Epoch 85/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.0476e-05 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9847\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0413e-05 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9847\n",
            "Epoch 87/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0346e-05 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9847\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.0283e-05 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9847\n",
            "Epoch 89/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0220e-05 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9847\n",
            "Epoch 90/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0162e-05 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9847\n",
            "Epoch 91/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0102e-05 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9847\n",
            "Epoch 92/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0043e-05 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9847\n",
            "Epoch 93/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 9.9906e-06 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9847\n",
            "Epoch 94/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 9.9371e-06 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9847\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 9.8852e-06 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9847\n",
            "Epoch 96/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 9.8347e-06 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9847\n",
            "Epoch 97/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 9.7878e-06 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9847\n",
            "Epoch 98/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 9.7394e-06 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9847\n",
            "Epoch 99/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 9.6953e-06 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9847\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 9.6510e-06 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9847\n",
            "maxnorm: Test Error Percentage = 1.53%\n",
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 2.7781 - accuracy: 0.8432 - val_loss: 1.6923 - val_accuracy: 0.9447\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3657 - accuracy: 0.9143 - val_loss: 0.9392 - val_accuracy: 0.9533\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8650 - accuracy: 0.9247 - val_loss: 0.6379 - val_accuracy: 0.9581\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6789 - accuracy: 0.9269 - val_loss: 0.5285 - val_accuracy: 0.9597\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5969 - accuracy: 0.9297 - val_loss: 0.4970 - val_accuracy: 0.9568\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5745 - accuracy: 0.9290 - val_loss: 0.4632 - val_accuracy: 0.9622\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5543 - accuracy: 0.9323 - val_loss: 0.4525 - val_accuracy: 0.9643\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5452 - accuracy: 0.9339 - val_loss: 0.4560 - val_accuracy: 0.9591\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.5456 - accuracy: 0.9331 - val_loss: 0.4443 - val_accuracy: 0.9616\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5323 - accuracy: 0.9353 - val_loss: 0.4588 - val_accuracy: 0.9587\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5356 - accuracy: 0.9337 - val_loss: 0.4599 - val_accuracy: 0.9581\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5303 - accuracy: 0.9367 - val_loss: 0.4502 - val_accuracy: 0.9583\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5325 - accuracy: 0.9346 - val_loss: 0.4886 - val_accuracy: 0.9494\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5246 - accuracy: 0.9367 - val_loss: 0.4353 - val_accuracy: 0.9655\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5256 - accuracy: 0.9370 - val_loss: 0.4364 - val_accuracy: 0.9659\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5221 - accuracy: 0.9364 - val_loss: 0.4322 - val_accuracy: 0.9636\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5227 - accuracy: 0.9353 - val_loss: 0.4345 - val_accuracy: 0.9631\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5174 - accuracy: 0.9388 - val_loss: 0.4306 - val_accuracy: 0.9635\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5098 - accuracy: 0.9382 - val_loss: 0.4300 - val_accuracy: 0.9623\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5077 - accuracy: 0.9388 - val_loss: 0.4397 - val_accuracy: 0.9602\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5093 - accuracy: 0.9377 - val_loss: 0.4233 - val_accuracy: 0.9634\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.5040 - accuracy: 0.9384 - val_loss: 0.4528 - val_accuracy: 0.9554\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5024 - accuracy: 0.9391 - val_loss: 0.4328 - val_accuracy: 0.9599\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5021 - accuracy: 0.9394 - val_loss: 0.4303 - val_accuracy: 0.9595\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5023 - accuracy: 0.9381 - val_loss: 0.4108 - val_accuracy: 0.9670\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4959 - accuracy: 0.9392 - val_loss: 0.4348 - val_accuracy: 0.9604\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4956 - accuracy: 0.9410 - val_loss: 0.4046 - val_accuracy: 0.9676\n",
            "Epoch 28/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4958 - accuracy: 0.9389 - val_loss: 0.4399 - val_accuracy: 0.9551\n",
            "Epoch 29/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4940 - accuracy: 0.9395 - val_loss: 0.4286 - val_accuracy: 0.9610\n",
            "Epoch 30/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4917 - accuracy: 0.9398 - val_loss: 0.4239 - val_accuracy: 0.9619\n",
            "Epoch 31/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4908 - accuracy: 0.9407 - val_loss: 0.4030 - val_accuracy: 0.9653\n",
            "Epoch 32/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4823 - accuracy: 0.9416 - val_loss: 0.4182 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4874 - accuracy: 0.9405 - val_loss: 0.4199 - val_accuracy: 0.9601\n",
            "Epoch 34/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4777 - accuracy: 0.9426 - val_loss: 0.4085 - val_accuracy: 0.9654\n",
            "Epoch 35/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4776 - accuracy: 0.9415 - val_loss: 0.4192 - val_accuracy: 0.9596\n",
            "Epoch 36/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4695 - accuracy: 0.9427 - val_loss: 0.3853 - val_accuracy: 0.9691\n",
            "Epoch 37/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4731 - accuracy: 0.9417 - val_loss: 0.3953 - val_accuracy: 0.9674\n",
            "Epoch 38/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4729 - accuracy: 0.9424 - val_loss: 0.3904 - val_accuracy: 0.9678\n",
            "Epoch 39/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4659 - accuracy: 0.9435 - val_loss: 0.3931 - val_accuracy: 0.9671\n",
            "Epoch 40/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4644 - accuracy: 0.9425 - val_loss: 0.4025 - val_accuracy: 0.9634\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4676 - accuracy: 0.9432 - val_loss: 0.4056 - val_accuracy: 0.9591\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4590 - accuracy: 0.9441 - val_loss: 0.3952 - val_accuracy: 0.9615\n",
            "Epoch 43/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4563 - accuracy: 0.9429 - val_loss: 0.3992 - val_accuracy: 0.9637\n",
            "Epoch 44/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4531 - accuracy: 0.9447 - val_loss: 0.4017 - val_accuracy: 0.9620\n",
            "Epoch 45/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4520 - accuracy: 0.9448 - val_loss: 0.3879 - val_accuracy: 0.9643\n",
            "Epoch 46/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4511 - accuracy: 0.9446 - val_loss: 0.3691 - val_accuracy: 0.9699\n",
            "Epoch 47/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4529 - accuracy: 0.9431 - val_loss: 0.3766 - val_accuracy: 0.9674\n",
            "Epoch 48/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4410 - accuracy: 0.9467 - val_loss: 0.3706 - val_accuracy: 0.9674\n",
            "Epoch 49/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4427 - accuracy: 0.9452 - val_loss: 0.4008 - val_accuracy: 0.9564\n",
            "Epoch 50/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4416 - accuracy: 0.9450 - val_loss: 0.3691 - val_accuracy: 0.9671\n",
            "Epoch 51/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4388 - accuracy: 0.9462 - val_loss: 0.3749 - val_accuracy: 0.9633\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.9461 - val_loss: 0.3784 - val_accuracy: 0.9640\n",
            "Epoch 53/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4363 - accuracy: 0.9461 - val_loss: 0.3812 - val_accuracy: 0.9637\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4301 - accuracy: 0.9471 - val_loss: 0.3789 - val_accuracy: 0.9646\n",
            "Epoch 55/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4284 - accuracy: 0.9471 - val_loss: 0.3618 - val_accuracy: 0.9669\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4228 - accuracy: 0.9481 - val_loss: 0.3889 - val_accuracy: 0.9598\n",
            "Epoch 57/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4273 - accuracy: 0.9471 - val_loss: 0.3795 - val_accuracy: 0.9609\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4216 - accuracy: 0.9474 - val_loss: 0.3571 - val_accuracy: 0.9668\n",
            "Epoch 59/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4257 - accuracy: 0.9469 - val_loss: 0.3513 - val_accuracy: 0.9709\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4189 - accuracy: 0.9482 - val_loss: 0.3441 - val_accuracy: 0.9715\n",
            "Epoch 61/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4208 - accuracy: 0.9471 - val_loss: 0.3551 - val_accuracy: 0.9667\n",
            "Epoch 62/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4122 - accuracy: 0.9482 - val_loss: 0.3541 - val_accuracy: 0.9702\n",
            "Epoch 63/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4220 - accuracy: 0.9471 - val_loss: 0.3662 - val_accuracy: 0.9631\n",
            "Epoch 64/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4089 - accuracy: 0.9495 - val_loss: 0.3695 - val_accuracy: 0.9636\n",
            "Epoch 65/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4063 - accuracy: 0.9498 - val_loss: 0.3470 - val_accuracy: 0.9683\n",
            "Epoch 66/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4093 - accuracy: 0.9484 - val_loss: 0.3372 - val_accuracy: 0.9697\n",
            "Epoch 67/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4086 - accuracy: 0.9488 - val_loss: 0.3448 - val_accuracy: 0.9698\n",
            "Epoch 68/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4048 - accuracy: 0.9495 - val_loss: 0.3618 - val_accuracy: 0.9643\n",
            "Epoch 69/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3991 - accuracy: 0.9503 - val_loss: 0.3415 - val_accuracy: 0.9706\n",
            "Epoch 70/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4034 - accuracy: 0.9497 - val_loss: 0.3397 - val_accuracy: 0.9682\n",
            "Epoch 71/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4003 - accuracy: 0.9488 - val_loss: 0.3326 - val_accuracy: 0.9713\n",
            "Epoch 72/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3960 - accuracy: 0.9510 - val_loss: 0.3596 - val_accuracy: 0.9616\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3964 - accuracy: 0.9513 - val_loss: 0.3377 - val_accuracy: 0.9681\n",
            "Epoch 74/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3946 - accuracy: 0.9497 - val_loss: 0.3256 - val_accuracy: 0.9724\n",
            "Epoch 75/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3964 - accuracy: 0.9492 - val_loss: 0.3313 - val_accuracy: 0.9704\n",
            "Epoch 76/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3891 - accuracy: 0.9520 - val_loss: 0.3318 - val_accuracy: 0.9700\n",
            "Epoch 77/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3842 - accuracy: 0.9518 - val_loss: 0.3419 - val_accuracy: 0.9685\n",
            "Epoch 78/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3894 - accuracy: 0.9500 - val_loss: 0.3336 - val_accuracy: 0.9686\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3804 - accuracy: 0.9535 - val_loss: 0.3136 - val_accuracy: 0.9733\n",
            "Epoch 80/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3849 - accuracy: 0.9507 - val_loss: 0.3404 - val_accuracy: 0.9644\n",
            "Epoch 81/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3818 - accuracy: 0.9527 - val_loss: 0.3243 - val_accuracy: 0.9674\n",
            "Epoch 82/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3769 - accuracy: 0.9525 - val_loss: 0.3155 - val_accuracy: 0.9710\n",
            "Epoch 83/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3762 - accuracy: 0.9533 - val_loss: 0.3250 - val_accuracy: 0.9695\n",
            "Epoch 84/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3751 - accuracy: 0.9527 - val_loss: 0.3247 - val_accuracy: 0.9685\n",
            "Epoch 85/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3712 - accuracy: 0.9520 - val_loss: 0.3206 - val_accuracy: 0.9701\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3731 - accuracy: 0.9528 - val_loss: 0.3172 - val_accuracy: 0.9685\n",
            "Epoch 87/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3687 - accuracy: 0.9534 - val_loss: 0.3135 - val_accuracy: 0.9710\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3702 - accuracy: 0.9529 - val_loss: 0.3079 - val_accuracy: 0.9741\n",
            "Epoch 89/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3691 - accuracy: 0.9530 - val_loss: 0.3076 - val_accuracy: 0.9731\n",
            "Epoch 90/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3659 - accuracy: 0.9539 - val_loss: 0.3132 - val_accuracy: 0.9700\n",
            "Epoch 91/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3704 - accuracy: 0.9523 - val_loss: 0.3152 - val_accuracy: 0.9720\n",
            "Epoch 92/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3605 - accuracy: 0.9549 - val_loss: 0.3002 - val_accuracy: 0.9738\n",
            "Epoch 93/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3590 - accuracy: 0.9550 - val_loss: 0.3012 - val_accuracy: 0.9732\n",
            "Epoch 94/100\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3597 - accuracy: 0.9542 - val_loss: 0.3045 - val_accuracy: 0.9715\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3555 - accuracy: 0.9548 - val_loss: 0.2962 - val_accuracy: 0.9730\n",
            "Epoch 96/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3498 - accuracy: 0.9562 - val_loss: 0.2928 - val_accuracy: 0.9737\n",
            "Epoch 97/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3517 - accuracy: 0.9549 - val_loss: 0.2965 - val_accuracy: 0.9719\n",
            "Epoch 98/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3536 - accuracy: 0.9544 - val_loss: 0.3145 - val_accuracy: 0.9664\n",
            "Epoch 99/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3483 - accuracy: 0.9550 - val_loss: 0.2972 - val_accuracy: 0.9731\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3456 - accuracy: 0.9555 - val_loss: 0.2868 - val_accuracy: 0.9761\n",
            "dropout_l2: Test Error Percentage = 2.39%\n",
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4948 - accuracy: 0.8417 - val_loss: 0.1763 - val_accuracy: 0.9483\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2751 - accuracy: 0.9180 - val_loss: 0.1405 - val_accuracy: 0.9599\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2194 - accuracy: 0.9350 - val_loss: 0.1192 - val_accuracy: 0.9631\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1961 - accuracy: 0.9412 - val_loss: 0.1189 - val_accuracy: 0.9643\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1728 - accuracy: 0.9490 - val_loss: 0.0919 - val_accuracy: 0.9719\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1628 - accuracy: 0.9516 - val_loss: 0.0941 - val_accuracy: 0.9728\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1502 - accuracy: 0.9557 - val_loss: 0.0889 - val_accuracy: 0.9723\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1376 - accuracy: 0.9585 - val_loss: 0.0886 - val_accuracy: 0.9742\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1327 - accuracy: 0.9607 - val_loss: 0.0855 - val_accuracy: 0.9755\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1257 - accuracy: 0.9611 - val_loss: 0.0762 - val_accuracy: 0.9772\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1215 - accuracy: 0.9638 - val_loss: 0.0790 - val_accuracy: 0.9767\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1094 - accuracy: 0.9658 - val_loss: 0.0772 - val_accuracy: 0.9759\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1099 - accuracy: 0.9662 - val_loss: 0.0768 - val_accuracy: 0.9769\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1033 - accuracy: 0.9685 - val_loss: 0.0748 - val_accuracy: 0.9781\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0987 - accuracy: 0.9699 - val_loss: 0.0679 - val_accuracy: 0.9787\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0978 - accuracy: 0.9708 - val_loss: 0.0689 - val_accuracy: 0.9797\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0943 - accuracy: 0.9709 - val_loss: 0.0692 - val_accuracy: 0.9794\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0941 - accuracy: 0.9715 - val_loss: 0.0669 - val_accuracy: 0.9800\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0895 - accuracy: 0.9722 - val_loss: 0.0676 - val_accuracy: 0.9792\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0837 - accuracy: 0.9750 - val_loss: 0.0665 - val_accuracy: 0.9806\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0810 - accuracy: 0.9743 - val_loss: 0.0646 - val_accuracy: 0.9795\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0791 - accuracy: 0.9765 - val_loss: 0.0634 - val_accuracy: 0.9807\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0769 - accuracy: 0.9769 - val_loss: 0.0635 - val_accuracy: 0.9806\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0744 - accuracy: 0.9771 - val_loss: 0.0621 - val_accuracy: 0.9817\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0737 - accuracy: 0.9776 - val_loss: 0.0630 - val_accuracy: 0.9816\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0712 - accuracy: 0.9776 - val_loss: 0.0642 - val_accuracy: 0.9817\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0706 - accuracy: 0.9776 - val_loss: 0.0597 - val_accuracy: 0.9821\n",
            "Epoch 28/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.0635 - val_accuracy: 0.9819\n",
            "Epoch 29/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0644 - accuracy: 0.9800 - val_loss: 0.0606 - val_accuracy: 0.9816\n",
            "Epoch 30/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0598 - accuracy: 0.9813 - val_loss: 0.0658 - val_accuracy: 0.9808\n",
            "Epoch 31/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0653 - accuracy: 0.9801 - val_loss: 0.0585 - val_accuracy: 0.9818\n",
            "Epoch 32/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0606 - accuracy: 0.9806 - val_loss: 0.0611 - val_accuracy: 0.9825\n",
            "Epoch 33/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0594 - accuracy: 0.9817 - val_loss: 0.0623 - val_accuracy: 0.9817\n",
            "Epoch 34/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.0616 - val_accuracy: 0.9817\n",
            "Epoch 35/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.0610 - val_accuracy: 0.9808\n",
            "Epoch 36/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0555 - accuracy: 0.9825 - val_loss: 0.0610 - val_accuracy: 0.9812\n",
            "Epoch 37/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0568 - accuracy: 0.9815 - val_loss: 0.0601 - val_accuracy: 0.9826\n",
            "Epoch 38/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0508 - accuracy: 0.9828 - val_loss: 0.0635 - val_accuracy: 0.9809\n",
            "Epoch 39/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0468 - accuracy: 0.9851 - val_loss: 0.0581 - val_accuracy: 0.9839\n",
            "Epoch 40/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 0.0576 - val_accuracy: 0.9831\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.0585 - val_accuracy: 0.9833\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0494 - accuracy: 0.9843 - val_loss: 0.0658 - val_accuracy: 0.9816\n",
            "Epoch 43/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0493 - accuracy: 0.9845 - val_loss: 0.0595 - val_accuracy: 0.9828\n",
            "Epoch 44/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0477 - accuracy: 0.9845 - val_loss: 0.0599 - val_accuracy: 0.9821\n",
            "Epoch 45/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0481 - accuracy: 0.9852 - val_loss: 0.0570 - val_accuracy: 0.9845\n",
            "Epoch 46/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 0.0572 - val_accuracy: 0.9845\n",
            "Epoch 47/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.0564 - val_accuracy: 0.9833\n",
            "Epoch 48/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0443 - accuracy: 0.9862 - val_loss: 0.0588 - val_accuracy: 0.9837\n",
            "Epoch 49/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9833\n",
            "Epoch 50/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0393 - accuracy: 0.9871 - val_loss: 0.0623 - val_accuracy: 0.9831\n",
            "Epoch 51/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0424 - accuracy: 0.9862 - val_loss: 0.0576 - val_accuracy: 0.9844\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.0579 - val_accuracy: 0.9828\n",
            "Epoch 53/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0400 - accuracy: 0.9869 - val_loss: 0.0569 - val_accuracy: 0.9836\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0397 - accuracy: 0.9881 - val_loss: 0.0542 - val_accuracy: 0.9830\n",
            "Epoch 55/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0398 - accuracy: 0.9875 - val_loss: 0.0583 - val_accuracy: 0.9836\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0398 - accuracy: 0.9873 - val_loss: 0.0616 - val_accuracy: 0.9826\n",
            "Epoch 57/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.0573 - val_accuracy: 0.9833\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.0568 - val_accuracy: 0.9844\n",
            "Epoch 59/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 0.0593 - val_accuracy: 0.9832\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0388 - accuracy: 0.9876 - val_loss: 0.0539 - val_accuracy: 0.9840\n",
            "Epoch 61/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.0566 - val_accuracy: 0.9842\n",
            "Epoch 62/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.0547 - val_accuracy: 0.9840\n",
            "Epoch 63/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.0539 - val_accuracy: 0.9838\n",
            "Epoch 64/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 0.0532 - val_accuracy: 0.9852\n",
            "Epoch 65/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 0.0559 - val_accuracy: 0.9831\n",
            "Epoch 66/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0320 - accuracy: 0.9899 - val_loss: 0.0553 - val_accuracy: 0.9831\n",
            "Epoch 67/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.0568 - val_accuracy: 0.9837\n",
            "Epoch 68/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 0.0556 - val_accuracy: 0.9847\n",
            "Epoch 69/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0544 - val_accuracy: 0.9845\n",
            "Epoch 70/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.0519 - val_accuracy: 0.9857\n",
            "Epoch 71/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0561 - val_accuracy: 0.9848\n",
            "Epoch 72/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.0557 - val_accuracy: 0.9842\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0303 - accuracy: 0.9899 - val_loss: 0.0565 - val_accuracy: 0.9845\n",
            "Epoch 74/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.0540 - val_accuracy: 0.9843\n",
            "Epoch 75/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.0561 - val_accuracy: 0.9839\n",
            "Epoch 76/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.0534 - val_accuracy: 0.9855\n",
            "Epoch 77/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0302 - accuracy: 0.9904 - val_loss: 0.0563 - val_accuracy: 0.9845\n",
            "Epoch 78/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.0582 - val_accuracy: 0.9839\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.0554 - val_accuracy: 0.9844\n",
            "Epoch 80/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.0540 - val_accuracy: 0.9843\n",
            "Epoch 81/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
            "Epoch 82/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0525 - val_accuracy: 0.9851\n",
            "Epoch 83/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0567 - val_accuracy: 0.9845\n",
            "Epoch 84/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 0.0528 - val_accuracy: 0.9853\n",
            "Epoch 85/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.0602 - val_accuracy: 0.9851\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 0.0542 - val_accuracy: 0.9853\n",
            "Epoch 87/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.0545 - val_accuracy: 0.9847\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.0546 - val_accuracy: 0.9856\n",
            "Epoch 89/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.0544 - val_accuracy: 0.9855\n",
            "Epoch 90/100\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.0548 - val_accuracy: 0.9861\n",
            "Epoch 91/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0558 - val_accuracy: 0.9862\n",
            "Epoch 92/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0589 - val_accuracy: 0.9844\n",
            "Epoch 93/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.0571 - val_accuracy: 0.9852\n",
            "Epoch 94/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0559 - val_accuracy: 0.9853\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.0530 - val_accuracy: 0.9870\n",
            "Epoch 96/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0540 - val_accuracy: 0.9864\n",
            "Epoch 97/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.0535 - val_accuracy: 0.9855\n",
            "Epoch 98/100\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0558 - val_accuracy: 0.9856\n",
            "Epoch 99/100\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0538 - val_accuracy: 0.9858\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0529 - val_accuracy: 0.9858\n",
            "dropout_maxnorm: Test Error Percentage = 1.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Results in a Table"
      ],
      "metadata": {
        "id": "pglwMy0Il-a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Paper's reported error percentages\n",
        "paper_error_percentages = {\n",
        "    'l2': 1.62,\n",
        "    'maxnorm': 1.35,\n",
        "    'dropout_l2': 1.25,\n",
        "    'dropout_maxnorm': 1.05\n",
        "}\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Method': ['L2', 'Max-norm', 'Dropout + L2', 'Dropout + Max-norm'],\n",
        "    'Our Test Error (%)': [error_percentages['l2'], error_percentages['maxnorm'], error_percentages['dropout_l2'], error_percentages['dropout_maxnorm']],\n",
        "    'Paper Test Error (%)': [paper_error_percentages['l2'], paper_error_percentages['maxnorm'], paper_error_percentages['dropout_l2'], paper_error_percentages['dropout_maxnorm']]\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 3))\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "the_table = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center')\n",
        "the_table.set_fontsize(15)\n",
        "the_table.scale(1.5, 1.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "d06JCRbUiq-9",
        "outputId": "34494a17-cfef-46ba-e5a0-3eb1a28d2adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAD7CAYAAACsRJ9XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACLAklEQVR4nOzdd1QU1/s/8PcuLEvvIGABxQJ2EVQiCljADvaKiCVGExVLjBoNttg1GvWjiT32ghqNWLChgr0XVFRsqDQLCtKf3x/+dr4suwu7CDae1zmco3fuzNyZ2b07z8wtIiIiMMYYY4wxxlgpIf7cBWCMMcYYY4yxT4mDIMYYY4wxxlipwkEQY4wxxhhjrFThIIgxxhhjjDFWqnAQxBhjjDHGGCtVOAhijDHGGGOMlSocBDHGGGOMMcZKFQ6CGGOMMcYYY6UKB0GMMcYYY4yxUoWDIMYYY4wxxlipwkEQY4wxxhhjrFThIIgxxhhjjDFWqnAQxBhjjDHGGCtVOAhijDHGGGOMlSocBDHGGGOMMcZKFQ6CGGOMMcYYY6UKB0GMMcYYY4yxUoWDIMYYY4wxxlipwkEQY4wxxhhjrFThIIgxxhhjjDFWqnAQxBhjjDHGGCtVOAhijDHGGGOMlSocBDHGGGOMMcZKFQ6CGGOMMcYYY6UKB0GMMcYYY4yxUoWDIMYYY4wxxlipwkEQY4wxxhhjrFThIIgxxhhjjDFWqnAQxBhjjDHGGCtVOAhijDHGGGOMlSocBDHGGGOMMcZKFQ6CGGOMMcYYY6UKB0GMMcYYY4yxUoWDIMYYY4wxxlipwkEQY4wxxhhjrFThIIgxxhhjjDFWqnAQxBhjjDHGGCtVOAhijDHGGGOMlSocBDHGGGOMMcZKFQ6CGGOMMcYYY6UKB0GMMcYYY4yxUoWDIMYYY4wxxlipwkEQY4wxxhhjrFThIIgxxhhjjDFWqnAQxBhjjDHGGCtVOAhijDHGGGOMlSocBDHGGGOMMcZKFQ6CGGOMMcYYY6UKB0GMMcYYY4yxUoWDIMYYY4wxxlipwkEQY4wxxhhjrFThIIgxxhhjjDFWqnAQxBhjjDHGGCtVOAhijDHGGGOMlSocBDHGGGOMMcZKFQ6CGGOMMcYYY6UKB0GMMcYYY4yxUoWDIMYYY4wxxlipwkEQY4wxxhhjrFThIIgxxhhjjDFWqnAQxBhjjDHGGCtVtNXN+PjxYyQlJZVkWRhj36CMjAxIpdLPXQzG2FeI6w/GWFFYWlqiQoUKBeZRKwh6/PgxnJ2dkZaWViwFY4yVHlpaWsjJyfncxWCMfYW4/mCMFYW+vj6io6MLDITUCoKSkpKQlpaGDRs2wNnZudgKyBj7toWFhWHSpElcdzDGNMb1B2OsKKKjo9GnTx8kJSV9fBAk4+zsDBcXl48uHGOsdIiOjgbAdQdjTHNcfzDGShIPjMCKjYODAxwcHD7LvidPngyRSITjx49/lv0zxhhjjH0O/v7+cHZ2LpGmo1lZWahUqRK6detW7Nv+3DgI+oo9fPgQIpEIIpEINjY2yM7OVpovOjpayPcxQQoHGowxprlnz57BwMAAM2bMKJHtHz58GCKRCGFhYSWyfaZc3t9g2Z+Ojg7Kly+PXr164dq1a5+7iMWqX79+Csdb0N/atWuLdf+y892vX78irVfQ3+d6gFscIiIi8O+//yIkJARaWlpC+qtXrxAUFIQyZcrAxsYG/fv3x6tXr5Ruo1evXqhZsyaysrIUlkkkEvz666/Yvn07zpw5U2LH8Tlo1ByOfZm0tbURHx+PsLAwdOjQQWH5qlWrIBZzvMtYcTl27BiWL1+OqKgoJCQkwMDAANWrV0fnzp0xZMgQ6OrqfpZyiUQijfITUbHuf/LkyZgyZQqOHTsGLy8vjdcrSEhICCZPnvxxBfxMfv31V+jr62P48OFy6ZGRkRgzZgxu3LiBcuXKYfTo0Rg4cKDC+vHx8XB2dsaYMWMwYcIEheUtWrSAh4cHxo4dC19fX7kbIVbyHB0d0adPHwDAu3fvcObMGWzevBk7d+7EkSNH0Lhx489cwuLh7++vECwcP34cERER8PPzQ926deWW5f//55b3OuVnamr6aQtTjCZNmgR7e3uFNzUBAQE4dOgQ+vbtCyLCP//8g6SkJOzZs0cuX1hYGLZu3YrIyEhIJBKl+wgMDMSECRMwadIkhIeHl9ixfGocBH0DvvvuO1y9ehWrV69WCIKys7OxYcMGtGjRAhEREZ+phIx9G7Kzs/Hjjz/i77//hoGBAVq3bo3KlSvjzZs3OHToEEaNGoXly5dj3759qFy58icvX0hIiELawoUL8ebNG6XLvjSdO3dGzZo1lS7TJKj6ksTExOCff/7Br7/+CkNDQyH98ePH8PHxQZkyZTB48GCcPn0agwYNgrm5OTp16iS3jWHDhqF8+fIYO3asyv2MHTsWHTp0wJYtW9C7d+8SOx6mqHLlygoB+sSJE/H777/j119//WZaT/j7+8Pf318ubfLkyYiIiIC/v7/Gb2g+NWXX6Wt38+ZNnDx5Er/++qvcw+7nz59j3759mD59On799VcAH7os/Pbbb3jx4gVsbGwAfAjahwwZgh9//BGNGjVSuR9tbW306NEDixcvxr179z7L71uJIDVcvHiRANDFixfVyc4+kdjYWAJAvr6+NHjwYNLW1qb4+Hi5PLt27SIAtGXLFpJKpWRvby+3PDc3l1atWkXfffcdGRkZkZ6eHtWvX59WrVoll8/T05MAKPzl3Z69vT3Z29vT27dvafjw4WRra0s6OjpUq1Yt2r59u9JjSExMpBEjRpCDgwPp6OiQlZUVde3ala5fv640/+PHj6lHjx5kZmZGBgYG1LRpU4qIiKCQkBACQMeOHdP4PLKSs2HDhm+q7hgzZgwBIDc3N3r69KncsuzsbPrtt98IADk6OtKbN28+Uynl2dvbk5pV/Ucr6vdQtt7mzZtLpmCfkewzc/fuXbn0GTNmkFgspkePHhHRh89P1apVydfXVy7fnj17SEtLi86dO1fgfjIzM8nS0pI8PDyK9wA+oy+9/sj7G5zfixcvCADp6+sTEVFcXBz99ttv1LBhQ7KysiIdHR2yt7enIUOGKPxuExEFBgYSALp//z7Nnj2bKleuTFKplBwcHGjKlCmUmZmptEwRERHUrl07srCwIB0dHapcuTL9+uuvlJqaKpfv2LFjBIBCQkIoMjKSWrZsSSYmJhrXFbLv7po1a4pcFiKiHTt2UNOmTcnKyoqkUinZ2tpS8+bNaceOHUREtGbNGqX3IOrUNwVdJ1UAkKenJz19+pQCAgKoTJkyJBKJ6NixY2qdu3fv3tFvv/1G1apVI6lUSmZmZtSmTRs6deqUynN47NgxWrNmDdWrV4/09PTI09Oz0HKOHj2aANCVK1fk0s+ePUsAaP/+/UJaWFgYAaCzZ88KacOGDaPy5cvT27dvC93XqVOnCABNnDix0Lyfm7pxC7eR+kb0798f2dnZWL9+vVz66tWrYW5urvD0BvjQFKZ3794YMGAAEhMT0atXLwwcOBCpqakYMGAAxowZI+Tt168fPD09AXx4LRoSEoKQkBAEBwfLbTMrKws+Pj44dOgQOnfujD59+uD+/fvo1q0bDh06JJc3MTERjRo1wqJFi+Dg4IBRo0ahWbNm2LlzJxo2bIhTp07J5X/+/Dnc3d2xZcsWNGjQAMOHD4e5uTlatmz5zbVTZV+eu3fvYsGCBTA3N8fevXtRtmxZueVaWlqYMmUKevXqhfv372PevHlyy0Uikcq3GcoGFZG1v3/w4AHmz5+P6tWrQyqVFtvT1szMTCxYsAAuLi4wMDCAkZERmjRpotBUAgDevHmD3377DdWrV4ehoSGMjY1RuXJlBAYG4tGjRwA+vKmRNWnz9vYu0bb2a9euFfoc7N27F40bN4aRkZGwL3XO3Y0bN9CtWzdYW1tDKpWiYsWKCA4ORnJyssL+ZNfn9evX+Omnn1C+fHloa2sX2uchNzcX69atQ926dVGlShW5ZU+ePIGVlZUwfKuWlhbq1q2Lx48fC3lSUlIwdOhQDB8+HG5ubgXuSyKRwN/fH6dOncK9e/cKzMs+HVkT1RMnTmD+/PkoU6YMevbsiWHDhsHR0RHLli2Du7s73rx5o3T94OBgzJ49Gy1atMCwYcMglUoREhKCnj17KuRdtmwZvLy8EBkZibZt22L48OEoV64cfv/9d7Rs2RKZmZkK60RFRcHLywsikQjff/89unfvXizHrUlZli1bhi5duiAmJgYdO3bEqFGj0KpVK7x48QK7du0C8KFp3YgRIwAAderUEe5BQkJCSqw/T3JyMtzd3XHt2jX06NED33//PYyNjYXlqs5deno6mjVrhqlTp8LAwADBwcHw8/PDsWPH4Onpie3btyvd39y5czF06FBUq1YNw4cPV6sZ5ZEjR2BgYKDwBr18+fIAgMuXLwtply5dAgChzjlz5gyWLl2KZcuWyb2lVqV+/fqQSCQ4cuRIoXm/GsUZUbFPK//TjZo1a1KNGjWE5c+fPydtbW0aNmwYEZHCm6C///6bAFBQUJDcU6WMjAxq3749AaALFy4I6YU95ZU9cfbz86OMjAwh/fDhw0qfwgQFBREAGj9+vFz6vn37CABVrlyZcnJyhHTZk7Hp06fL5f/rr7/UfiLEPq0v/UmuJiZMmEAAaNy4cQXmi46OJgBUtmxZuXT8/yeLysjeouYl+7y3adOGzM3NKSAggMaOHUvz5s3TqNzK3gSlp6eTl5cXAaC6devSsGHD6IcffqDy5csTAFq8eLGQNzc3lxo2bEgAqHHjxjRy5EgaPXo0denShUxNTSk8PJyIPjyplb0xDgwMpJCQEAoJCaE//vij0DJq+iZI9lS4TZs2pK2tTf7+/jR27Fj64YcfiKjwc3fy5EnS19cnbW1t6tGjB40bN04ou6OjIyUmJiqcQxsbG6pXrx5VqVKFhg4dSsOHD6ewsLACy3nlyhUCIJQrrxkzZpCWlhY9efKEiIhycnKoWrVqcvXkkCFDyMHBgd69e6fWeVm1ahUBoL/++kut/F+6L73+KOgNg+ytsLe3NxERxcfHK33avm7dOqW/a7LPsJWVlfAZIfrw+9y0aVMCILwlISK6efMmaWtrU506dSgpKUluWzNnziQAcnWH7G0GAFq9enXRTgApfxOkaVlcXFxIR0dH6RuxvOvLzndgYKBGZZSt5+joKNRL+f/yvjEhIuHcBAUFUXZ2ttyyws7dlClTCAD17t2bcnNzhfRLly6Rjo4OmZqaUkpKipAuO4cGBgZ07do1tY/r7du3JBaLqXHjxkqXt2nThiQSCQ0cOJAGDBhAEomE2rdvT0Qf3hzXrFmTevToofb+iIjq1atHEomE0tPTNVrvU1M3buEg6CuWvwJesGABAaAzZ84QEdGsWbMIAF2+fJmIFIOg2rVrk4GBAaWlpSls+9q1awSARo8eLaSpGwQ9ePBA6TJzc3Ph/xkZGaSrq0sWFhZKX423bNmSANCJEyfk8ltbW9P79+/l8ubk5FCVKlU4CPoCfek3MZqQBQ2ym/6C2NnZEQB6/PixkFbUIKhcuXJCk6miUBYEyQK6SZMmyf1Ip6SkkKurK+no6FBcXBwR/V9d4O/vr7Dt9PR0uRu7j20O17lzZ5U3Kc+fPxfyy4IgsVis9HoUdO5ycnLI0dGRANCBAwfklv38888EgPr37y+XLjuHvr6+SutLVZYuXUoAaMWKFQrLHj58SHp6euTo6Ehjxoyhxo0bEwAKDQ0log9NT8RisUIZC3L16lUCQH379lV7nS/Zl15/KLu5HjNmDDVp0oQAkK6uLkVFRRW4jdzcXDI2NiYvLy+5dFUP/Yg+BPEAqF27dkLa8OHD5X4z88rJySErKyuqX7++kCa7kXdxcdH0sOUoC4I0LYuLiwsZGBjQy5cvC9zXxwZBBf2NGDFCbh0ApKOjo/BAhKjwc1epUiWSSCRywavMoEGDCAD9888/QprsHI4cOVKj47pz5w4BoE6dOildnpycTH379iUrKyuytramfv36Ced4ypQpZG5uTvHx8fTixQvy8/MjqVRKpqamNGrUKIXAT6ZVq1YKv21fInXjFh4Y4RvSp08f/PLLL1i9ejUaNmyINWvWoF69ekpHaElLS8P169dhZ2eH2bNnKyyXDZN4+/ZtjcpgamqKihUrKqSXK1cOp0+fFv5/+/ZtpKenw9vbG/r6+gr5vb29ER4ejitXrqBJkya4c+eO8Io5/8hbYrEYjRs3RkxMjEZlZUwTL168APB/zQwKUr58eTx79gzPnz9XK39Bfv755wJnvNZUbm4uli1bBkdHR0yZMkVuRDkjIyP89ttv6NChA3bu3ImffvpJWKanp6ewLalUCqlUWmxlCw0NRWhoqNJl/v7+QmdeGT8/P7Ro0ULl9pSdu8jISNy/fx+tW7eGr6+v3LLffvsNq1atwqZNm7Bs2TLo6OjILZ8zZ47S86DK06dPAQBlypRRWGZvb4+DBw9izJgxWLZsGcqVK4cVK1agU6dOyMzMxKBBg9CrVy/4+voiLCwMo0ePRkxMDCpXrow//vgDrVu3VtimbD+y/bJP4/79+0JTUIlEgjJlyqBXr14YN24catWqJeTbuXMn/vrrL1y6dAmvXr2Sm9Pl2bNnSrfdpEkThTR3d3doa2vLNXWSNQk/ePCg0uZKEolE6e95Yc0si0LTsvTo0QNjx45FzZo10atXL3h7e8PDw0Ou6Vlx8PX1xYEDB9TOX7FiRVhaWqpcruzcpaSk4MGDB3B2dka5cuUUlnt7e2PFihW4cuUKAgIC5JY1aNBA7bIBEJruqhrZztzcHOvWrVNIj46OxowZM7B8+XJYW1vD19cXt2/fxrZt2/Ds2TMEBwejTJkySgdiMTc3BwAkJSV99G/bl4CDoG+IlZUV2rdvjy1btqBr1664c+cOFi9erDTvq1evQESIi4srcGja1NRUjcpgYmKiNF1bWxu5ubnC/1NSUgAovzkAAFtbW7l8svbS1tbWSvOr2g5jXztNfxgLc+fOHbx69Qp2dnZKv/uJiYkA/u8BiLOzM2rXro3Nmzfj6dOn8Pf3h5eXF+rWrVvsQ+9v3rwZPXr0UDt/YedG2XLZjaOy/lmGhoZwdXXFoUOHcOfOHbkbWF1dXbn/q6Owm5QmTZrg7NmzCunTp09HYmIi/vjjDzx69AgdO3ZEp06dsGTJEqxatQodO3bE3bt3FQK8vDco7NNR5+Z6/vz5GDNmDKysrODj44Ny5coJAfXChQuRkZGhdD1lv21aWlqwsLCQ60f08uVLAMDvv/+uUdlL4rdT07KMGTMGFhYWWLZsGebPn4958+ZBW1sbbdu2xR9//KH0weqnUNi5UbZc03sbTfaXn+zzk56ervY6RIRBgwahSZMm6NevH27fvo1Dhw5h48aNwujCFy9exB9//KE0CHr//j0AKH14/TXiIOgbM2DAAOzcuRP9+vWDrq6uyqFSZU9Y6tevjwsXLnzKIsrtPz4+Xuly2VN3WT5ZcJWQkKA0v6rtMFZcbGxscPv2bTx58gTVqlUrMO+TJ08A/N8P3sco7psU2Q3KzZs3cfPmTZX5ZA9AtLW1cfToUUyePBmhoaEYPXo0gA8PXX766Sf8+uuvn21emk95k2Jtba3xPExFuUm5efMmZs2ahdWrV8PS0hLz5s2Drq4uVq9eDT09PXz33XfYt28fli1bhpkzZ8qt+63doHwrsrOzMW3aNNja2uLKlStyD/OICHPmzFG5bnx8vEJ9k5OTg+TkZLnPsOy3MiUlBUZGRmqXTdPPtDo0LYtIJEL//v3Rv39/JCcn4+TJk9i8eTO2bduGmJgYXLt27bPUMYWdG2XLNb230WR/+VlZWQH4vzpdHcuWLcPly5dx/fp1AB8eigHyczrVq1cPK1euxJs3bxQebMv2Jdv3145Hh/vG+Pr6omzZsoiLi4O/vz/MzMyU5jMyMoKzszOio6Px+vVrtbYtq4TyvsIvKicnJ+jq6uL8+fNIS0tTWC6bV0H2xaxatSp0dXVx4cIFhRuK3NxcREVFfXSZGCvId999BwCFjoxz+/ZtPHv2DGXLlpVrLiASiZCdna10HVUjQ8nWK06yH9/OnTuDPvQLVfq3Zs0aYR0LCwssXrwYcXFxuHXrFpYsWQJzc3OEhIQUeANX0j7lTUpRroOmNym5ubkYOHAgmjdvLkzqeOfOHVSrVk0IqPT09FCtWjWlTZu+tRuUb0VSUhLevHkDd3d3hdYMFy5cEIJXZU6ePKmQdvr0aWRnZ6NevXpCWsOGDQHgixgp9WPKYmFhAX9/f2zduhXNmjXDrVu3hNEOi/MepKQYGxujUqVKuHfvHuLi4hSW57+3+Rh2dnawsLAQApnCxMXFYfz48ZgyZQoqVaoktyzvm0jZv5XVeXfu3EHZsmWFt85fOw6CvjFaWlrYvXs3du3apfCUML/hw4cjLS0NgwYNUtrsLTY2Fg8fPhT+L/vQy55yfwwdHR307NkTSUlJCuU8cOAADh48iMqVKwtDREqlUnTr1g0JCQmYP3++XP6VK1fi7t27H10mxgrSt29fiMVirFixQmgypoysCUj//v3l0s3MzJT+KD58+FDtBxHFwdnZGcbGxrhw4YLQ909dIpEIzs7O+PHHH4VZw/MOqf013KTIbhyVTWCZmpqKCxcuCIHGx5I1n1P3JmXJkiW4fv06li1bJpeev6lURkaGyhuUvPtlXwZra2vo6enh0qVLcg/9Xr16hWHDhhW47qJFi+T6eGVmZgqTX+Yd8n3o0KHQ1tbGsGHD5IZZl3n9+rVcH6KSpGlZjh8/DiKSy5OVlSUE9bJ+wGZmZhCJRMVyD1KSAgMDkZWVhfHjx8sd17Vr17B27VqYmJgonbZEUyKRCE2aNEFsbGyBv0kyQ4cOReXKlTFy5EghzcnJCQAQFhYmpIWFhcHOzk7hQdDjx4/x4sULNG3a9KPL/qXg5nDfIFdXV7i6uhaab/DgwThz5gzWrVuHyMhItGjRAnZ2doiPj8ft27dx9uxZbNq0SRiDXzb3x4QJE3Dz5k2YmJjA1NRUrvO0JmbPno2IiAhMnz4dUVFRaNiwIR4+fIjt27dDX18fa9asketzMGvWLBw5cgQTJ07EqVOnUK9ePURHRyMsLEyYm4ixklKtWjWMGDECf/zxB9q3b49du3bJNXfLzc3F77//jg0bNsDR0VFuni3gQyfagwcPIiIiQphzKzMzE6NGjfqkx6GtrY0hQ4Zg9uzZGDNmDObNmweJRCKX58aNG7C2toa1tbXwICT/XByyNyl5ByopzgclJaVx48ZwdHTE/v37cfjwYbmBFaZPn47k5GT0799fYVCEomjSpAnEYrHSfj/5PX78GL/++iumTZsmd66dnZ2xd+9ePHr0CPb29nj06BFu3ryJdu3aKWxDth/Z54t9GcRiMYYOHYr58+ejTp06aN++PVJSUrB//37Y29vDzs5O5bqNGjVCnTp10L17dxgYGGDv3r24c+cOOnXqhM6dOwv5atasif/9738YMmQIqlWrhjZt2sDR0RFv377FgwcPEBERgX79+mH58uUlfryalsXf3x/GxsZo1KgR7O3tkZWVhfDwcNy6dQtdunSBvb09gA999tzc3HDixAkEBASgSpUqEIvFCAgIEPIU5N69e5g8ebLK5ePGjVMYeKkoxo4di3379mH9+vWIjo5G8+bNkZCQgK1btyI7OxsrVqzQqMliQTp27Ijdu3cjPDwcvXr1Uplv27ZtCAsLw7lz5+SaFlarVg2tWrXC5MmT8ejRIzx//hyHDx9WmOcOgPDgqzgCuC9GcQ41xz4tTWdBzj9EtszWrVupRYsWZGZmRhKJhMqWLUteXl40f/58heEh165dS7Vq1SKpVEoA5LanbJhfGdkcHPklJibS8OHDyd7eniQSCVlaWlKXLl3o+vXrSrfz6NEj6t69O5mampK+vj41adKEIiIiijw0LytZX/oQt5rKysqi/v37C3M6dOvWjcaPH08//vijMEx7lSpVKCYmRmHdgwcPkkgkIn19fRowYAANGzaMnJycqFGjRmRra6tyiOzY2NiPKrOqeYJkw9A7OjpSUFAQ/fLLL9SnTx+qU6cOAaDTp08TEdGuXbtIJBJRw4YNKSgoiMaPH099+/YlY2NjEovF9O+//wrbvXnzJolEIrK1taUxY8bQtGnT5OYcUkWdIbLzziEkGyJb2Sz1RIWfO9k8QRKJhHr16kXjx48XhkB3dHSkhIQEhXOoqm4rjLe3NxkbGysM7Z9fmzZtyM3NTW5uNKIPdZ5UKqVKlSpRcHAwVapUiXR1dZUOv+vh4UFmZmaF7utr8aXXH5r8BmdmZtLvv/9OVapUIalUShUqVKDRo0fT27dvCxwi//79+zRr1iyqXLky6ejokL29PU2ePFluLr68zp07Rz169CA7OzvhN9XFxYXGjRtH0dHRQj7ZMM8hISEfcwqUDpGtaVn+97//UYcOHcje3l6YOqNBgwa0bNkyuTkMiT4MC92mTRsyNTUlkUik1u++OkNkA6BXr14J66CAKQ3UOXfv3r2jSZMmUdWqVYW5gVq3bk0nT55UyPsx9y/v378nc3Nzat26tco8L1++pDJlytDYsWOVLo+Pj6dOnTqRvr4+WVhY0NixYxXqIaIP00RYW1srXJMvEc8TxBj77L70m5iiCg8Pp65duwo/7qampuTu7k7z588vcB6Z7du3U61atUhHR4dsbGxo2LBhhd4ElUQQRESUnZ1Nf/31FzVu3JiMjY2FG7NWrVrRsmXLhAk6nzx5QuPGjaNGjRqRtbU16ejoUIUKFahTp05CoJRXQQ9KVJHdBBT05+fnJ+T/2CCI6MP8R126dCFLS0uSSCRkb29PI0aMUDovyMcEQVu3biUAtHXrVpV5Nm7cSNra2nT16lWly/fv3081atQgiURCNWrUoIMHDyrkiY2NJZFIRMHBwUUq55foW60/1FFc33/27Zs4cSJpa2vTw4cPS2wfd+/eJZFIRFOmTCmxfRQndeMWEVG+hphKXLp0CfXr18fFixfh4uKi2asmxliptXHjRvTp04frDlZqZWVloVq1anB0dBSak5SEiRMnYs6cOYiOjoajo2OJ7edTKs31R79+/bBu3TrExsYqNEVlLK+3b9+icuXK8PPzw99//10i+wgICMDRo0dx9+5dGBgYlMg+ipO6cQsPjMAYY4yVEIlEgpkzZ+Lw4cMlNorlq1evsHjxYgwZMuSbCYAYY+oxMjLC+vXr4eDgUCKD0sge5Pzzzz9fRQCkCR4YgTHGGCtB3bt3x+PHj4XJU4tbbGwsRo4cWehIY4yxb5OPjw98fHxKZNsSiQQTJ04skW1/bhwEMcYYYyXs559/LrFtu7i4lLrmYt+6tWvXYu3atZ+7GIx907g5HGOMMcYYY6xU0ehNUFhYGKKjo0uqLIyxb0xkZCQArjsYY5rj+oMxVhSxsbFq5VNrdLjTp0+jSZMmX/Qs4IyxL5NYLEZubu7nLgZj7CvE9QdjrCi0tLRw8uRJuLu7q8yj1psgqVSKnJwcbNiwAc7OzsVWQMbYty0sLAyTJk3iuoMxpjGuPxhjRREdHY0+ffpAKpUWmE+j5nDOzs7c+ZIxpjZZExauOxhjmuL6gzFWknhgBMYYY4wxxlipwkEQK9DDhw8hEonQqlWrAvPFxMRgxowZaNq0Kezs7KCjo4Py5cujb9++uH379icqLWMfxMXFYeHChfDx8UGFChWgo6MDGxsbdO7cGWfPnlV7O6dOncLo0aNRv359WFhYQFdXF05OTvjll1/w+vVrhfzp6ekYNWqU8D3Q1dWFjY0NGjdujDVr1iArK0vpflJSUjBq1CjY29tDKpXCwcEBP//8M969e6c0f25uLhYvXoxatWpBT08PVlZW6NmzJx48eKDyWA4ePAhPT08YGRnB2NgY3t7eOHLkiMr8d+/eRbdu3WBpaQk9PT3UqVMHy5YtgxrdSPHgwQMYGhpCJBLhhx9+UJrn1atXGDNmDCpXrgypVAorKyt06dIFN2/eVJrfy8sLIpFI6Z+Dg4PSdZ4+fYrBgwcLnwE7OzsEBQXhyZMnSvNv2LABgwcPhqurK6RSKUQiUaHDFGt67YAPM7yHhISgZs2a0NfXh6mpKVxcXDBlypQC9wUAs2fPFo77zJkzheYv7FrI6nhVf5MnTy50H4ypqyjfMVXU/R4V1+8B+/bwPEGsWEyaNAlbt25FzZo14efnB2NjY1y/fh3r16/Hjh07cODAATRt2vRzF5OVEosXL8bs2bPh6OgIHx8fWFlZISYmBrt378bu3buxadMmdO/evdDtdOnSBUlJSfDw8EDfvn0hEolw/PhxzJkzBzt27EBUVBTKlCkj5H/37h2WLVuGBg0aoG3btrCyssKrV6+wf/9+9O/fH1u2bMH+/fshFv/f86fU1FR4enriypUr8PHxQc+ePXH58mXMmzcPEREROHHiBHR1deXKNXjwYKxcuRI1atTA8OHD8ezZM2zbtg2HDh3CmTNnUKVKFbn8GzZsQEBAAKysrNCvXz8AwNatW9GyZUts27YNXbp0kct/69YtfPfdd3j//j26desGOzs77Nu3D0OHDsWtW7ewePFilecsNzdX2IcqycnJcHd3R0xMDNzd3eHn54fnz58jNDQU+/fvx9GjR9GwYUOl64aEhCikmZqaKqTdv38f3333HRISEuDj44Pu3bsjJiYG69atQ1hYGKKiouDo6Ci3zsSJE/Ho0SNYWlrC1tYWjx49KvA4inLtHj9+jGbNmuHBgwdo0aIF2rZti4yMDNy7dw+hoaFKj0/mxo0bCAkJgYGBAVJTUwssG6DetZCpU6cO/P39FdK9vLzUWp8xdWj6HVNFk+9Rcf0esG8QqeHixYsEgC5evKhOdvYNiY2NJQDk6+tbYL41a9bQpUuXFNI3b95MAKh69eolVUT2BduwYcNnqTtCQ0Pp+PHjCuknTpwgiURCZmZmlJ6eXuh2Zs2aRXFxcXJpubm5NGTIEAJAQ4cOlVuWk5NDGRkZCtvJysoiLy8vAkD//fef3LLffvuNANAvv/wil/7LL78QAJoxY4Zc+tGjRwkANW3aVG5fYWFhBIB8fHzk8r98+ZJMTU3J0tKSnjx5IqQ/efKELC0tydLSklJSUuTWadq0KQGgsLAwIS0jI4OaNGlCACgqKkrhGGXmzZtH2tra9McffxAAGjx4sEKeH3/8kQDQqFGj5NKjoqJIS0uLqlevTjk5OXLLPD09Sc2fLCIiatu2LQGgRYsWyaVv27ZNZZ0WHh5ODx8+JCKimTNnEgBas2aNyn1oeu2ysrLI1dWV9PT06OjRowrby8rKUrmvzMxMcnFxoYYNG1KfPn0IAJ0+fVplfiL1roWsjg8MDCxwW5/D56o/WMnR9DumjKbfo+L6PWBfD3XjFg6CWIHUDYIKUrVqVQJAiYmJxVgy9jX4Em9ifHx8CACdP3++yNt49uwZAaAaNWqovc6iRYsIAC1cuFBIy83NJTs7OzI0NKR3797J5X/37h0ZGhpSpUqV5NJ79uxJACgiIkJhH7JA69GjR0LaX3/9RQBoypQpCvknT55MAGjdunVC2p07dwgAeXt7K+Q/fvw4AaCgoCClxxgdHU26uro0adIkOnbsmMob73LlypFYLKa3b98qLPP39ycACjc3mgRB79+/J21tbSpTpgzl5uYqLK9bty4BoPv376vcRmE3aEW5drKHQpMmTVLrOPIKCQkhqVRKN2/epMDAwEKDIHWvBQdB7HMpahD0Md+j/Irj94B9edSNW7hPECtxEokEAKCtza0v2edXHJ9HTbeRm5uLAwcOAABq1qwppMfExODZs2do3LgxDAwM5NYxMDBA48aN8eDBA7k+LMePHxeW5efr6wsAiIiIkMsPAD4+Ph+d38PDAwYGBnL5ZXJychAYGIgqVapg4sSJCsvzevHiBSwtLWFoaKiwrGLFigCAo0ePKl1306ZNmDFjBhYuXIjjx48rnUMmOTkZ2dnZsLe3h0gkUrmPY8eOFVjOghTl2m3duhUA0LVrVzx58gTLly/HrFmzsH379gL7EF26dAm///47QkJCUL169ULLpsm1kHn27BmWLl2KGTNmYNWqVbh//75a6zH2qRX1e6QM35+UbnzVWYk6d+4cbt68CTc3N6Xt9hn7lB4/fozDhw/D1tYWtWrVKvJ2Vq9eDUB5oAAAmZmZmDFjBogIycnJOHLkCG7fvo2goCA0b95cyBcTEwMACn14ZKpUqYKDBw8iJiYG5cuXR2pqKp4/f46aNWtCS0tLaf682y1sH5rm19LSQsWKFXHr1i1kZ2fL3TjMnDkTly5dwpkzZ6Cjo6P0eGQsLS2RkJCAd+/eKQRCspm+7969q3Td3r17y/2/atWq2LhxI1xdXYU0MzMzaGlp4dGjRyAihUCosH2oQ9NrBwAXL14EAJw4cQKjR49GRkaGkN/Kygrbtm1T6IOTkZGBvn37om7duhg7dqxaZdPkWsiEh4cjPDxc+L9IJELv3r2xfPlyhSCPsc+pKN8jZYrr94B9vfhNECsxb968QWBgIMRiMebMmfO5i8NKuaysLAQEBCAjIwOzZ89WGkSo48qVK5gyZQqsra1V3pRmZmZiypQpmDp1KpYuXYo7d+5gzJgx+Pvvv+XyvXnzBgBgYmKidDvGxsZy+TTNX9g6muaXrZObm4u3b98KaVevXsXUqVPx888/o379+krXy6t169bIzc1VGMXp7Nmz+O+//wBAYfQ9Pz8//Pfff4iLi0NaWhpu3bqFESNG4P79+2jZsiUeP34s5NXX10fTpk0RHx+P//3vf3Lb2blzJ65cuaJ0H5ooyrVISEgAAIwYMQLBwcF48uQJEhMT8eeff+LNmzfw9/fH8+fP5bbz22+/ISYmBmvWrFHrM6vptdDX18ekSZNw8eJFvH79Gi9fvsThw4fRoEEDbNiwAX379i10G4x9SkX5HuVXXL8H7OvGQRArEe/fv0fHjh1x+/ZtTJs2jUcYYp+VbJSsEydOYNCgQQgICCjSdh48eIC2bdsiJycHW7ZsgaWlpdJ8hoaGICLk5OTgyZMnWLp0KVauXAkvLy+kpKR8zKF8cTIzMxEYGIjKlSsXOLJZXlOnToWtrS3mzZsHDw8PjBkzBr1790bTpk2F5l55R9ADgJEjR6Jt27aws7ODnp4enJ2dsXDhQkyYMAGvX7/GvHnz5PL/8ccfMDQ0xE8//YRWrVph7Nix6NSpE7p27YratWsr3UdJkzXda9euHWbNmoVy5crB0tISw4YNQ3BwMN68eYNVq1YJ+U+fPo158+Zh4sSJcs0oVSnKtbC2tsbUqVPh4uICExMTmJmZoXnz5jh69CiqVauGnTt34tKlS0U7YMZKgKbfI2XrF8fvAfv6cRDEil16ejr8/Pxw7NgxjB8/HhMmTPjcRWKlWG5uLvr3749NmzahT58+WL58eZG2ExsbC29vbyQlJWHHjh3w9vYudB2xWIxy5cphyJAh+PvvvxEZGYnff/9dWC57i5D3bUFesoBJlk/T/IWto2l+2ToikQhGRkYAPjS9un79OtasWQOpVKp0nfzKlSuH8+fPY8CAAYiNjcWff/6JM2fOYOrUqUJ9YW1trda2Bg8eDACIjIyUS69Tpw7Onz+Pbt264dKlS1i0aBHu3LmDv/76S7jpUXcfynzMtejQoYNCflnahQsXAADZ2dkIDAxE7dq1MW7cOLXKVJRroYq+vr5wnvKfW8Y+J02+R/kV1+8B+zZwEMSK1fv379GhQweEh4dj7NixmDFjxucuEivFcnNzERQUhHXr1qFnz55Yu3ZtkZ7+P3jwAF5eXnj+/Dm2bduGdu3aabwNWf8h2cADgPI+OXnl73diYGAAW1tbxMbGIicnp9D8he1D0/w5OTmIjY1FxYoVhf5Aly9fRm5uLho1aiQ3yaYsSPzrr78gEokU5qApW7YsVq5cibi4OGRmZuL+/fv45ZdfEB0dDQByfXwKYmFhAZFIpHTeHCcnJ2zduhUJCQnIyMjAzZs3MXDgQNy4cUOjfSij6bUDgGrVqgFQPq+RLO39+/cAPsw5FRMTgytXrkBHR0fu3K5btw4A4O7uDpFIhN27dwMo+rVQRfamU505iRj7VDT5HuVVXL8H7NvBAyOwYvP+/Xv4+fkhPDwcY8aMwezZsz93kVgpJvvB++eff9C9e3esX7++SO2+Hzx4AG9vbzx//hxbt26Fn59fkcrz7NkzAP83GhHw4QbZzs4OkZGRSE1NleuAnpqaisjISFSsWFHoWA8Anp6e2LJlCyIjIxUmID548CAAyKV7enpi8+bNOHToEBo1aqQ0v6enp1x+ADh06JDCG4hTp04JE4TKtGzZUmmzwOfPnyMsLAxOTk5o3Lgx6tWrV9DpAQChmaG2tjY6d+5caH7gw+ArRAQHBwe18r99+xZ79+6FhYUFWrZsqdY6yhTl2jVr1gyRkZG4desWOnXqJLe9W7duAYBwHFKpFAMGDFC67xMnTiAmJgYdOnSAlZWVsE5xXgvgQx+tvGVi7EugyfdIprh+D9g3pjjH22bfHnXnCXr//j21bNlS6QSIrPT6XPN85OTkCHOpdO3atcBJKImIEhMTKTo6WmEuqwcPHlCFChVIW1ubQkNDC93vzZs3KTU1VSE9NTWVWrVqRQDo999/l1v2KSZLNTExKdbJUiMjIws9FwXNTZOZmUlpaWlyaTk5ORQcHEwAaOTIkXLLHjx4QMnJyQrbefr0KdWoUUNhriMiorS0NIXrnp6eTl27dlU6iWp+JTFZ6oMHD0gqlZK1tTU9ffpUSE9JSRHmLjp8+HCB5SIiteYJyquga3Hp0iWlcymFhoaSWCwmMzMzev36tVr7KW48T9C3rbDvWEH1sibfI01/D9jXT924hd8EMbVcv34d/fr1U7rMyckJt2/fRnh4OGxsbGBkZITJkycr5OvXrx8/UWSfxNSpU7Fu3ToYGhqiatWqmD59ukIef39/1K1bFwCwZMkSTJkyBSEhIXKfXW9vbzx+/BiNGjXCtWvXcO3aNYXt5M2/bds2LFiwAB4eHnBwcICxsTHi4uKwf/9+JCcno0mTJhg5cqTc+mPHjsW///6L2bNn4/Lly3BxccGlS5dw6NAhuLm5ITg4WC6/t7c3Bg4ciJUrV8LFxQVt27YV3lKZm5tj8eLFcvnNzMywZMkSBAQEwMXFBd27dwfwYa6N5ORkbN26VejfI/O///0PjRs3hr+/P7p37w5bW1vs27cPN2/exE8//YTvvvuusEtQoPj4eNSoUQM+Pj6oWLEiMjMzcfDgQdy+fRtt27bFzJkz5fJHRERgyJAhaNKkCSpWrAgzMzPExsZi3759SE1NRe/evRU6N1+8eBGdOnVCy5YtUb58eaSkpGDfvn14/PgxBg0ahGHDhimUa+XKlTh16hSAD3WeLE3WhNHDwwMDBw4U8mt67SpWrIi5c+di+PDhqFOnDjp27AipVIp9+/bh4cOHGDx4sNwQ6p/CyJEjcf/+fbi7u6NcuXLIycnBpUuXcOrUKUilUqxdu1blCHiMaUqT75iqelnT75GmvwesFCnOiIp9e2Rvggr68/T0FGZzL+jv2LFjn/tw2Cf2uZ7kyp76FfSX9+ljSEgIAaCQkBC57RS2jfxV6Pnz52nQoEFUo0YNMjU1JW1tbbKwsCBvb2/666+/VD6BfP36NQUHB1P58uVJIpFQhQoVaPTo0QpvaGRycnJo0aJFVKNGDZJKpWRhYUHdu3ene/fuqTwn+/fvpyZNmpCBgQEZGhqSp6cnhYeHq8x/+/Zt6tKlC5mbm5NUKqVatWrR0qVLlb41UKagtw8pKSkUEBBAlSpVIl1dXTIyMiJ3d3dasWIF5eTkKOS/evUqBQQEUPXq1YXzamlpST4+PrRlyxal+3/06BF17dqVypcvTzo6OmRqakrNmjWjHTt2qCxzYZ+bwMBAhXU0vXZERHv27KEmTZqQoaEh6erqUv369WnFihUq86sqZ3G8CVqxYgW1atWKypcvT3p6eiSVSqlSpUo0cOBAio6OVrtMJYHfBH17NPmOqaqXZdT9Hmn6e8C+furGLSIiosICpUuXLqF+/fq4ePEiXFxc1ImtGGMMGzduRJ8+fbjuYIxpjOsPxlhRqBu38LAYjDHGGGOMsVKFgyDGGGOMMcZYqcJBEGOMMcYYY6xU4SCIMcYYY4wxVqpwEMQYY4wxxhgrVTSaJygsLAzR0dElVRbG2DcmMjISANcdjDHNcf3BGCuK2NhYtfKpNUT26dOn0aRJE+Tk5Hx0wRhjpYtYLEZubu7nLgZj7CvE9QdjrCi0tLRw8uRJuLu7q8yj1psgqVSKnJwcbNiwAc7OzsVWQMbYty0sLAyTJk3iuoMxpjGuPxhjRREdHY0+ffpAKpUWmE+j5nDOzs48YRljTG2yJixcdzDGNMX1B2OsJPHACIwxxhhjjLFShYOgL8TDhw8hEokgEolgY2OD7Oxspfmio6OFfA4ODp+2kIx9RTZs2IDBgwfD1dUVUqkUIpEIa9eu1Wgbx48fF75vyv7yby85ORl///03OnTogEqVKkEqlcLS0hKtW7fGwYMHVe4nOjoavXv3ho2NDaRSKezt7TFixAi8fPlSaf709HRMmzYN1atXh66uLszMzNC6dWuhI7kyBw4cQIsWLWBqago9PT3UqlULCxYsUNrX08vLq8DjFolEWL9+vdw6Dg4OKvN6eXkpLdOzZ88wYsQIVK9eHQYGBihTpgw8PDywfv16hXJNnjy50DINGDBAyJ+amooNGzagW7duqFq1KvT09GBqagpPT09s3rxZ5XnKzc3F4sWLUatWLejp6cHKygo9e/bEgwcPFPLGx8fjp59+QsOGDVGmTBlIpVKUK1cOzZs3x86dO6Gqy21JX4vc3FwsWbIELi4u0NfXh7GxMZo2bYo9e/YoLU9h5/bhw4cqzxdj6iqOOvns2bMIDAxEzZo1YW5uDl1dXVSuXBndu3fHhQsXlK5TlLqJlQ4aNYdjJU9bWxvx8fEICwtDhw4dFJavWrUKYjHHrowVZuLEiXj06BEsLS1ha2uLR48eFXlbnp6eSn8s69atK/f/7du3Y8iQIbCzs0Pz5s1RtmxZPH36FKGhoThw4ADmzJmDn3/+WW6dM2fOoEWLFnj//j38/Pzg6OiIK1eu4M8//8SBAwcQFRUFCwsLIX96ejqaN2+OqKgo1K5dG0OGDMHr168RGhoKT09PhIaGws/PT24ff/75J0aMGAFjY2N06tQJpqamOHz4MEaPHo3Tp09j+/btcvn79eun9HizsrIwc+ZMiMViNG/eXGG5iYkJgoODFdKVPbB58OABGjZsiOTkZPj6+qJ9+/ZISUnB7t270bdvXxw9ehRr1qwR8hd0s7Jy5UrExcXB19dXSDt58iQCAgJgYWGB5s2bo3PnzkhISMDOnTvRq1cvREZGYsmSJQrbGjx4MFauXIkaNWpg+PDhePbsGbZt24ZDhw7hzJkzqFKlipD3yZMn+Oeff9CoUSN07NgR5ubmSEhIwN69e9G5c2cMHDgQK1askNt+SV8LIkK3bt0QGhoKR0dHDBgwABkZGfj333/h5+eHxYsX46efflJ6HgMDA5VeK1NTU6X5GdNEcdTJJ0+eRHh4OBo1aoRmzZpBX18fDx48wJ49e7B9+3asW7cOAQEBCutpUjexUoTUcPHiRQJAFy9eVCc7K4LY2FgCQE2bNiUTExPy8/NTyJOVlUVlypQhHx8fkkqlZG9v/8nLyZgmNmzY8NnqjvDwcHr48CEREc2cOZMA0Jo1azTaxrFjxwgAhYSEqJX/yJEjtGfPHsrJyZFLv337NpmYmJBEIqG4uDi5ZTVr1iQA9O+//8qlz5kzhwDQ4MGD5dLnzp1LAKhr166UnZ0tpN+7d4+MjY3JysqKUlJShPS4uDiSSqVkZmYmnA+iD/WJn58fAaDNmzerdXw7duwgANS+fXuFZfb29hrVSUOGDCEAtHDhQrn0V69eUYUKFQiAXHlVefHiBWlra5OFhQVlZGQI6ZcvX6b169fLpcny29vbEwA6e/as3LKjR48K9XDe9cLCwggA+fj4yOXPzMyUuwYyKSkp5OzsTADoxo0bQvqnuBbbt28nANS4cWNKS0sT0hMTE8ne3p6kUinFxsbKrRMSEkIA6NixY2rt+1P5nPUHK37FUSe/f/9eafr169dJV1eXrK2tKTc3V26ZpnUT+/qpG7fwK4UvjJ6eHnr06IF9+/YhISFBbtl///2H+Ph49O/fX2G9Z8+eISQkBI0aNYK1tTWkUikcHBwwdOhQhe3cu3cPRkZGKFeuHJKTk9VeporslXJ8fDwCAwNhaWkJPT09NGrUCMePH1e6zqNHjzBgwACULVsWOjo6KFeuHAYMGIDHjx8r5JU1B0lPT8fEiRPh6OgIiUSCyZMny+0/Li4OvXr1gqWlJYyMjNC2bVuhCUt0dDT8/f1hbm4OIyMjdOnSBfHx8WodH/s6tWjRAvb29p90n82aNUP79u0V3tZWq1YN3bt3R1ZWFqKiooT0+/fv48aNG3Bzc1N48zt69GhYWFhg/fr1SE1NFdL//fdfAB+aMGlpaQnpjo6O6N+/PxITE7Fjxw4hff/+/cjIyMDAgQPlzoe2tjamTJkCAFi2bJlax7dq1SoAkGt2VlSy72abNm3k0k1NTeHh4QEASEpKKnQ769atQ3Z2NgICAqCjoyOk161bF3369JFLA4AyZcpg8ODBAIATJ07ILZO9tZk2bZrceq1bt4aXlxcOHTokV0dJJBK5ayBjZGSEVq1aAfhQp8p8imsh+3xMmDABenp6QrqlpSVGjhyJjIwMuTdsjH0qxVEn6+rqKk2vWbMmnJ2dkZCQgJSUlI/aBys9OAj6AvXv3x/Z2dkK7bxXr14Nc3Nz+Pv7K6xz4sQJzJ8/H2XKlEHPnj0xbNgwODo6YtmyZXB3d8ebN2+EvJUrV8bixYsRFxeHgQMHCulZWVno2bMn0tLSsH79erkmOIV5/fo1PDw8cPPmTQQEBKBTp064cOECfH19cePGDbm8d+/ehZubG1avXo369etj9OjRqFevHlavXg1XV1fcvXtX6T46d+6MtWvXwtvbGyNGjEDFihWFZa9evYKHhwdiY2MRGBgILy8vhIWFoWXLlrhx4wa+++47vHv3Dv3794erqytCQ0PRs2dPtY+PlW4xMTFYuHAhZs6cifXr1yMuLk7jbUgkEgAfbnhlXrx4AQByn2UZsViMChUqIC0tDWfOnFFrHVna0aNHNcofFRWFjIyMAsv/9OlTHDx4ELa2tmjbtq3SPBkZGVi7di1mzJiBJUuW4OzZsyq3V7NmTQAfhkHO6/Xr14iMjISNjQ2qV69eYJmA/wsG8tZlhVF2LYAPfcAMDAzQuHFjhXVkTe0iIiIK3X56ejqOHj0KkUiEGjVqCOmf4lpo+vnI68SJE5g9ezbmzp2L3bt34927dwWWg7Evxf3793Hnzh2UL18eJiYmCss1qZtYKVKcr5VY0cmaw/n6+hLRhyYyNWrUEJY/f/6ctLW1adiwYURECs3h4uPj6e3btwrbXbduHQGg6dOnKyzr0aMHAaD//e9/RET0888/EwAaP368RmUHQABo6NChcs2AVq5cqbQ5j7e3NwGgv/76Sy596dKlBICaNWsml+7p6UkAqG7dupScnKxy/yNHjpRLlzW3MTU1lWtyk5ubS23atOHP9CfwpTRn+djmcPn/tLW1aeTIkUqbQinz5s0bKlOmDOnq6lJSUpKQfvv2bQJAbm5uCuvk5OSQhYWF3HeUiKhRo0YEgG7evKmwTnBwMAGgBg0aCGnLly8nAPTzzz8r5L9y5YpwTLdu3SrwGKZOnUoAaNy4cUqXy5qY5f9zc3Oje/fuKeR/8eIFVa1alUQiEbVq1YrGjh1LP/zwA9nY2FClSpXo9OnTBZaHiOjEiRMEgBo1alRoXpns7GyqVasWiUQiun79upD+7t07AkA1a9ZUup6s+dmkSZMUlsXHx1NISAhNmjSJBg8eTOXLl1fajPJTXAtZvb5v3z6FZQsXLiQAZG1tLZcuaw6X/8/U1JTWrVtXYFlK0pdSf7DiV9Q6Webs2bMUEhJCEyZMoN69e5ORkRHp6+sr/dxrWjexr5+6cQsHQV+I/EHQggULCACdOXOGiIhmzZpFAOjy5ctEpBgEqZKbm0vGxsbk5eWlsOz169fk4OBAenp69Oeff5JIJKIGDRpQVlaWRmUHQAYGBgpBWFZWFmlra5OLi4uQ9ujRIwJA1atXV2i3m5OTQ05OTgSAHj9+LKTLgqD8fSby7t/Q0JBSU1Pl0mU3SI6Ojgr7+ueffwgArV69WqNjZZr5Um5iivqDe+PGDZo1axbduHGD3r17R/Hx8bR7927hczpq1Ci1ttOzZ08CQFOnTpVLz83NpUqVKhEA+u+//+SWzZ8/X/ixnjFjhpA+ZcoUAkDdu3eXC8IePHhAJiYmBICqVq0ql66lpUXm5uZy36usrCzq2LGjsI+oqCiV5c/NzaWKFSsSAIqJiVGaZ/LkyXTkyBGKj4+n1NRUunz5MgUEBBAAsre3l+unJJOcnEytW7eWuzHR09OjyZMny/VnUSUwMJAA0MqVKwvNKzN+/HgCQP3795dLj4uLE/rSKHPo0CECQMOHD1dYdv36dbljkEgkNHfuXIV651NcC9mDryZNmsj1n0hKSiIHBwcCQDo6OnLr7Ny5k1avXk0PHjyg9+/fU2xsLC1evJjMzMxIJBKprHtL2pdSf7Di97FB0OLFi+W+c2XKlKGDBw8qzVuUuol93TgI+srkD4ISEhJIIpHQ999/T0RE1apVo3r16gn5lQVBoaGh5OPjQ5aWlqSlpSVXQeS9KcorMjJSyGtkZKT0qcgff/xBISEhcn95O9YCkCtbXmXLlqVKlSoJ///3338JAA0ZMkRp/u+//54A0J49e4Q0WRD0/Plzpeuo2n9MTAwBoI4dOyosCw8PV/mGjBWfL+Um5mN/cPN7/vw5WVlZkba2NsXHxxeYd9y4cQSAWrVqpfTN0YEDB0gikZBYLKZOnTrRzz//TD4+PgSAatWqRQBo1qxZQv6UlBSqXr06AaA6derQyJEjKSgoiIyNjal27doEgJycnOT2MWnSJAJAJiYmFBQURMHBwVSrVi0yMTERBiGQPXBR5vDhwwSAPD09NTtRRMLNxvz58+XSY2JiyMnJiVxdXenkyZP09u1bevLkCc2cOZO0tLTI3d29wDdtb968IX19fTI0NFT6FlyZZcuWCfVF/nU+JgiSyc7OptjYWJoxYwbp6OhQx44dFR4qlfS1yMrKEt62V65cmX766ScaPHgwlSlTRvh86Orqqtx+/n2JRCKqVauWWvmL25dSf7DiV1x1clpaGl29epUCAwNJLBbT3Llz1V5XVd3Evn48MMJXzsrKCu3bt8eWLVtw+PBh3LlzR+mACDLz589H586dcfnyZfj4+GD06NEICQlBSEgITExMVLYxd3FxEToqtm7dGo6Ojgp5Fi5ciClTpsj95Z83wtjYWOn2tbW15ea+kHVYLFOmjNL8tra2cvnyUrWOqv3L2vsXtCwrK0vlNhlTxcbGBn5+fsjOzi6wbfmkSZMwa9YsNGvWDDt37lTaid7X1xcnT55E69atcfToUfz5559ITk7Grl274OnpCQCwtrYW8hsZGSEyMhIjR47EmzdvsGTJEhw6dAg//PCDMORz3vwAMHXqVKxfvx7VqlXDli1bsGrVKpQrVw6RkZHC9yP/OnkVpd+NjGwQgvxzGPXr1w+PHj3C3r174eHhAUNDQ5QrVw7jxo3DsGHDcPr0aWzZskXldrds2YK0tDR0794dhoaGhZZj5cqVGDp0KGrVqoXw8HCFdWT9CPL2n8xLVicp628go6WlBQcHB4wfPx7Tp0/Hrl27FIbILulroa2tjf3792Py5MkQi8X4+++/sXPnTvj5+QkDZhS0/byaN28OR0dHXL9+nTubsy+Snp4eateujbVr16JVq1b45ZdfFPohq6KqbmKlBwdBX7ABAwYgJSUF/fr1g66uLnr37q00X3Z2NqZNmwZbW1vcuHEDGzduxOzZszF58mSEhIQgMzNT5T5+/vlnPHjwABYWFti2bZtCJ2Xgw0Su9OGtofBX1AnGZD/yqkZmk3XqVRa4iESiIu2TsZJgaWkJAHIjt+U1adIkTJ8+HV5eXti7d6/cSF35NWzYEP/99x9evXqF9PR0XLhwAf7+/rh+/ToAwNXVVS6/qakpFixYgNjYWGRmZuLp06eYPXs27t+/rzQ/APTp0wdnz55FWloaUlJSEBYWhsqVKyMmJgYWFhZKO9IDHwYd2bVrF0xNTdGlS5fCT0w+ys7T27dvERkZCWdnZ9jY2Cis4+3tDQC4fPmyyu2uXLkSgHqB2YoVK/D999+jevXqOHLkiNJBXwwMDGBra4vY2Filk5bGxMQAgNw8QQXx8fEBAKUjZJb0tZBKpQgJCcGdO3eQkZGBhIQE/PXXX8KAHso+H6rIrl9aWpra6zD2Ofj4+CA3NxcnT55UK39hdTj79nEQ9AXz9fVF2bJlERcXB39/f5iZmSnNl5SUhDdv3sDd3V3hCd+FCxfw/v17pevt27cPS5YsgaenJy5cuAAzMzMEBQWV6NDRssklT5w4oTCbOhEJQ9bmn4SSsS+N7A2Qssn2ZAGQp6cn9u3bB319fY23/+jRI5w6dQrVq1dHrVq11Fpn48aNAIAePXqolX/Hjh3IyMhA9+7dVebZsGED0tPT0bt3b5XD0xZE2XmSPZhRNQR2YmIigA8388pcv34d58+fR40aNdCoUaMC979ixQoMHjwYzs7OOHr0KKysrFTm9fT0RGpqqtInwwcPHgQANG3atMD9yTx79gzA/41EV5hPcS00/Xykpqbi5s2bMDAwEG4YGftSafqdK6gOZ6VEcbatY0WXv0+QzPnz52nXrl0Kk9vl7ROUk5NDenp65ODgIDc4wMuXL6lhw4ZC57+8ZH0azMzM6MmTJ0T0f5Ps+fr6KnToLQgKaJ+ubJIyWXv1/J2ZZSMnqRodTtP9y85pYGCgwjJNJ8FkRfOltOkvrP15YmIiRUdHU2Jiolz6hQsXlOaXjbJVpUoVhX4rsj4fTZo0oXfv3hVatrdv3yp8316/fk1NmjRROSDImzdvFNJkg6ko6wOnLP+tW7eoTJkyZGxsLNdJP786deoQALp06ZLKPNHR0QoDk8jSbWxsCABFRETILatWrRoBoBUrVsilv3r1Shh4Ijw8XOn+RowYQQBowYIFKstERLRixQoSiUTk7OxML168KDAvkeaTpV65coUyMzMVtpOcnEx169YlALRx40a5ZSV9LVTtY/v27SQWi8nNzU3uM5uSkkJ37txRyJ+WliYM6BEUFFTg/krKl1J/sOJX1Dr5/PnzSvNfvnyZjI2NSSKRyN0vFaVuYl8/deMW+UkS2BfH1dW10KYLYrEYQ4cOxfz581GnTh20b98eKSkp2L9/P+zt7WFnZyeXn4jQt29fYVLFcuXKAQC6dOmCAQMGYNWqVViwYAFGjx5dIse0bNkyeHh4YNCgQdi7dy+qV6+OmzdvYs+ePbCyslJ7skDGCrJy5UqcOnUKAIRmZStXrhSaJ3l4eAhNqZYsWYIpU6YgJCREmIQX+DA3lUQigaurK8qVK4fU1FScOXMGly9fhqmpKTZs2CDXz2ft2rWYNm0atLW10aBBA8ydO1ehXF5eXnLNSXfv3o0JEyagWbNmsLOzQ0JCAvbs2YPExERMmzZNYRJVAChbtiy8vb1RpUoViEQiHD9+HBcvXoSrq6vQZySv0aNH49KlS3Bzc4O5uTliYmKwd+9eiMVi7N69G+XLl1d6Di9evIirV6/CxcUF9erVU3mut2zZggULFqBp06awt7eHgYEB7t69i7CwMGRlZWH8+PEKb1D++OMPdOjQAYMGDcKWLVtQr149vHr1Sjj2zp07o0WLFgr7yszMxIYNG6Cjo4O+ffuqLNPRo0fx/fffg4jQtGlTpfVK3bp15eZd8/b2xsCBA7Fy5Uq4uLigbdu2eP78ObZu3Qpzc3MsXrxY4Rj+++8/NG7cGBUqVICenh4ePXqEffv2ITU1FV27dlWYj6ykrwXwoXll+fLl4ezsDF1dXZw7dw7Hjx9HpUqVsH37drnPbHJyMpycnODm5iY0T4yPj8fhw4fx9OlT1KpVS+nnmDFNFUed3KVLF2hra6N+/fqoUKECMjMzcefOHYSHh4OIsGjRIrk3O0Wpm1gpUpwRFSs6VW+CVMk/OlxmZib9/vvvVKVKFZJKpVShQgUaPXo0vX37VuFtzNy5cwkADRw4UGG77969o6pVq5KOjk6hTxtloOGbICKihw8fUlBQENna2pK2tjbZ2tpSUFAQPXz4UCEvvwn6en3OJ7my4ZNV/eX9XMjmScn/eZg1axZ5e3uTnZ0dSaVS0tPTIycnJwoODhbeoOalar6VvH/593HlyhVq164d2drakkQiIUtLS2rXrh0dPXpU5bH98MMPVK1aNdLX1ycDAwOqV68ezZ07l9LT05Xm37ZtG3l4eJC5uTlJJBIqX7489e/fv9A5MmRzbeWdp0iZ48ePU7du3ahKlSpkbGxM2traZGNjQ35+fiqHrSUiOnfuHHXt2lWoBwwNDcnNzY0WL16scmS4rVu3EgDq1q1bgWVas2ZNoddCWd2Qk5NDixYtoho1apBUKiULCwvq3r270nN1+PBhCggIoKpVq5KRkRFpa2tTmTJlqHXr1rRlyxal5Srpa0H04XNYq1YtMjIyIl1dXXJ2dqaJEycqfUP05s0b+vHHH8nNzU0Y8dDIyIgaNGhAc+bMUWuo8pLCb4K+LcVRJ//111/Uvn17qlChAunp6ZFUKiUHBwfq06eP0lEVi1o3sa+bunGLiChfxwwlLl26hPr16+PixYtwcXEpWrTFGCt1Nm7ciD59+nDdwRjTGNcfjLGiUDdu4YERGGOMMcYYY6UKB0GMMcYYY4yxUoWDIMYYY4wxxlipwkEQY4wxxhhjrFThIIgxxhhjjDFWqmg0T1BYWBiio6NLqiyMsW9MZGQkAK47GGOa4/qDMVYUsbGxauVTa4js06dPo0mTJsjJyfnogjHGShexWIzc3NzPXQzG2FeI6w/GWFFoaWnh5MmTcHd3V5lHrTdBUqkUOTk52LBhA5ydnYutgIyxb1tYWBgmTZrEdQdjTGNcfzDGiiI6Ohp9+vSBVCotMJ9GzeGcnZ15wjLGmNpkTVi47mCMaYrrD8ZYSeKBERhjjDHGGGOlCgdBxeDhw4cQiURyf/r6+rCzs0Pz5s3x22+/4f79+5+7mJ+NSCSCl5fX5y6G4Pjx4xCJRPjhhx8KzXvlyhVMmjQJjRo1grW1NaRSKSpVqoShQ4ciLi7uE5SWFUVcXBwWLlwIHx8fVKhQATo6OrCxsUHnzp1x9uxZtbdz9uxZBAYGombNmjA3N4euri4qV66M7t2748KFC0rXISLs3LkT3t7esLW1hb6+PqpVq4bBgwfjwYMHKvfj5+cHS0tLSKVSVKlSBb/99hvev3+vNP+rV68wZswYVK5cGVKpFFZWVujSpQtu3ryp8lg2bdqExo0bw9DQEAYGBnBzc8PatWuV5nVwcFCo0/L/nTx5UsgfExODGTNmoGnTprCzs4OOjg7Kly+Pvn374vbt2yrLlNfp06ehpaUFkUiEWbNmKT1Hn+JaxMTEICgoCFWqVIGenh7Kli2Lli1bYs+ePQp509LSMH/+fPTq1QtOTk4Qi8UQiUR4+PCh0m0nJyfj77//RocOHVCpUiVIpVJYWlqidevWOHjwoNLy79+/H0OGDEHt2rVhYmICfX191KlTBzNmzEB6errS/RR03fr166d0HeBDZ+JBgwbB3t4eUqkUZcqUgbe3N7Zv365yHcbUtWHDBgwePBiurq6QSqUQiUQq6yBVTp06hdGjR6N+/fqwsLCArq4unJyc8Msvv+D169dK1ymoPvuS7k3Yp6dRczhWMEdHR/Tp0wcAkJGRgYSEBJw7dw7Tpk3DjBkzMHbsWPz+++8QiUSfuaRMXT/88APOnj2LBg0aoEePHpBKpTh79iyWLVuG7du34+TJk3BycvrcxWT5LF68GLNnz4ajoyN8fHxgZWWFmJgY7N69G7t378amTZvQvXv3Qrdz8uRJhIeHo1GjRmjWrBn09fXx4MED7NmzB9u3b8e6desQEBAgt86YMWOwYMEC2Nrawt/fH8bGxrh69SpWrFiBzZs3IyoqCjVr1hTy79y5E927d4eWlhY6d+4MGxsbREZGYtq0aTh69CiOHDki1645OTkZ7u7uiImJgbu7O/z8/PD8+XOEhoZi//79OHr0KBo2bChXptGjR2PBggWwsbFB7969IZFIEBYWhqCgINy4cQPz5s2Tyx8cHKz0hiIpKQlLly6FmZkZ3NzchPRJkyZh69atqFmzJvz8/GBsbIzr169j/fr12LFjBw4cOICmTZuqPM9paWkIDAyEnp4eUlNTP9u1OHv2LLy9vZGVlYUOHTqgc+fOSEhIwM6dO+Hn54fJkycjJCREyJ+QkIAxY8YAAOzt7WFmZoaXL1+qPM7t27djyJAhwgOysmXL4unTpwgNDcWBAwcwZ84c/Pzzz0L+jIwMtGnTBlKpFF5eXvD19UV6ejoOHjyIX3/9Fbt378bx48ehr6+vsC97e3ulAU/dunWVli08PBz+/v4AgPbt26NSpUp49eoVrl27hsOHD6Nr164qj4sxdUycOBGPHj2CpaUlbG1t8ejRI4230aVLFyQlJcHDwwN9+/aFSCTC8ePHMWfOHOzYsQNRUVEoU6aMwnomJiYIDg5WSHdwcCjCkbBvBqnh4sWLBIAuXryoTvZSJzY2lgCQr6+v0uUnT54kBwcHAkATJ078xKX7/ACQp6dnsWwrJCSEAFBsbGyRt3Hs2DECQIMHDy40759//kkxMTEK6bNmzSIA1KZNmyKXozTYsGHDZ6k7QkND6fjx4wrpJ06cIIlEQmZmZpSenl7odt6/f680/fr166Srq0vW1taUm5srpD9//pzEYjHZ29vT69ev5dZZsGABAaCgoCAhLS0tjaysrEgikdCFCxeE9NzcXPrxxx8JAM2cOVNuO7L0UaNGyaVHRUWRlpYWVa9enXJycoT08+fPEwCqXLkyJScnC+nv3r0jNzc3AkBRUVGFngsionnz5hEAGjZsmFz6mjVr6NKlSwr5N2/eTACoevXqBW73p59+IhMTE5o+fbrSYyYq+WtBRNS6dWsCQLt375ZLf/jwIRkZGZGenp7c5+bt27d06NAh4bz6+voWWD8dOXKE9uzZI3d9iIhu375NJiYmJJFIKC4uTkjPzMyk6dOn08uXL+XyZ2ZmUvv27QkAzZkzR2E/mta5jx49ImNjY6pSpQo9evRIYXlWVpba2ypOn6v+YCUjPDycHj58SEREM2fOJAC0Zs0ajbYxa9Ysue8I0Yf6csiQIQSAhg4dqrCOvb092dvbF7XY7CukbtzCQVAxKCwIIvrwIyeVSklHR4ceP34spK9Zs0aoCPbs2UPfffcdGRoayn1hExMTacSIEeTg4EA6OjpkZWVFXbt2pevXryvsJzAwkADQ/fv3afbs2VS5cmWSSqXk4OBAU6ZMoczMTKXlW716NTVo0IAMDAzIwMCAGjRooLRyylve/GTBRUhIiNz/lf1pWvHJfOogSJXs7GzS09MjAwODIm+jNPgSb2J8fHwIAJ0/f/6jtlOvXj0CIHeDffr0aQJAvXr1Ush/9+5dAkDt2rUT0g4fPkwAqGvXrgr5X716RQDI3t5e7ua+XLlyJBaL6e3btwrr+Pv7EwA6evSokDZx4kQCQEuXLlXIv3v3bgJAffv2VeuYnZ2dCQBduXJFrfxERFWrViUAlJiYqHT50aNHSSQS0apVq4T6RVkQVJDiuBZERNWqVSORSEQZGRkK63z33XcEgJKSklSWo7AgqCDff/89AaDt27erlT8qKooAUNu2bRWWaRoEDR48mADQkSNH1F7nU/gS6w9WPIoaBKny7NkzAkA1atRQWMZBUOmjbtzCzeE+kWrVqqFbt25Yv349du/ejWHDhskt3759Ow4dOoR27dph6NChSElJAQAkJibC3d0d9+/fh5eXF3r06IHY2Fjs2LED+/btw8GDB+Hh4aGwv+DgYERGRqJbt24wNDTE3r17ERISgmvXrmHHjh1yeYcPH47FixejbNmyGDBgAAAgNDQUQUFBuHz5MhYtWlSkY3ZwcEBISAimTJmi0DRDVZOMr4VIJIJEIuGmjV8hiUQCANDWLnr1d//+fdy5cwfly5eHiYmJkF6lShXo6OggMjISKSkpMDY2Fpb9999/AIDmzZsLaS9evAAAVKxYUWEfpqamMDMzw6NHj/DgwQM4OjoK61haWsLQ0FBhHdl2jh49Cm9v70L3kTd/YaKiohAdHQ1XV1fUqVOn0PwyBZ3vt2/fIigoCD4+Pujfv7/G/QOA4rsWAFCzZk3cuXMH+/fvh5+fn5D++PFjXL9+HXXq1IGFhYXGZVSHpp/LwvK/fv0af//9N5KSkmBubo7GjRujVq1aCvmICNu3b4eFhQWaNWuGixcvIiIiArm5uahbty6aNWsGsZi7D7MvW2Hfh4yMDKxduxbPnj2DsbEx3NzcFJoNs9KHg6BPyMvLC+vXr8f58+cVlh04cAAHDx5EixYt5NJ/+eUX3L9/H+PHj8eMGTOE9LCwMLRt2xZBQUG4c+eOwo/UmTNncPXqVZQrVw4A8Pvvv6Nly5YIDQ1FaGgoOnfuDAA4ceIEFi9eDGdnZ5w+fVq4iZg8eTIaNWqEP//8E126dEGTJk00Pl4HBwdMnjwZU6ZMEf79rdixYwdSUlK4nfxX5vHjxzh8+DBsbW2V3hCqcu7cOYSFhSErKwuPHj0SOskvX75cLp+FhQVmzZqF0aNHw8nJSegfc/XqVRw9ehRDhw7FTz/9JOS3tLQEoHx26zdv3uDVq1cAgLt37wpBkKWlJRISEvDu3TuFQEi2nbt376q1D1na06dPkZaWprRvicyqVasAAAMHDlSZJ79z587h5s2bcHNzg6mpqcLykSNH4tWrV1ixYoVG2yyJawEA06dPR2RkJLp06YIOHTqgatWqQp8gR0dHbN26Ve1yaiIlJQU7duyArq6u2nXt6tWrAQA+Pj5Kl1+9ehWDBw+WS2vVqhXWrVsHa2trIS02NhYvX76Eq6srBg8ejL///ltunXr16mHPnj3CbwljX6LCvg8vXrxAUFCQXJqbmxs2b94s1K2sFCrO10qllTrN4YiI9u/fTwCodevWQpqs+UfHjh0V8mdkZJCuri5ZWFhQamqqwvKWLVsSADpx4oSQJmsON336dIX8J0+eVGgC0r9/fwJAW7duVci/ceNGAkD9+/dXKK86zeFk8BX3CVLm8ePHVKZMGdLT06Pbt28XuRylwZfUnCUzM5OaNm1KAOiff/7RaN3FixfLNecsU6YMHTx4UGX+rVu3kpGRkdw6Hh4edOrUKbl8b9++JWNjY5JIJAp9aoYPHy6su2nTJiE9KCiIANCYMWPk8p85c4a0tbUJAPn4+AjpERERBICqVKlCr169EtJTU1OpYcOGwj6ePXum8njevn1LhoaGpK+vT2/evCnwXMm8fv2anJycSCwW07FjxxSWh4WFEQD666+/hDR1msOV1LWQefjwodBXSvZnYWFBixYtouzs7AKPuajN4Xr27EkAaOrUqWrlDwsLI7FYTM7Ozkr7to0ePZqioqIoKSmJUlJSKCoqSujv5ObmJnccsmaDWlpaZGhoSGvWrKGXL19SbGwsDRo0iABQw4YNNTqe4vIl1R+seBVnc7jLly+Tvr4+WVtbK212O3nyZDpy5AjFx8dTamoqXb58mQICAoTmxikpKR9dBvZl4T5Bn1BxBEHKfvSvXr2qkD+vGTNmEAD6888/hTRZEBQREaGQPzs7m7S1tals2bJCmqwtfXx8vEJ+WRtbFxcXhfJ+iiDI09NTZZ8iZX/596vKxwRBSUlJVLNmTRKJRLR+/XqN1y9tvpSbmJycHOrVqxcBoEGDBhV5O2lpaXT16lUKDAwksVhMc+fOVcgzZcoUkkgkNHPmTHry5Am9ffuWTp48Sa6urqStrU3//vuvXP6VK1cSAJJKpdS7d28aPXo0ubu7k46ODjk5OREA2rJli5D/yZMnZGtrSwCocePGNHr0aOrVqxfp6OhQ7dq1CQC1atVKbh+yH3xbW1saPHgw/fTTT1SpUiWqUKECmZiYEAB68eKFyuOWlTEwMFDt8+Tt7U0A6Pfff1dY/vLlS7Kzs6PmzZvLpWvSJ6gkrsXZs2fJ1taWfHx86OLFi5Samkr379+nkSNHquy7lVdRgqBx48YJ16ywIIuI6Ny5c2RkZERmZmZ048YNtfeTk5Mj1KmhoaFCemRkpFCH/vHHHwrryQLlkydPqr2v4vKl1B+s+BVXEHT//n2ys7MjqVQq1xdSHbJ6cf78+R9VBvbl4T5BX6Bnz54BAKysrBSWKRvSUdYvSNkyALC1tZXLV9j2tLS0YGFhgTdv3sjtQywWqyyTSCRSuv1PoV+/fgpj+B8/fhwREREYMWKEQvOakh7vPzk5Gc2bN8fNmzexbNkyYTh09mXLzc1F//79sWnTJvTp00eh2ZQm9PT0ULt2baxduxaJiYn45Zdf0KpVK2GY5cOHDyMkJAQjR47EuHHjhPU8PDywd+9eVKpUCaNHj0aHDh2EZQMGDICdnR3mzJmDf//9Fzk5OXBzc8ORI0cwe/Zs3L59W675Urly5XD+/HmEhIRg//79OHfuHMqXL4+pU6fCwcEBPXr0kMsPAGvXroWrqytWrVqFtWvXQk9PD76+vpgzZw5q1KgBbW1tmJubqzxuTZrCpaenw8/PD8eOHcP48eMxYcIEhTyjRo3CmzdvsHLlykK3p0pxX4usrCz06NEDYrEYu3btEpoGVqpUCQsWLEBsbCy2b9+OyMhING7cuMjlzmvSpEmYNWsWmjVrhp07d0JLS6vA/BcuXICPjw/EYjEOHjyIGjVqqL0vsViMQYMGISIiApGRkejUqRMAyPWjyvu5lGnfvj3Onj2LCxcuKO1/ytjnEhsbC29vbyQlJSE0NFToB6muwYMHY/369YiMjMSoUaNKqJTsS8ZB0Cd0/PhxAJCbX0NGWQd7WUfe+Ph4pduTdXjO2+FXJj4+HtWqVZNLy8nJQXJyslyAZGxsjNzcXCQmJircOCUkJICI5LYv63uUnZ2tsM+8wVVxUDbHxeTJkxEREYHg4OBPOr6/LAC6evUqli5dqtDWnn2ZcnNzERQUhH/++Qc9e/bE2rVri62Tt4+PD8LCwnDy5Enhxnv//v0AoPTH2MbGBk5OTrh8+bJCf57WrVujdevWCusEBARALBbDxcVFLr1s2bJKAwhZvztXV1e5dLFYjOHDh2P48OFy6Q8fPsS7d+/g4uIidCzO79atWzh9+jScnJwKvQl+//49/Pz8EB4ejrFjx8r1Y8zr8uXLSE1NVTpYAwCMHz8e48ePx4gRI7Bw4cIC9wkUz7W4ffs2YmNj0alTJ6V9o7y9vbF7925cvny5WIKgSZMmYfr06fDy8sLevXuhp6dXYP4LFy6gZcuWyM3NxaFDh5T+jhRG1j8s71xMjo6O0NLSQk5OjtJ+W7I0VRP3MvY5PHjwAN7e3nj+/Dm2b9+Odu3aabwNZd8HVrpwEPSJ3L17F9u2bYNUKkXHjh3VWsfJyQm6uro4f/680k7LsqBK2UhrJ0+eVJic8PTp08jOzka9evWEtHr16uHy5cs4fvw4unXrVuj2zczMAABxcXEK+7x8+bLS4xCLxcjJyVG67GuQNwBavHgxhg4d+rmLxNSQNwDq3r071q9fX+iTdk3I3uzmDR4yMzMBfBjVUZnExESIxWKVAUdekZGRePjwIdq0aSP3tF6VnJwcbNmyBdra2sLAJ4XZuHEjAKBHjx4q88jeAslGjlQlbwA0ZswYzJ49W2XeTp06KQRqABATE4MTJ07Azc0NtWvXhru7uzqHUSzXQp38AOQmri0qWQDk6emJffv2FTggBfB/AVBOTg4OHjxY5FGtzp49C0B+gkhdXV189913OHnyJG7duqUQ6N66dUthHcY+p7wB0NatW+VGctSEsu8DK2WKs21daVVYn6BTp04Jk6Xm77dSUB8bov/rBJ1/klVZ/6LKlSvLTbwn6xNkZWVFT548EdIzMjKETuE7duwQ0mWdpqtXry7X4VnWqRn5+hfFxcWRSCQiJycnuckL7969S6ampkqP0dLSkhwcHJQen6Y+9cAIycnJVLduXQJAixYtKvI+S6vP1aY/JydH+C507dq10MkeExMTKTo6WqFTraq5hC5fviwMaJD3syibHLRGjRoKE3QuW7ZM6MeTl7KBBuLi4sjJyYm0tbUVzl1mZialpaUpHG9wcDABoJEjRypsT9k+Tpw4QQYGBgV2DM7MzBQmc1XWb1Dm/fv3wkAt+Sdx1URBfYJK+lqkp6eTsbExicVihYEWHj9+TFZWViQSiejOnTsqy69On6BJkyYRAGrSpAm9e/dOZT6ZCxcukKmpKRkaGqoczCGva9euKZ0PLjIykvT19UkikdC9e/fklm3atIkAUPPmzeUGWoiOjiZ9fX0yMjJSmLD1U+A+Qd+uwvoEqaqTHzx4QBUqVCBtbW25vm2qREdHKx1YKjo6mmxsbFT2oWZfN+4T9Bncu3dPaI6SmZmJhIQEnDt3DtevX4eWlhYmTpyIkJAQjbY5e/ZsREREYPr06YiKikLDhg3x8OFDbN++Hfr6+lizZo3S5j2NGjVCnTp10L17dxgYGGDv3r24c+cOOnXqJPeUuGnTphg2bBgWL16MmjVronPnziAihIaG4unTpxg+fLjcGyU7Ozv07NkTmzZtQv369dGqVSskJCRg165daNWqFUJDQxXK0qxZM2zbtg3+/v6oV68etLS00KFDB9SuXVujc1Hcjh07prTJHfCh38DAgQPRqVMnXLlyBU5OTnj58qXSYb6Dg4OVNiNhn8/UqVOxbt06GBoaomrVqpg+fbpCHn9/f+Et55IlSzBlyhSEhITIXeMuXbpAW1sb9evXR4UKFZCZmYk7d+4gPDwcRIRFixbJPUXs2rUrli1bhhMnTqBq1aro0KEDTE1NcenSJRw9ehR6enpYsGCBXDn+/PNPbNiwAR4eHrC2tsaTJ0/w77//Ii0tDatWrVJoChcfH48aNWrAx8cHFStWRGZmJg4ePIjbt2+jbdu2mDlzpsKxdunSBe/fv0ft2rVhbGyM69evY//+/TA3N8fu3bthZGSk9Dzu2bMHiYmJ6NSpk0Jz2bx++OEHhIeHw8bGBkZGRkq/J/369fuoJ64lfS2kUinmzp2LwYMHo3Xr1mjXrh2cnJzw4sUL7Ny5E+/evcPo0aNRtWpVuXKNGTMGSUlJAIDr168LabLmjgMHDhTerqxduxbTpk2DtrY2GjRogLlz5yocp5eXl9C/8eXLl2jZsiVev36NVq1aITw8HOHh4XL5TU1NERwcLPx//vz52LdvHzw8PFC+fHlIJBLcvHkThw4dgkgkwtKlSxWGBO7Rowd27tyJHTt2oE6dOvD19cWbN28QGhqK9PR0/PPPP0IrAMaKauXKlTh16hSA//uurFy5Umh1IvvdBVTXyd7e3nj8+DEaNWqEa9eu4dq1awr7yZt/y5YtWLBgAZo2bQp7e3sYGBjg7t27wjD748ePV2g1w0qR4oyoSivZm6C8f3p6emRra0ve3t40adIkhSdvMoW9CSL68ERk+PDhZG9vTxKJhCwtLalLly50/fp1hbyyp9/379+nWbNmUeXKlUlHR4fs7e1p8uTJSmdCJyJavXo1ubm5kb6+Punr65ObmxutXr1aad60tDQaPnw4lSlThqRSKdWuXZs2btyocnS458+fU7du3cjS0pLEYvFHjQhTnG+CCvqTjYJlb29faN6PKcu37nM9yZV9Dwr6y/sZlH2u8n92//rrL2rfvj1VqFCB9PT0SCqVkoODA/Xp04fOnDmjdN/p6ek0c+ZMqlevHunr6wsjMvbp04du3bqlkP/IkSPUokULsra2JolEQjY2NtS9e3eFIbNlUlJSKCAggCpVqkS6urpkZGRE7u7utGLFCrm3wnktXbqU3NzcyMTEhHR0dMjR0ZFGjBhR4IhwRCQMqxwWFlZgPnVGclQ2THZ+Bb0J+hTXgojo0KFD1LZtW7K0tCQtLS0yMTGhpk2b0oYNG5TmL6yOUPY5K+gv72dQ2W9L/j97e3u58uzcuZP8/PyoYsWKZGBgQBKJhMqXL089e/aks2fPqjz3WVlZtGDBAqpRowZJpVIyNjYmHx8fOn78uMp1Shq/Cfq2FFYv5x19UlWdXNj3If9t7fHjx6lbt25UpUoVMjY2Jm1tbbKxsSE/P78Ch9ZnXzd14xYREVFhgdKlS5dQv359XLx4UeGpJPuy9OvXD+vWrUNsbCy3c2Wf3caNG9GnTx+uOxhjGuP6gzFWFOrGLcUzTBJjjDHGGGOMfSU4CGKMMcYYY4yVKhwEMcYYY4wxxkoVDoK+MWvXrgURcX8gxhhjjDHGVOAgiDHGGGOMMVaqaDRPUFhYGKKjo0uqLIyxb0xkZCQArjsYY5rj+oMxVhSxsbFq5VNriOzTp0+jSZMmyMnJ+eiCMcZKF7FYjNzc3M9dDMbYV4jrD8ZYUWhpaeHkyZNwd3dXmUetN0FSqRQ5OTnYsGEDnJ2di62AjLFvW1hYGCZNmsR1B2NMY1x/MMaKIjo6Gn369IFUKi0wn0bN4ZydnXnCMsaY2mRNWLjuYIxpiusPxlhJ4oERGGOMMcYYY6XKVxcEPXz4ECKRSO5PX18fdnZ2aN68OX777Tfcv3//cxfzsxGJRPDy8vrcxRAcP35cuE6urq4q8+3fv1/I9yWVn317NmzYgMGDB8PV1RVSqRQikQhr1679qG1mZmaibt26EIlEcHJyKrb9nj17Fn5+frC0tIRUKkWVKlXw22+/4f3790rzv3r1CmPGjEHlypUhlUphZWWFLl264ObNmyr3sWnTJjRu3BiGhoYwMDCAm5ubynI5ODgo1L/5/06ePCnkj4mJwYwZM9C0aVPY2dlBR0cH5cuXR9++fXH79m2l+zhx4gTGjBkDb29vmJiYQCQSoV+/firLn7eOUfaX/1iSk5Px999/o0OHDqhUqRKkUiksLS3RunVrHDx4sFiOW+bgwYPw9PSEkZERjI2N4e3tjSNHjqg8Fk2uBfDhTUnv3r1hY2MDqVQKe3t7jBgxAi9fvlS5Tm5uLlavXg0PDw+YmppCX18fVatWRVBQEN6+fatyPcaKQ3HVv7m5uVi8eDFq1aoFPT09WFlZoWfPnnjw4IHS/AV9dwuqX9i3TaPmcF8SR0dH9OnTBwCQkZGBhIQEnDt3DtOmTcOMGTMwduxY/P777xCJRJ+5pAwAtLW1cfHiRVy7dg21a9dWWL5q1Spoa2sjOzv7M5SOlSYTJ07Eo0ePYGlpCVtbWzx69OijtzllyhTcu3evWPe7c+dOdO/eHVpaWujcuTNsbGwQGRmJadOm4ejRozhy5Ihce+fk5GS4u7sjJiYG7u7u8PPzw/PnzxEaGor9+/fj6NGjaNiwodw+Ro8ejQULFsDGxga9e/eGRCJBWFgYgoKCcOPGDcybN08uf3BwMF6/fq1Q1qSkJCxduhRmZmZwc3MT0idNmoStW7eiZs2a8PPzg7GxMa5fv47169djx44dOHDgAJo2bSq3rdWrV2PdunXQ19dHhQoVkJKSUuB5kvH09FT6AKVu3bpy/9++fTuGDBkiPDgrW7Ysnj59itDQUBw4cABz5szBzz///FHHDXy42QsICICVlZVwk7V161a0bNkS27ZtQ5cuXeTya3otzpw5gxYtWuD9+/fw8/ODo6Mjrly5gj///BMHDhxAVFQULCws5NbJyMhAly5d8N9//6F27dro168fpFIpHj9+jLCwMEybNg1GRkYFnGXGPk5x1b+DBw/GypUrUaNGDQwfPhzPnj3Dtm3bcOjQIZw5cwZVqlRRWMfe3l5pwJO/jmClCKnh4sWLBIAuXryoTvYSFRsbSwDI19dX6fKTJ0+Sg4MDAaCJEyd+4tJ9fgDI09OzWLYVEhJCACg2NrbI2zh27BgBoLZt25JYLKYRI0Yo5ElMTCQdHR3q0KFDsZaffX4bNmz4YuoOmfDwcHr48CEREc2cOZMA0Jo1a4q8vbNnz5KWlhYtWbKEAFC1atU+er9paWlkZWVFEomELly4IKTn5ubSjz/+SABo5syZcuvI0keNGiWXHhUVRVpaWlS9enXKyckR0s+fP08AqHLlypScnCykv3v3jtzc3AgARUVFqXUO5s2bRwBo2LBhculr1qyhS5cuKeTfvHkzAaDq1asrLDt//jzduHGDsrOz6fTp0wSAAgMDVe5bVseEhISoVdYjR47Qnj175M4FEdHt27fJxMSEJBIJxcXFqbUtVcf98uVLMjU1JUtLS3ry5ImQ/uTJE7K0tCRLS0tKSUkR0otyLWrWrEkA6N9//5VLnzNnDgGgwYMHK5Q3ODiYANCsWbMUluXk5Cick8/tS6w/2Mcpjvr36NGjBICaNm1KGRkZQnpYWBgBIB8fH4V1+N6idFE3bvnqmsMVxsPDAwcOHIBUKsWcOXPw5MkTYdnatWuFV6979+5F48aNYWRkBAcHByFPUlISgoODUbFiRUilUlhbW6Nbt264ceOGwr769esHkUiEBw8eYM6cOahSpQp0dXVRsWJFTJ06FVlZWUrLuGbNGjRs2BCGhoYwNDREw4YNlb4Ozlve/GRNQCZPniz3fwCIiIgosDnI51CuXDm0bNkSGzduRGZmptyyDRs2IDMzE/3791e67t27dzF27Fi4uLjAwsICurq6qFq1KsaNG4d3797J5Y2MjIS2tjbq1q2LjIwMtZcpI2t62a9fP9y7dw8dO3aEmZkZDAwM0KJFC1y9elXpejdu3EC3bt1gbW0NqVSKihUrIjg4GMnJyQp5HRwc4ODggNevX+Onn35C+fLloa2tjbVr18rtPzo6Gu3atYOpqSnMzMzQs2dPJCUlAfgwhH3z5s1hbGwMMzMzDBw4EKmpqYUeX2nVokUL2NvbF8u20tPTERgYCA8PDwwdOrTY9hsVFYXExET4+/ujfv36QrpIJML06dMBAMuXLwflmeHg33//hVgsxpQpU+S25e7ujvbt2+PWrVuIiIiQyw8AI0eOhLm5uZBuYGCAX3/9VdiHOlatWgUAGDBggFx6v379UK9ePYX8PXr0QNWqVXHr1i3hcyzj6uqKGjVqQEtLS619a6pZs2Zo3749xGL5n79q1aqhe/fuyMrKQlRUlFrbUnXc27dvx+vXrzFs2DCUK1dOSC9Xrhx++uknJCUlYdeuXUK6ptfi/v37uHHjBtzc3NChQwe5fY8ePRoWFhZYv369XD0QFxeHJUuWoEmTJvjll18UjkUsFiucE8aKW3HUvytWrAAATJs2DTo6OkJ669at4eXlhUOHDuHx48cftQ9WOnyTNV61atXQrVs3ZGZmYvfu3QrLt2/fjk6dOsHa2hpDhw5F69atAQCJiYlo1KgRFi1aBAcHB4waNQrNmjXDzp070bBhQ5w6dUrp/oKDgzF79my0aNECw4YNg1QqRUhICHr27KmQd/jw4ejfvz/i4uIwYMAADBgwAHFxcQgKCsKIESOKfMwODg4ICQkB8OGVb0hIiPD3pbzq7d+/P5KSkrB371659NWrV6NGjRoKTXVkdu7ciVWrVqFSpUoIDAzEDz/8AHNzc8yePRstW7aUCzYbN26MiRMn4urVq3I/9K9fv0bv3r0hlUqxefPmQodNzOvhw4do1KgRXr58if79+6Nly5Y4cuQIvL29ER8fL5f31KlTaNiwIXbt2oXmzZtj1KhRsLe3x6JFi9CwYUOFGz7gQxOVZs2a4dChQ+jQoQN+/PFHlClTRlgeGxuL7777DhkZGRg4cCDq1KmDLVu2wN/fH6dOnULz5s1haGiI77//Ho6Ojli1ahWGDRum9vGxopswYQIeP36MVatWFWvT2xcvXgAAKlasqLBMFgg/evRIrv37ixcvYGlpCUNDQ4V1ZNs5evSoWvtQll+VqKgoREdHw9XVFXXq1Ck0v4xEIgHwoalscYiJicHChQsxc+ZMrF+/HnFxcRpvQ5MyFXTcx48fBwD4+PgorOfr6wsAcgGppteioPxisRgVKlRAWloazpw5I6Tv2LED2dnZ6Nq1K96+fYuNGzdi5syZWL16dZHOFWOfy/Hjx2FgYIDGjRsrLFP2/ZJ5/fo1/v77b8yYMQPLly/H9evXS7ys7AtXnK+VPoXCmsPJrFq1igBQQECAkLZmzRoCQGKxmMLDwxXWCQoKIgA0fvx4ufR9+/YJTRXyNhcIDAwkAGRlZSXX5CEjI4OaNm1KAGjHjh1CekREBAEgZ2dnev36tZD+8uVLqlq1KgGgEydOKJRX2atiVU1A8IU2hxs8eDBlZGSQhYUFtWnTRlh+7tw5AkDz58+n58+fKy3/06dP5V55y0yZMoUA0IYNG+TSs7OzqXHjxiQSiSgsLIyIiLp160YA6K+//lK77LLPGpQ0H5k4caJCk6ScnBxydHQkAHTgwAG5/D///DMBoP79+8ul29vbC5/ntLQ0lftfuHChkJ6bm0tt2rQhAGRqakq7d+8WlmVmZlLt2rVJW1ubXrx4ofaxlpQvvTnLxzSHi4iIILFYLHdtUEBzOE32e+DAAQJAXbt2VVj2+vVr4XMh+3wTEdnY2JBYLKa3b98qrOPv708AqFu3bkLauHHjCAAtXbpUIf/u3buFfaSmphZ4LP379ycAtHz58gLz5XX27FkCQG5ubgXm06Q5XP4/bW1tGjlyJGVnZ6tVpjdv3lCZMmVIV1eXkpKSCs1f0HG7uroSAKXbSUpKIgDUpEkTIU3Ta3H79m2V5y8nJ4csLCwIAP3vf/8T0gMCAggATZ06lWxtbeXOlY6ODi1YsKDQY/7UvvT6g32cotS/7969IwBUs2ZNpct37NhBAGjSpEly6crqCADUqlUrio+P/5jDYF+gUtscTsbOzg4AlD559/PzQ4sWLeTSMjMzsXnzZlhYWGDixIlyy9q0aYOWLVvi3r17iIyMVNjeiBEj5Jo86Ojo4PfffwcAuaZo69atAwBMnjwZJiYmQrqZmZnwFudLaLpWUnR0dNC7d28cPHgQz549A/DhLZBEIkFAQIDK9cqWLSv3ylvmp59+AgAcPnxYLl1LSwsbN26EiYkJ+vXrh5kzZ2Lbtm3o1KkTvv/+e43LXbFiRYWO0rLmL+fPnxfSIiMjcf/+fbRu3Vp4GiXz22+/wdzcHJs2bVJoDggAc+bMgZ6entL9Ozo6Yvjw4cL/RSIRevToAQCoV68e/Pz8hGUSiQRdunRBdnY2bt26peGRMnWlpqYiKCgI7u7uJfLWrXHjxjA2Nsbu3btx+fJluWW//fab8O+8nfVbt26N3NxcheZwZ8+exX///ac0PwAsXLhQLj0tLQ0zZ84U/v/mzRuV5Xz37h22bdsGfX19pW++lXnz5g0CAwMhFosxZ84ctdYpiJWVFWbNmoUbN27g3bt3iI+Px+7du1G5cmX88ccfGDt2rFrb+eGHHxAfH48JEyYoDCiQX2HHLTtneet5GWNjY7k8gObXomrVqqhUqRLOnz+Pffv2yW1/4cKFQtPbvNtKSEgA8GEQjzp16uDmzZtISUnBf//9B0tLS4waNQr79+8v8LgZ+9wK+m4Byr9fwIdmolFRUUhKSkJKSgqioqLQunVrHDhwAO3atUNOTk7JFpx9kb7ZIKggDRo0UEi7ffs20tPT0aBBA+jr6yss9/b2BgBcuXJFYVmTJk0U0tzd3aGtrS13AyP7t7IRjAra/qfg5eWlMGyk7GaqYsWKCstkfZE01b9/f+Tk5GDdunVIT0/Hli1b0K5dO1hZWalch4iwevVqNG3aFObm5tDS0oJIJBJuVGQBVV729vZYvnw5EhISMGHCBJQrV05oR5zX5MmTFf7yjwJVt25dhbbysqA3b96Crq+hoSFcXV2Rnp6OO3fuyC3T1dVFrVq1VB5/7dq1FZpa2draCmXLT7ZM2XlhxWPMmDF49uwZVq9eXSL9KAwNDbFgwQJkZWXB3d0dffr0wZgxY/Ddd99h+fLlwjDcefc9depU2NraYt68efDw8MCYMWPQu3dvNG3aFNWrV1fI37RpUwQEBCAmJgbVq1fHDz/8gGHDhqFWrVp4/vy5cJNR0PFt3boV7969Q9euXYWbj4K8f/8eHTt2xO3btzFt2rRiGQ6/Ro0a+OWXX1CjRg0YGBjA2toafn5+OHbsGKysrPDnn38KAYAq48ePx+bNm9GqVStMmDCh0H1qetyF0fRaiEQi/O9//4NEIkGHDh3QuXNnjB07Fr6+vhg9erRQn+S9drm5uQAAa2trhIaGonr16jAyMkLbtm2xcuVKAMD8+fM/+lgY+xLNmzcP7u7usLCwgJGREdzd3fHff//B09MT58+fF/rlsdLlqx0iuzCyG0BlN9d5+1vIyIZhVbYM+L8bS2XDtSpbR0tLCxYWFnJPI1JSUiAWi1WWSSQSqT0cbHHr16+fwg3J8ePHERERgREjRsDU1FRuWVFvXurUqQMXFxesWbMGFSpUwOvXr1UOiCAzfPhwLFmyBOXLl0eHDh1ga2sr9OmZMmWKykEOZIMFpKSkoFevXnIdjmXyPzUHPpyLvMer7CZH1mcg79Ojon6GrK2tC+xPUtD+C1qmamAO9nGOHz+O5cuXY+7cuahatWqJ7WfAgAGws7PDnDlz8O+//yInJwdubm44cuQIZs+ejdu3b8Pa2lrIX65cOZw/fx4hISHYv38/zp07h/Lly2Pq1KlwcHBAjx495PIDH948u7q6YtWqVVi7di309PTg6+uLOXPmoEaNGtDW1lb6vZGRDQwwcODAQo8nPT1dCE7Gjx+vVrDxMWxsbODn54eVK1fi7NmzaN++vdJ8kyZNwqxZs4T+n+oMyFDYccuCljdv3ii8VZJ9//M/ydb0Wvj6+uLkyZPCkOn79u1DzZo1sWvXLhw5cgTXr1+Xu96y/bVo0ULhQZ+vry+kUikuXLhQ6LEz9jnl/W4po+r7pYxYLMagQYMQERGByMhIdOrUqfgKyr4K32wQJOuYmn/uBgBKbzhlN5P5O7rLyDqiKrvpjI+PR7Vq1eTScnJykJycLHdDbGxsjNzcXCQmJircjCQkJICI5LYve4qnbO6cgpqoFIWysfMnT56MiIgIBAcHy42g97EGDBiAH3/8Eb/88gvs7OyEpiDKJCQkYOnSpahduzZOnz4t9+P94sULpUGMTP/+/ZGSkgILCwssXLgQPXv2VHhzQnlG1/pYRf0M8VxWXxfZ29qff/5ZoZkkANy5cwcikQgmJiZK55bRROvWrZV+PwICAiAWi+Hi4iKXXrZsWeGpfl6yN7f5JywWi8UYPny4XHNL4MNgIO/evYOLi4swWEB+t27dwunTp+Hk5AQPD48Cj0M2l014eDjGjh2LGTNmFJi/uFhaWgKAytESJ02ahOnTp8PLywt79+5V2SQ1L3WOu0qVKrhw4QJiYmIUgqCYmBghT15FuRYNGzYUmjrmtXDhQgDy11v2G5X/gZZs30ZGRp/tIRxj6jIwMICtrS1iY2ORk5Oj8NBC1fdLlcLqCPZt+yabw929exfbtm2DVCpFx44d1VrHyckJurq6OH/+PNLS0hSWy4IqZc2PlM0Ufvr0aWRnZ8sNDyv7t2xbhW3fzMwMAJSO3JO/n4CMWCz+4tu29urVC7q6uoiLi0Pfvn0LfPL64MEDEJHSp5fKzrvM0qVLsXfvXvTp0weHDh0CAPTs2VPptS0uBV3f1NRUXLhwAXp6egoBM/u61KxZUxjZMf8f8OEJ5IABA9C3b98S2X9kZCQePnyIVq1aqfW0MycnB1u2bIG2tjY6d+6s1j42btwIAELfM2VUDQ+dX94AaMyYMZg9e7ZaZSgOZ8+eBQClD3FkAZCnpyf27duntBm0Muoct6enJwAIdU9eBw8elMtTGHWuRV6PHj3CqVOnUL16dblmts2aNQMApX0FExMTkZSUVKwPuxgrKZ6enkhNTVXaR1v2/co/CbMqBdURrBQozlEWPoXCRoc7deqUMFlq/pHTChptjej/RofLP8nq/v37i3V0uOrVq9ObN2+E9NevX5OTkxMBoIiICCE9Li6ORCIROTk50fv374X0u3fvkqmpqdJjtLS0JAcHB6XHp6niHh0ur4iICNq1a5fcqCzKRod79uwZAaBGjRrJnfsnT54II7HlH03u+vXrpKurS5UqVRImJJw7dy4BoEGDBqlddtlnTdXIVPn3nXd0uPyjD8pGf1I2Opy9vb3G+y9ogsjCPuef0pc+ulNhoxMlJiZSdHQ0JSYmqrU9FNPocEQkV0fIxMXFkZOTE2lrayuc08zMTIURBnNycoQJMkeOHKnWPk6cOEEGBgZkb28vN6Fn/n3JJnMtaGSl9+/fU8uWLQlKJnFVhzqjw+WdTDavhQsXEgCqUqWKwghxkyZNEkZoe/fundrlUfe4X758SSYmJmpPlkqk+bV4+/Yt5ebmyqW9fv2amjRpQlAyiWp2djY5OzsTADp06JCQnpubSwMHDlT62/e5fen1B/s4Ra1/NZ0s9dq1a5SZmamw/cjISNLX1yeJREL37t37+ANiXwx145avtjncvXv3hCYemZmZSEhIwLlz53D9+nVoaWlh4sSJwohr6po9ezYiIiIwffp0REVFoWHDhnj48CG2b98OfX19rFmzRmkn4UaNGqFOnTro3r07DAwMsHfvXty5cwedOnWSe/LatGlTDBs2DIsXL0bNmjXRuXNnEBFCQ0Px9OlTDB8+XO7phZ2dHXr27IlNmzahfv36aNWqFRISErBr1y60atUKoaGhCmVp1qwZtm3bBn9/f9SrVw9aWlro0KEDateurdG5KGnqPqWxtbVF586dERoaCldXVzRv3hzx8fH477//0Lx5c9y/f18uf3p6Onr27Ins7Gxs2rQJRkZGAD6MDHPo0CGsWLECvr6+aj8R14RYLMbatWvh6+uLNm3aoGvXrrC3t8fp06dx/PhxODo6YtasWcW+X6aZlStXCnN+yeaJWLlypfAGz8PDQ+jrsWTJEkyZMgUhISFFHgykKPsFgD///BMbNmyAh4cHrK2t8eTJE/z7779IS0vDqlWrFJrCxcfHo0aNGvDx8UHFihWRmZmJgwcP4vbt22jbtq3cKGMyXbp0wfv371G7dm0YGxvj+vXr2L9/P8zNzbF7927h+5Pfnj17kJiYKMy3psoPP/yA8PBw2NjYwMjISOk57Nevn9xT2FOnTglN+hITE4U0WZNdS0tLzJs3T8jfuXNnSCQSuLq6oly5ckhNTcWZM2dw+fJlmJqaYsOGDXJvm9euXYtp06ZBW1sbDRo0wNy5cxXK5OXlpbTfo7rHbWZmhiVLliAgIAAuLi7o3r07gA8DKiQnJ2Pr1q0K51bTa7F7925MmDABzZo1g52dHRISEoTyTZs2TWESVS0tLaxZswbNmjVDmzZt0KlTJ5QrVw6nTp3CuXPn4OLignHjxqk8JsaKQ3HUv97e3hg4cCBWrlwJFxcXtG3bFs+fP8fWrVthbm6OxYsXy+1z/vz52LdvHzw8PFC+fHlIJBLcvHkThw4dgkgkwtKlS+Ho6FjyB8++PMUZUX0KeedOkf3p6emRra0teXt706RJk1RG9Oo8IU9MTKThw4eTvb09SSQSsrS0pC5dutD169cV8sreBN2/f59mzZpFlStXJh0dHbK3t6fJkycrnduGiGj16tXk5uZG+vr6pK+vT25ubrR69WqledPS0mj48OFUpkwZkkqlVLt2bdq4caPKNwHPnz+nbt26kaWlJYnF4o96I1CSb4KUUTVP0Nu3b2n06NHk4OBAUqmUqlSpQtOmTaPMzEyF/D/++CMBoOnTpyts/9mzZ2RpaUlmZmb0+PHjQsuj6ZsgmWvXrlGXLl3I0tKSJBIJ2dvb04gRI5S+TeA3QZ+e7Hur6i/v+ZZ9B5SdZ2VQwJsgTfZLRHTkyBFq0aIFWVtbk0QiIRsbG+revTtdunRJ6fZTUlIoICCAKlWqRLq6umRkZETu7u60YsUKubeoeS1dupTc3NzIxMSEdHR0yNHRkUaMGFHoHFOtW7cm5JunSBlPT88CjxkAHTt2TG4d2edX1V/+78usWbPI29ub7OzsSCqVkp6eHjk5OVFwcLDcWxgZ2TUt6E/V9Vb3uGX2799PTZo0IQMDAzI0NCRPT0+lc9QRaX4trly5Qu3atSNbW1vht6pdu3Z09OjRAst048YN6ty5M1lYWJBEIiFHR0caP3680vmlPrcvsf5gH6e46t+cnBxatGgR1ahRg6RSKVlYWFD37t2V3v/t3LmT/Pz8qGLFimRgYEASiYTKly9PPXv2pLNnz5bg0bLPRd24RURUeM/wS5cuoX79+rh48aLC08fSrF+/fli3bh1iY2O5PSljSmzcuBF9+vThuoMxpjGuPxhjRaFu3PJNDozAGGOMMcYYY6pwEMQYY4wxxhgrVTgIYowxxhhjjJUqHAR9hLVr14KIuD8QY4wxxhhjXxEOghhjjDHGGGOlikbzBEVHR5dUORhj36DY2FgAXHcwxjTH9QdjrCjUrTPUGiL78ePHcHZ2Rlpa2kcXjDFWumhpaSEnJ+dzF4Mx9hXi+oMxVhT6+vqIjo5GhQoVVOZRKwgCPgRCSUlJxVY4xljpkJGRAalU+rmLwRj7CnH9wRgrCktLywIDIECDIIgxxhhjjDHGvgU8MAJjjDHGGGOsVOEgiDHGGGOMMVaqcBDEGGOMMcYYK1U4CGKMMcYYY4yVKhwEMcYYY4wxxkoVDoIYY4wxxhhjpQoHQYwxxhhjjLFShYMgxhhjjDHGWKnCQRBjjDHGGGOsVOEgiDHGGGOMMVaqcBDEGGOMMcYYK1U4CGKMMcYYY4yVKhwEMcYYY4wxxkoVDoIYY4wxxhhjpQoHQYwxxhhjjLFShYMgxhhjjDHGWKnCQRBjjDHGGGOsVOEgiDHGGGOMMVaqcBDEGGOMMcYYK1U4CGKMMcYYY4yVKhwEMcYYY4wxxkoVDoIYY4wxxhhjpQoHQYwxxhhjjLFShYMgxhhjjDHGWKnCQRBjjDHGGGOsVOEgiDHGGGOMMVaqcBDEGGOMMcYYK1U4CGKMMcYYY4yVKhwEMcYYY4wxxkoVDoIYY4wxxhhjpQoHQYwxxhhjjLFShYMgxhhjjDHGWKnCQRBjjDHGGGOsVOEgiDHGGGOMMVaqcBDEGGOMMcYYK1U4CGKMMcYYY4yVKhwEMcYYY4wxxkoVDoIYY4wxxhhjpQoHQYwxxhhjjLFShYMgxhhj/6/9OhAAAAAAEORvPchlEQCsSBAAALAiQQAAwIoEAQAAKxIEAACsSBAAALAiQQAAwIoEAQAAKxIEAACsSBAAALAiQQAAwIoEAQAAKxIEAACsSBAAALAiQQAAwIoEAQAAKxIEAACsSBAAALAiQQAAwIoEAQAAKxIEAACsBNVuoKIm/G3uAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Claim 3 (7.4): 7.4 Effect of Data Set Size**"
      ],
      "metadata": {
        "id": "T9WnTCm82F-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Function to create the model with optional dropout\n",
        "def create_model(with_dropout=True, dropout_rate_input = 0.1, dropout_rate_hidden=0.5):\n",
        "    model = Sequential()\n",
        "    if with_dropout:\n",
        "        model.add(Dropout(dropout_rate_input, input_shape=(784,)))  # Input dropout\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    if with_dropout:\n",
        "        model.add(Dropout(dropout_rate_hidden))\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    if with_dropout:\n",
        "        model.add(Dropout(dropout_rate_hidden))\n",
        "    model.add(Dense(2048, activation='relu'))\n",
        "    if with_dropout:\n",
        "        model.add(Dropout(dropout_rate_hidden))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# Function to compile and train the model\n",
        "def compile_and_train(model, x_train, y_train, x_val, y_val, epochs=100, batch_size=32):\n",
        "    model.compile(optimizer=\n",
        "                  get_sgd_optimizer(),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                        validation_data=(x_val, y_val))\n",
        "    _, accuracy = model.evaluate(x_val, y_val)\n",
        "    # Calculate classification error\n",
        "    classification_error = 1 - accuracy\n",
        "    return classification_error\n",
        "\n",
        "# Main loop to iterate over different dataset sizes and dropout configurations\n",
        "dataset_sizes = [100, 500, 1000, 5000, 10000, 50000]\n",
        "classification_errors_with_dropout = []\n",
        "classification_errors_without_dropout = []\n",
        "\n",
        "for size in dataset_sizes:\n",
        "    # Get a subset of the training data\n",
        "    x_train = x_train_full[:size]\n",
        "    y_train = y_train_full[:size]\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model with dropout\n",
        "    model_with_dropout = create_model(with_dropout=True, dropout_rate_input= 0.1, dropout_rate_hidden=0.5)\n",
        "    error_with_dropout = compile_and_train(model_with_dropout, x_train, y_train, x_val, y_val)\n",
        "    classification_errors_with_dropout.append((size, error_with_dropout))\n",
        "\n",
        "    # Train model without dropout\n",
        "    model_without_dropout = create_model(with_dropout=False)\n",
        "    error_without_dropout = compile_and_train(model_without_dropout, x_train, y_train, x_val, y_val)\n",
        "    classification_errors_without_dropout.append((size, error_without_dropout))\n",
        "\n",
        "# Plotting\n",
        "sizes_with_dropout, error_values_with_dropout = zip(*classification_errors_with_dropout)  # Unzip the sizes and errors\n",
        "sizes_without_dropout, error_values_without_dropout = zip(*classification_errors_without_dropout)  # Unzip the sizes and errors\n",
        "\n",
        "plt.plot(sizes_with_dropout, error_values_with_dropout, marker='o', label='With Dropout')\n",
        "plt.plot(sizes_without_dropout, error_values_without_dropout, marker='x', label='Without Dropout')\n",
        "plt.xscale('log')  # Logarithmic scale since dataset sizes vary widely\n",
        "plt.xlabel('Dataset Size')\n",
        "plt.ylabel('Classification Error')\n",
        "plt.title('Classification Error vs Dataset Size')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NhBWSI6KlDk6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44036704-cdbf-4932-ef30-33091bad5080"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 7s 273ms/step - loss: 2.3048 - accuracy: 0.1444 - val_loss: 2.3432 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 2.1799 - accuracy: 0.1333 - val_loss: 2.1561 - val_accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.9679 - accuracy: 0.3556 - val_loss: 1.9437 - val_accuracy: 0.6000\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.8588 - accuracy: 0.3667 - val_loss: 1.7104 - val_accuracy: 0.6000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.3669 - accuracy: 0.6222 - val_loss: 1.8171 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0905 - accuracy: 0.6778 - val_loss: 1.5313 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.8757 - accuracy: 0.7444 - val_loss: 1.4871 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.7330 - accuracy: 0.7889 - val_loss: 1.2430 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.8099 - accuracy: 0.7222 - val_loss: 1.4684 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.4952 - accuracy: 0.8778 - val_loss: 1.2772 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2491 - accuracy: 0.9667 - val_loss: 1.0996 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2295 - accuracy: 0.9444 - val_loss: 1.4682 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1724 - accuracy: 0.9556 - val_loss: 1.2822 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1282 - accuracy: 0.9778 - val_loss: 1.6028 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1080 - accuracy: 0.9889 - val_loss: 1.5817 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1182 - accuracy: 0.9778 - val_loss: 1.4237 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0840 - accuracy: 0.9778 - val_loss: 1.5872 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1154 - accuracy: 0.9667 - val_loss: 1.5804 - val_accuracy: 0.8000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.1221 - accuracy: 0.9667 - val_loss: 1.8249 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0585 - accuracy: 0.9889 - val_loss: 1.7887 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.6668 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0583 - accuracy: 0.9889 - val_loss: 1.7491 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.8198 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.1402 - accuracy: 0.9556 - val_loss: 1.4410 - val_accuracy: 0.8000\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1143 - accuracy: 0.9556 - val_loss: 1.8919 - val_accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0987 - accuracy: 0.9667 - val_loss: 1.5399 - val_accuracy: 0.8000\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 1.6483 - val_accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0514 - accuracy: 0.9889 - val_loss: 1.6869 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.6597 - val_accuracy: 0.8000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.6515 - val_accuracy: 0.8000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.6894 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0346 - accuracy: 0.9889 - val_loss: 1.7121 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.8337 - val_accuracy: 0.8000\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.9951 - val_accuracy: 0.8000\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0528 - accuracy: 0.9889 - val_loss: 1.9782 - val_accuracy: 0.8000\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0385 - accuracy: 0.9889 - val_loss: 1.8364 - val_accuracy: 0.8000\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0589 - accuracy: 0.9778 - val_loss: 1.6951 - val_accuracy: 0.8000\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.7392 - val_accuracy: 0.8000\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.6975 - val_accuracy: 0.8000\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 1.8504 - val_accuracy: 0.8000\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0256 - accuracy: 0.9889 - val_loss: 1.6534 - val_accuracy: 0.8000\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.6741 - val_accuracy: 0.8000\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.8000\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.6013 - val_accuracy: 0.8000\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.5252 - val_accuracy: 0.8000\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.6562 - val_accuracy: 0.8000\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.6748 - val_accuracy: 0.8000\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6870 - val_accuracy: 0.8000\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.7630 - val_accuracy: 0.8000\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.7888 - val_accuracy: 0.8000\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.8565 - val_accuracy: 0.8000\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.7944 - val_accuracy: 0.8000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0167 - accuracy: 0.9889 - val_loss: 2.0053 - val_accuracy: 0.8000\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.0262 - val_accuracy: 0.8000\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 0.9889 - val_loss: 1.9059 - val_accuracy: 0.8000\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.9413 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.8388 - val_accuracy: 0.8000\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.7672 - val_accuracy: 0.8000\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.1155 - val_accuracy: 0.8000\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1584 - val_accuracy: 0.8000\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 2.1902 - val_accuracy: 0.8000\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0384 - accuracy: 0.9778 - val_loss: 2.1022 - val_accuracy: 0.8000\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.0486 - val_accuracy: 0.8000\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0198 - accuracy: 0.9889 - val_loss: 1.7527 - val_accuracy: 0.8000\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0331 - accuracy: 0.9889 - val_loss: 1.8692 - val_accuracy: 0.8000\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0311 - accuracy: 0.9778 - val_loss: 2.0146 - val_accuracy: 0.8000\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.9782 - val_accuracy: 0.8000\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.8300 - val_accuracy: 0.8000\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.7375 - val_accuracy: 0.8000\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7080 - val_accuracy: 0.8000\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.7426 - val_accuracy: 0.8000\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7904 - val_accuracy: 0.8000\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.7388 - val_accuracy: 0.8000\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7143 - val_accuracy: 0.8000\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.8000\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.7099 - val_accuracy: 0.8000\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7404 - val_accuracy: 0.8000\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7616 - val_accuracy: 0.8000\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7789 - val_accuracy: 0.8000\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8105 - val_accuracy: 0.8000\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8227 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.8480 - val_accuracy: 0.8000\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8668 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9074 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.9748 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.0073 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0082 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9992 - val_accuracy: 0.8000\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9987 - val_accuracy: 0.8000\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.0388 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1075 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1286 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0951 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0811 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0513 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0375 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0306 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.0372 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0379 - val_accuracy: 0.8000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0379 - accuracy: 0.8000\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 94ms/step - loss: 2.2566 - accuracy: 0.1444 - val_loss: 2.2495 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.8087 - accuracy: 0.3778 - val_loss: 1.9630 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.3176 - accuracy: 0.8111 - val_loss: 1.6627 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.8702 - accuracy: 0.9111 - val_loss: 1.5345 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.9333 - val_loss: 1.8512 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3579 - accuracy: 0.9444 - val_loss: 1.3241 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1867 - accuracy: 0.9778 - val_loss: 1.3648 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 1.3579 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 1.2165 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 1.3554 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.3563 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.3817 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.3799 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.4078 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.4171 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.4241 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.4380 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.4382 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4553 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4577 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4678 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.4719 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4856 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.4843 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.4923 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.5072 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.5162 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.5173 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.5233 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.5300 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5361 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.5388 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.5464 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5506 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.5546 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5632 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5656 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5716 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.5754 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5802 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5853 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.5900 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5976 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5991 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6015 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.6063 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6114 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6151 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6191 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6237 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6257 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6251 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6305 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6348 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6398 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6419 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6452 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6478 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6508 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6549 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6594 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6614 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6635 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6653 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6684 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6695 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6740 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6771 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6820 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6803 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6861 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6858 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6912 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6931 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6962 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7002 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7023 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7062 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7069 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7114 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7118 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7147 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7175 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7210 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7234 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7247 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7267 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7290 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7315 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7320 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7344 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7339 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7374 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7391 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7412 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7429 - val_accuracy: 0.7000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.7429 - accuracy: 0.7000\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 17ms/step - loss: 2.1181 - accuracy: 0.2356 - val_loss: 5.1754 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8641 - accuracy: 0.5156 - val_loss: 1.5085 - val_accuracy: 0.3600\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0159 - accuracy: 0.6489 - val_loss: 0.6399 - val_accuracy: 0.8200\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7537 - accuracy: 0.7600 - val_loss: 0.5171 - val_accuracy: 0.8200\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6406 - accuracy: 0.7911 - val_loss: 0.9714 - val_accuracy: 0.6800\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.8622 - val_loss: 0.6363 - val_accuracy: 0.7400\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3809 - accuracy: 0.8800 - val_loss: 0.7636 - val_accuracy: 0.7200\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4099 - accuracy: 0.8667 - val_loss: 1.1096 - val_accuracy: 0.7200\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.8311 - val_loss: 0.3464 - val_accuracy: 0.8800\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.9022 - val_loss: 0.9449 - val_accuracy: 0.6800\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3716 - accuracy: 0.8756 - val_loss: 1.6832 - val_accuracy: 0.5400\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5591 - accuracy: 0.8489 - val_loss: 0.7685 - val_accuracy: 0.7600\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2817 - accuracy: 0.9067 - val_loss: 0.4764 - val_accuracy: 0.8600\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1637 - accuracy: 0.9378 - val_loss: 0.2847 - val_accuracy: 0.9400\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1469 - accuracy: 0.9511 - val_loss: 0.3150 - val_accuracy: 0.8600\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1524 - accuracy: 0.9444 - val_loss: 0.3878 - val_accuracy: 0.9000\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.9467 - val_loss: 0.7042 - val_accuracy: 0.8200\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.9689 - val_loss: 0.4465 - val_accuracy: 0.8600\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9822 - val_loss: 0.4937 - val_accuracy: 0.8800\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.9467 - val_loss: 0.2444 - val_accuracy: 0.8600\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0956 - accuracy: 0.9644 - val_loss: 0.4862 - val_accuracy: 0.8800\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1373 - accuracy: 0.9644 - val_loss: 0.5047 - val_accuracy: 0.8200\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9733 - val_loss: 0.3780 - val_accuracy: 0.8600\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0427 - accuracy: 0.9822 - val_loss: 0.3136 - val_accuracy: 0.9000\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 0.9867 - val_loss: 0.3532 - val_accuracy: 0.8400\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0603 - accuracy: 0.9778 - val_loss: 0.4267 - val_accuracy: 0.8200\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0425 - accuracy: 0.9822 - val_loss: 0.4664 - val_accuracy: 0.8600\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.5267 - val_accuracy: 0.8800\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0414 - accuracy: 0.9889 - val_loss: 0.2407 - val_accuracy: 0.9000\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 0.2905 - val_accuracy: 0.8800\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0425 - accuracy: 0.9889 - val_loss: 0.3318 - val_accuracy: 0.8600\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9956 - val_loss: 0.5254 - val_accuracy: 0.8600\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9933 - val_loss: 0.3187 - val_accuracy: 0.8600\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9889 - val_loss: 0.2609 - val_accuracy: 0.8800\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9911 - val_loss: 0.3143 - val_accuracy: 0.8800\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.3137 - val_accuracy: 0.8800\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 0.9889 - val_loss: 0.4194 - val_accuracy: 0.8600\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0371 - accuracy: 0.9867 - val_loss: 0.1902 - val_accuracy: 0.9200\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.9822 - val_loss: 0.5552 - val_accuracy: 0.8800\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0212 - accuracy: 0.9911 - val_loss: 0.5674 - val_accuracy: 0.8600\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.4553 - val_accuracy: 0.8800\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.3586 - val_accuracy: 0.9200\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0180 - accuracy: 0.9911 - val_loss: 0.3562 - val_accuracy: 0.8800\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.8800\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.3693 - val_accuracy: 0.9400\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.4229 - val_accuracy: 0.9000\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.3962 - val_accuracy: 0.9200\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 0.9956 - val_loss: 0.3776 - val_accuracy: 0.8800\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0121 - accuracy: 0.9933 - val_loss: 0.3493 - val_accuracy: 0.8600\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0315 - accuracy: 0.9933 - val_loss: 0.3882 - val_accuracy: 0.8800\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9956 - val_loss: 0.2340 - val_accuracy: 0.9000\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.3451 - val_accuracy: 0.9400\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.3179 - val_accuracy: 0.9400\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.2433 - val_accuracy: 0.9000\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.2669 - val_accuracy: 0.9200\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 16.1774 - val_accuracy: 0.2600\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.5217 - accuracy: 0.6467 - val_loss: 0.5176 - val_accuracy: 0.8600\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2696 - accuracy: 0.9111 - val_loss: 0.4430 - val_accuracy: 0.8400\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1144 - accuracy: 0.9667 - val_loss: 0.3087 - val_accuracy: 0.9200\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0966 - accuracy: 0.9756 - val_loss: 0.4107 - val_accuracy: 0.9000\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9911 - val_loss: 0.4332 - val_accuracy: 0.8800\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0526 - accuracy: 0.9844 - val_loss: 0.4158 - val_accuracy: 0.8800\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1412 - accuracy: 0.9644 - val_loss: 0.4136 - val_accuracy: 0.9000\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.9822 - val_loss: 0.6633 - val_accuracy: 0.8600\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9778 - val_loss: 0.5954 - val_accuracy: 0.9000\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0684 - accuracy: 0.9822 - val_loss: 0.6370 - val_accuracy: 0.8200\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0553 - accuracy: 0.9889 - val_loss: 0.5428 - val_accuracy: 0.8600\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9933 - val_loss: 0.5985 - val_accuracy: 0.8600\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 0.4976 - val_accuracy: 0.9000\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0421 - accuracy: 0.9911 - val_loss: 0.4735 - val_accuracy: 0.9000\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9889 - val_loss: 0.6069 - val_accuracy: 0.9000\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9956 - val_loss: 0.5613 - val_accuracy: 0.9200\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.5838 - val_accuracy: 0.8600\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0451 - accuracy: 0.9889 - val_loss: 0.4157 - val_accuracy: 0.9000\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9911 - val_loss: 0.4425 - val_accuracy: 0.9000\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9000\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9867 - val_loss: 0.5069 - val_accuracy: 0.9200\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.5224 - val_accuracy: 0.9200\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.5143 - val_accuracy: 0.9000\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 0.9978 - val_loss: 1.1995 - val_accuracy: 0.8400\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0455 - accuracy: 0.9933 - val_loss: 0.5575 - val_accuracy: 0.9000\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.5159 - val_accuracy: 0.9200\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.4984 - val_accuracy: 0.9200\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 0.9933 - val_loss: 0.4551 - val_accuracy: 0.9000\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.4864 - val_accuracy: 0.9000\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9978 - val_loss: 0.4809 - val_accuracy: 0.9200\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9889 - val_loss: 0.6117 - val_accuracy: 0.8800\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.9000\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9933 - val_loss: 0.5286 - val_accuracy: 0.9200\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 0.9978 - val_loss: 0.5022 - val_accuracy: 0.9000\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.9956 - val_loss: 0.5727 - val_accuracy: 0.8600\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 0.9956 - val_loss: 0.5618 - val_accuracy: 0.8800\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.9933 - val_loss: 0.4557 - val_accuracy: 0.9000\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8800\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.6572 - val_accuracy: 0.9400\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0622 - accuracy: 0.9822 - val_loss: 0.5542 - val_accuracy: 0.9200\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9911 - val_loss: 0.4750 - val_accuracy: 0.9200\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9911 - val_loss: 0.5230 - val_accuracy: 0.8800\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.5136 - val_accuracy: 0.8800\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.8800\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5478 - accuracy: 0.8800\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 16ms/step - loss: 1.7669 - accuracy: 0.4378 - val_loss: 5.2241 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3477 - accuracy: 0.6489 - val_loss: 2.4207 - val_accuracy: 0.3800\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6709 - accuracy: 0.8089 - val_loss: 0.6100 - val_accuracy: 0.8200\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2583 - accuracy: 0.9333 - val_loss: 0.4563 - val_accuracy: 0.8200\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1601 - accuracy: 0.9622 - val_loss: 0.5417 - val_accuracy: 0.8600\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0767 - accuracy: 0.9889 - val_loss: 0.7680 - val_accuracy: 0.7600\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0909 - accuracy: 0.9711 - val_loss: 0.5732 - val_accuracy: 0.8200\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0590 - accuracy: 0.9889 - val_loss: 0.4445 - val_accuracy: 0.8200\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9956 - val_loss: 0.2999 - val_accuracy: 0.8600\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.3418 - val_accuracy: 0.9000\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.8600\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.8800\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.8400\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.8600\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.8600\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.8600\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.8600\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.8400\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.8600\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.8600\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.8400\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.8400\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.8400\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.8400\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.8400\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.8600\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.8400\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.8400\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.8400\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.8400\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.8400\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.8400\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.8400\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.8400\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.8400\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.8400\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.8400\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.8400\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.6943e-04 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.8400\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.3877e-04 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.8400\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.0880e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.8400\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 8.8196e-04 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.8600\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.8296e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.8400\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 8.3606e-04 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.8400\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.0863e-04 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.8400\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.8455e-04 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.8400\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 7.6327e-04 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.8400\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.4484e-04 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.8400\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 7.3785e-04 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.8400\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.1940e-04 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.8400\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.9275e-04 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.8400\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.7463e-04 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.8400\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.5796e-04 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.8400\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.4337e-04 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.8400\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.2878e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.8400\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.1567e-04 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.8400\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.0539e-04 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.8400\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.9134e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.8400\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.7877e-04 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.8400\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.6665e-04 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.8400\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.5522e-04 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.8400\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.5311e-04 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.8600\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.4582e-04 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.8600\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.2888e-04 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.8600\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 5.1547e-04 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.8600\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 5.0524e-04 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.8600\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.0110e-04 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.8600\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.8820e-04 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.8600\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.7874e-04 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.8600\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 4.7021e-04 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.8600\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 4.6233e-04 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.8600\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 4.5400e-04 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.8600\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.5017e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.8600\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.3967e-04 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.8600\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 4.2952e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.8600\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 4.2310e-04 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.8600\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 4.1755e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.8600\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.1156e-04 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.8600\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.0364e-04 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.8600\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.9765e-04 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.8400\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.9154e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.8400\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.8468e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.8400\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.8034e-04 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.8400\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.7455e-04 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.8400\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.6857e-04 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.8400\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.6348e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.8400\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.5834e-04 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.8600\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.5381e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.8600\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.4943e-04 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.8600\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.4461e-04 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.8600\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.4014e-04 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.8600\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.3637e-04 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.8600\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.3213e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.8600\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.2854e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.8600\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.2425e-04 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.8600\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1994e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.8600\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1588e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.8600\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1320e-04 - accuracy: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.8600\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.0848e-04 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.8600\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.0493e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.8600\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3709 - accuracy: 0.8600\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 1s 10ms/step - loss: 1.8426 - accuracy: 0.3556 - val_loss: 0.9991 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.0064 - accuracy: 0.6811 - val_loss: 0.5871 - val_accuracy: 0.8300\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6659 - accuracy: 0.7689 - val_loss: 0.7504 - val_accuracy: 0.8000\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5795 - accuracy: 0.8111 - val_loss: 0.4815 - val_accuracy: 0.8800\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.4700 - accuracy: 0.8456 - val_loss: 0.4500 - val_accuracy: 0.8500\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8867 - val_loss: 0.4445 - val_accuracy: 0.8600\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.3416 - accuracy: 0.8833 - val_loss: 1.1156 - val_accuracy: 0.7700\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8822 - val_loss: 0.4826 - val_accuracy: 0.8800\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 0.2555 - accuracy: 0.9256 - val_loss: 0.7233 - val_accuracy: 0.8200\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.3598 - accuracy: 0.8889 - val_loss: 0.4596 - val_accuracy: 0.8900\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1963 - accuracy: 0.9311 - val_loss: 2.5838 - val_accuracy: 0.7200\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.4275 - accuracy: 0.8800 - val_loss: 0.4145 - val_accuracy: 0.9100\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.1711 - accuracy: 0.9400 - val_loss: 0.4368 - val_accuracy: 0.9200\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1461 - accuracy: 0.9567 - val_loss: 0.4218 - val_accuracy: 0.9000\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1159 - accuracy: 0.9633 - val_loss: 0.9317 - val_accuracy: 0.8200\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1522 - accuracy: 0.9556 - val_loss: 0.5702 - val_accuracy: 0.9100\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1086 - accuracy: 0.9678 - val_loss: 0.6426 - val_accuracy: 0.8500\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.2066 - accuracy: 0.9444 - val_loss: 0.6247 - val_accuracy: 0.8400\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.1848 - accuracy: 0.9411 - val_loss: 0.6335 - val_accuracy: 0.8700\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1349 - accuracy: 0.9578 - val_loss: 0.4120 - val_accuracy: 0.9200\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0855 - accuracy: 0.9711 - val_loss: 0.5750 - val_accuracy: 0.8700\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0954 - accuracy: 0.9756 - val_loss: 0.4968 - val_accuracy: 0.9100\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9789 - val_loss: 0.4267 - val_accuracy: 0.8900\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9767 - val_loss: 0.5561 - val_accuracy: 0.9300\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9744 - val_loss: 0.4416 - val_accuracy: 0.9400\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9900 - val_loss: 0.4805 - val_accuracy: 0.9400\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9778 - val_loss: 0.5062 - val_accuracy: 0.9200\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0553 - accuracy: 0.9833 - val_loss: 0.4629 - val_accuracy: 0.9300\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9711 - val_loss: 0.6469 - val_accuracy: 0.9100\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0943 - accuracy: 0.9733 - val_loss: 0.5584 - val_accuracy: 0.9200\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9933 - val_loss: 0.5110 - val_accuracy: 0.9400\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9822 - val_loss: 0.6673 - val_accuracy: 0.9300\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0978 - accuracy: 0.9622 - val_loss: 0.8129 - val_accuracy: 0.8600\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9678 - val_loss: 0.6101 - val_accuracy: 0.8900\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9800 - val_loss: 0.4458 - val_accuracy: 0.9200\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9867 - val_loss: 0.4715 - val_accuracy: 0.9100\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9800 - val_loss: 0.4944 - val_accuracy: 0.9100\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9789 - val_loss: 0.5710 - val_accuracy: 0.8900\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9744 - val_loss: 0.4603 - val_accuracy: 0.9300\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 0.9889 - val_loss: 0.5422 - val_accuracy: 0.9300\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.4187 - val_accuracy: 0.9200\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.7096 - val_accuracy: 0.9000\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9856 - val_loss: 0.5725 - val_accuracy: 0.9200\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9911 - val_loss: 0.4872 - val_accuracy: 0.9100\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.4411 - val_accuracy: 0.9300\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.5174 - val_accuracy: 0.9400\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.5959 - val_accuracy: 0.9000\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.5449 - val_accuracy: 0.9100\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9833 - val_loss: 0.7288 - val_accuracy: 0.9000\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9900 - val_loss: 0.5615 - val_accuracy: 0.9200\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9811 - val_loss: 0.9653 - val_accuracy: 0.8400\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.2711 - accuracy: 0.9500 - val_loss: 0.7004 - val_accuracy: 0.8900\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0996 - accuracy: 0.9700 - val_loss: 0.6403 - val_accuracy: 0.9100\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0579 - accuracy: 0.9878 - val_loss: 0.5209 - val_accuracy: 0.9100\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0476 - accuracy: 0.9833 - val_loss: 0.6587 - val_accuracy: 0.9300\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.6535 - val_accuracy: 0.9300\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0427 - accuracy: 0.9900 - val_loss: 0.6339 - val_accuracy: 0.9100\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9944 - val_loss: 0.7089 - val_accuracy: 0.9100\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9956 - val_loss: 0.6452 - val_accuracy: 0.9300\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9822 - val_loss: 0.6204 - val_accuracy: 0.9300\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1390 - accuracy: 0.9711 - val_loss: 0.6263 - val_accuracy: 0.9300\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 0.9867 - val_loss: 0.7348 - val_accuracy: 0.9300\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.5082 - val_accuracy: 0.9300\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.5442 - val_accuracy: 0.9100\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9856 - val_loss: 0.6253 - val_accuracy: 0.9200\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.5543 - val_accuracy: 0.9400\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.6239 - val_accuracy: 0.9200\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9867 - val_loss: 0.4907 - val_accuracy: 0.9400\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 0.9911 - val_loss: 0.4627 - val_accuracy: 0.9300\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 0.9911 - val_loss: 0.5380 - val_accuracy: 0.9300\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.6202 - val_accuracy: 0.9100\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9944 - val_loss: 0.7218 - val_accuracy: 0.9100\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9856 - val_loss: 0.6593 - val_accuracy: 0.9300\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.5844 - val_accuracy: 0.9200\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.6938 - val_accuracy: 0.9200\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 0.9933 - val_loss: 0.5372 - val_accuracy: 0.9300\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 0.9900 - val_loss: 0.5862 - val_accuracy: 0.9200\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.6861 - val_accuracy: 0.9400\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 0.5911 - val_accuracy: 0.9300\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0200 - accuracy: 0.9911 - val_loss: 0.5640 - val_accuracy: 0.9400\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9911 - val_loss: 0.7080 - val_accuracy: 0.9300\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 0.6907 - val_accuracy: 0.9300\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 0.9922 - val_loss: 0.6149 - val_accuracy: 0.9200\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.6501 - val_accuracy: 0.9300\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.6386 - val_accuracy: 0.9100\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0315 - accuracy: 0.9944 - val_loss: 0.6716 - val_accuracy: 0.9100\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.7310 - val_accuracy: 0.9300\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 0.6305 - val_accuracy: 0.9200\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5979 - val_accuracy: 0.9300\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.5616 - val_accuracy: 0.9200\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9944 - val_loss: 0.5976 - val_accuracy: 0.9300\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9911 - val_loss: 0.4695 - val_accuracy: 0.9300\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.4736 - val_accuracy: 0.9200\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.6906 - val_accuracy: 0.9400\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.9400\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.5841 - val_accuracy: 0.9400\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5804 - val_accuracy: 0.9400\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.5845 - val_accuracy: 0.9400\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.5683 - val_accuracy: 0.9300\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.7308 - val_accuracy: 0.9200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7308 - accuracy: 0.9200\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 1s 11ms/step - loss: 1.3766 - accuracy: 0.5822 - val_loss: 0.8109 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.8344 - val_loss: 0.4438 - val_accuracy: 0.8900\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.2782 - accuracy: 0.9133 - val_loss: 0.8056 - val_accuracy: 0.8100\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.2711 - accuracy: 0.9200 - val_loss: 0.3550 - val_accuracy: 0.9100\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.9667 - val_loss: 0.4896 - val_accuracy: 0.8900\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0431 - accuracy: 0.9978 - val_loss: 0.4155 - val_accuracy: 0.9100\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.9000\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 0.9967 - val_loss: 0.4116 - val_accuracy: 0.9200\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9000\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.9200\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.9100\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9200\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9200\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.9100\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.9200\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.9100\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.9200\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.9100\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.9100\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9100\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5258 - val_accuracy: 0.9100\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.9100\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5316 - val_accuracy: 0.9100\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5440 - val_accuracy: 0.9100\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.9100\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.9100\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.9100\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5534 - val_accuracy: 0.9100\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.9100\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 9.6916e-04 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.9100\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 9.3231e-04 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.9100\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 8.8963e-04 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 0.9100\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 8.4880e-04 - accuracy: 1.0000 - val_loss: 0.5723 - val_accuracy: 0.9100\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 8.2646e-04 - accuracy: 1.0000 - val_loss: 0.5757 - val_accuracy: 0.9100\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 7.8176e-04 - accuracy: 1.0000 - val_loss: 0.5746 - val_accuracy: 0.9100\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 7.5845e-04 - accuracy: 1.0000 - val_loss: 0.5746 - val_accuracy: 0.9100\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 7.2788e-04 - accuracy: 1.0000 - val_loss: 0.5796 - val_accuracy: 0.9100\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 7.0557e-04 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.9100\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 6.8473e-04 - accuracy: 1.0000 - val_loss: 0.5756 - val_accuracy: 0.9100\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 6.6026e-04 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.9100\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 6.3907e-04 - accuracy: 1.0000 - val_loss: 0.5881 - val_accuracy: 0.9100\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 6.1933e-04 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.9100\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 6.0095e-04 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.9100\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 5.8547e-04 - accuracy: 1.0000 - val_loss: 0.5957 - val_accuracy: 0.9100\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 5.6888e-04 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.9100\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 5.5439e-04 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.9100\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 5.3784e-04 - accuracy: 1.0000 - val_loss: 0.5981 - val_accuracy: 0.9100\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 5.2359e-04 - accuracy: 1.0000 - val_loss: 0.6039 - val_accuracy: 0.9100\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 5.0868e-04 - accuracy: 1.0000 - val_loss: 0.6041 - val_accuracy: 0.9100\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.9664e-04 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.9100\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.8423e-04 - accuracy: 1.0000 - val_loss: 0.6059 - val_accuracy: 0.9100\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.7224e-04 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.9100\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.6145e-04 - accuracy: 1.0000 - val_loss: 0.6090 - val_accuracy: 0.9100\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.5135e-04 - accuracy: 1.0000 - val_loss: 0.6124 - val_accuracy: 0.9100\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.4097e-04 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 0.9100\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.3157e-04 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.9100\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.2328e-04 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.9100\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.1222e-04 - accuracy: 1.0000 - val_loss: 0.6204 - val_accuracy: 0.9100\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 4.0367e-04 - accuracy: 1.0000 - val_loss: 0.6236 - val_accuracy: 0.9100\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.9493e-04 - accuracy: 1.0000 - val_loss: 0.6240 - val_accuracy: 0.9100\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.8786e-04 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.9100\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.8054e-04 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.9100\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.7273e-04 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.9100\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.6608e-04 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.9100\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.5902e-04 - accuracy: 1.0000 - val_loss: 0.6253 - val_accuracy: 0.9100\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.5233e-04 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.9100\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.4541e-04 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 0.9100\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.3855e-04 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 0.9100\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.3351e-04 - accuracy: 1.0000 - val_loss: 0.6326 - val_accuracy: 0.9100\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.2731e-04 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.9100\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.2173e-04 - accuracy: 1.0000 - val_loss: 0.6379 - val_accuracy: 0.9100\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.1647e-04 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.9100\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.1172e-04 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.9100\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.0631e-04 - accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 0.9100\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3.0100e-04 - accuracy: 1.0000 - val_loss: 0.6401 - val_accuracy: 0.9100\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2.9621e-04 - accuracy: 1.0000 - val_loss: 0.6415 - val_accuracy: 0.9100\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2.9122e-04 - accuracy: 1.0000 - val_loss: 0.6418 - val_accuracy: 0.9100\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2.8699e-04 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.9100\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2.8349e-04 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.9100\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2.7853e-04 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.9100\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 2.7516e-04 - accuracy: 1.0000 - val_loss: 0.6470 - val_accuracy: 0.9100\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.7029e-04 - accuracy: 1.0000 - val_loss: 0.6508 - val_accuracy: 0.9100\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.6609e-04 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.9100\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.6247e-04 - accuracy: 1.0000 - val_loss: 0.6515 - val_accuracy: 0.9100\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 2.5897e-04 - accuracy: 1.0000 - val_loss: 0.6507 - val_accuracy: 0.9100\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2.5516e-04 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.9100\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2.5129e-04 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.9100\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.4805e-04 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.9100\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.4463e-04 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.9100\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2.4174e-04 - accuracy: 1.0000 - val_loss: 0.6530 - val_accuracy: 0.9100\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.3866e-04 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.9100\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.3584e-04 - accuracy: 1.0000 - val_loss: 0.6600 - val_accuracy: 0.9100\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 2.3219e-04 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.9100\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.2923e-04 - accuracy: 1.0000 - val_loss: 0.6615 - val_accuracy: 0.9100\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.2607e-04 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.9100\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.2363e-04 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.9100\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.2089e-04 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.9100\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.1812e-04 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.9100\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2.1540e-04 - accuracy: 1.0000 - val_loss: 0.6642 - val_accuracy: 0.9100\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2.1310e-04 - accuracy: 1.0000 - val_loss: 0.6653 - val_accuracy: 0.9100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6653 - accuracy: 0.9100\n",
            "Epoch 1/100\n",
            "141/141 [==============================] - 2s 6ms/step - loss: 0.9910 - accuracy: 0.6707 - val_loss: 0.4374 - val_accuracy: 0.8720\n",
            "Epoch 2/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.4809 - accuracy: 0.8484 - val_loss: 0.3732 - val_accuracy: 0.8840\n",
            "Epoch 3/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3456 - accuracy: 0.8920 - val_loss: 0.2839 - val_accuracy: 0.9080\n",
            "Epoch 4/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3211 - accuracy: 0.8984 - val_loss: 0.2884 - val_accuracy: 0.8980\n",
            "Epoch 5/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2612 - accuracy: 0.9176 - val_loss: 0.2264 - val_accuracy: 0.9300\n",
            "Epoch 6/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2314 - accuracy: 0.9282 - val_loss: 0.2074 - val_accuracy: 0.9360\n",
            "Epoch 7/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2047 - accuracy: 0.9360 - val_loss: 0.1893 - val_accuracy: 0.9300\n",
            "Epoch 8/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.1911 - accuracy: 0.9404 - val_loss: 0.1969 - val_accuracy: 0.9420\n",
            "Epoch 9/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.1628 - accuracy: 0.9511 - val_loss: 0.1959 - val_accuracy: 0.9460\n",
            "Epoch 10/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.1700 - accuracy: 0.9469 - val_loss: 0.1774 - val_accuracy: 0.9500\n",
            "Epoch 11/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.1331 - accuracy: 0.9573 - val_loss: 0.1677 - val_accuracy: 0.9460\n",
            "Epoch 12/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.1414 - accuracy: 0.9558 - val_loss: 0.2065 - val_accuracy: 0.9420\n",
            "Epoch 13/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.1548 - accuracy: 0.9556 - val_loss: 0.1742 - val_accuracy: 0.9540\n",
            "Epoch 14/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.1159 - accuracy: 0.9624 - val_loss: 0.2441 - val_accuracy: 0.9440\n",
            "Epoch 15/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.1228 - accuracy: 0.9631 - val_loss: 0.1818 - val_accuracy: 0.9520\n",
            "Epoch 16/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.1002 - accuracy: 0.9680 - val_loss: 0.2202 - val_accuracy: 0.9420\n",
            "Epoch 17/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.1061 - accuracy: 0.9658 - val_loss: 0.2136 - val_accuracy: 0.9540\n",
            "Epoch 18/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9638 - val_loss: 0.1932 - val_accuracy: 0.9580\n",
            "Epoch 19/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9698 - val_loss: 0.1798 - val_accuracy: 0.9460\n",
            "Epoch 20/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0820 - accuracy: 0.9738 - val_loss: 0.2744 - val_accuracy: 0.9440\n",
            "Epoch 21/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9720 - val_loss: 0.2210 - val_accuracy: 0.9560\n",
            "Epoch 22/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0808 - accuracy: 0.9756 - val_loss: 0.2269 - val_accuracy: 0.9480\n",
            "Epoch 23/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.9769 - val_loss: 0.2377 - val_accuracy: 0.9540\n",
            "Epoch 24/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0790 - accuracy: 0.9747 - val_loss: 0.1828 - val_accuracy: 0.9560\n",
            "Epoch 25/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0685 - accuracy: 0.9767 - val_loss: 0.1695 - val_accuracy: 0.9580\n",
            "Epoch 26/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0715 - accuracy: 0.9784 - val_loss: 0.1738 - val_accuracy: 0.9580\n",
            "Epoch 27/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1597 - val_accuracy: 0.9600\n",
            "Epoch 28/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0740 - accuracy: 0.9780 - val_loss: 0.1628 - val_accuracy: 0.9640\n",
            "Epoch 29/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0636 - accuracy: 0.9796 - val_loss: 0.1730 - val_accuracy: 0.9600\n",
            "Epoch 30/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9782 - val_loss: 0.1826 - val_accuracy: 0.9620\n",
            "Epoch 31/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0724 - accuracy: 0.9822 - val_loss: 0.1811 - val_accuracy: 0.9560\n",
            "Epoch 32/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9860 - val_loss: 0.1967 - val_accuracy: 0.9620\n",
            "Epoch 33/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0685 - accuracy: 0.9791 - val_loss: 0.1926 - val_accuracy: 0.9620\n",
            "Epoch 34/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 0.1887 - val_accuracy: 0.9580\n",
            "Epoch 35/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0585 - accuracy: 0.9816 - val_loss: 0.1736 - val_accuracy: 0.9580\n",
            "Epoch 36/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0566 - accuracy: 0.9833 - val_loss: 0.1683 - val_accuracy: 0.9620\n",
            "Epoch 37/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.1772 - val_accuracy: 0.9660\n",
            "Epoch 38/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0483 - accuracy: 0.9851 - val_loss: 0.1817 - val_accuracy: 0.9620\n",
            "Epoch 39/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0545 - accuracy: 0.9842 - val_loss: 0.1781 - val_accuracy: 0.9580\n",
            "Epoch 40/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.1961 - val_accuracy: 0.9520\n",
            "Epoch 41/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 0.9820 - val_loss: 0.1904 - val_accuracy: 0.9600\n",
            "Epoch 42/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0640 - accuracy: 0.9816 - val_loss: 0.1642 - val_accuracy: 0.9600\n",
            "Epoch 43/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.1678 - val_accuracy: 0.9600\n",
            "Epoch 44/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0458 - accuracy: 0.9858 - val_loss: 0.1871 - val_accuracy: 0.9640\n",
            "Epoch 45/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0600 - accuracy: 0.9820 - val_loss: 0.1772 - val_accuracy: 0.9660\n",
            "Epoch 46/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0434 - accuracy: 0.9876 - val_loss: 0.1805 - val_accuracy: 0.9660\n",
            "Epoch 47/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0506 - accuracy: 0.9849 - val_loss: 0.1942 - val_accuracy: 0.9580\n",
            "Epoch 48/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.2057 - val_accuracy: 0.9640\n",
            "Epoch 49/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 0.1937 - val_accuracy: 0.9540\n",
            "Epoch 50/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.1634 - val_accuracy: 0.9620\n",
            "Epoch 51/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.2017 - val_accuracy: 0.9620\n",
            "Epoch 52/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.2126 - val_accuracy: 0.9520\n",
            "Epoch 53/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0283 - accuracy: 0.9891 - val_loss: 0.2624 - val_accuracy: 0.9520\n",
            "Epoch 54/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0227 - accuracy: 0.9907 - val_loss: 0.1994 - val_accuracy: 0.9580\n",
            "Epoch 55/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 0.2448 - val_accuracy: 0.9540\n",
            "Epoch 56/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0532 - accuracy: 0.9851 - val_loss: 0.2381 - val_accuracy: 0.9540\n",
            "Epoch 57/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.1881 - val_accuracy: 0.9660\n",
            "Epoch 58/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0424 - accuracy: 0.9867 - val_loss: 0.2164 - val_accuracy: 0.9620\n",
            "Epoch 59/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0414 - accuracy: 0.9896 - val_loss: 0.2144 - val_accuracy: 0.9620\n",
            "Epoch 60/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0389 - accuracy: 0.9891 - val_loss: 0.1986 - val_accuracy: 0.9580\n",
            "Epoch 61/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0275 - accuracy: 0.9931 - val_loss: 0.1897 - val_accuracy: 0.9580\n",
            "Epoch 62/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.1568 - val_accuracy: 0.9640\n",
            "Epoch 63/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.1743 - val_accuracy: 0.9640\n",
            "Epoch 64/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.1781 - val_accuracy: 0.9680\n",
            "Epoch 65/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.1840 - val_accuracy: 0.9680\n",
            "Epoch 66/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.1958 - val_accuracy: 0.9680\n",
            "Epoch 67/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 0.1679 - val_accuracy: 0.9660\n",
            "Epoch 68/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0259 - accuracy: 0.9929 - val_loss: 0.2208 - val_accuracy: 0.9640\n",
            "Epoch 69/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0404 - accuracy: 0.9878 - val_loss: 0.2015 - val_accuracy: 0.9680\n",
            "Epoch 70/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.2242 - val_accuracy: 0.9620\n",
            "Epoch 71/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 0.2194 - val_accuracy: 0.9660\n",
            "Epoch 72/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 0.2922 - val_accuracy: 0.9540\n",
            "Epoch 73/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.2352 - val_accuracy: 0.9580\n",
            "Epoch 74/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0284 - accuracy: 0.9918 - val_loss: 0.1967 - val_accuracy: 0.9620\n",
            "Epoch 75/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.1759 - val_accuracy: 0.9580\n",
            "Epoch 76/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0359 - accuracy: 0.9898 - val_loss: 0.1919 - val_accuracy: 0.9600\n",
            "Epoch 77/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 0.2353 - val_accuracy: 0.9600\n",
            "Epoch 78/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0169 - accuracy: 0.9936 - val_loss: 0.2282 - val_accuracy: 0.9580\n",
            "Epoch 79/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0306 - accuracy: 0.9909 - val_loss: 0.1928 - val_accuracy: 0.9520\n",
            "Epoch 80/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.1979 - val_accuracy: 0.9660\n",
            "Epoch 81/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.2237 - val_accuracy: 0.9640\n",
            "Epoch 82/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1983 - val_accuracy: 0.9580\n",
            "Epoch 83/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.1978 - val_accuracy: 0.9620\n",
            "Epoch 84/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.2028 - val_accuracy: 0.9540\n",
            "Epoch 85/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.2170 - val_accuracy: 0.9580\n",
            "Epoch 86/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.2008 - val_accuracy: 0.9660\n",
            "Epoch 87/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.2321 - val_accuracy: 0.9540\n",
            "Epoch 88/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.2456 - val_accuracy: 0.9540\n",
            "Epoch 89/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0368 - accuracy: 0.9902 - val_loss: 0.2205 - val_accuracy: 0.9620\n",
            "Epoch 90/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.1613 - val_accuracy: 0.9680\n",
            "Epoch 91/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0187 - accuracy: 0.9918 - val_loss: 0.2062 - val_accuracy: 0.9600\n",
            "Epoch 92/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.1885 - val_accuracy: 0.9580\n",
            "Epoch 93/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 0.2265 - val_accuracy: 0.9600\n",
            "Epoch 94/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.2374 - val_accuracy: 0.9620\n",
            "Epoch 95/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0326 - accuracy: 0.9911 - val_loss: 0.2285 - val_accuracy: 0.9680\n",
            "Epoch 96/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.2326 - val_accuracy: 0.9660\n",
            "Epoch 97/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.2219 - val_accuracy: 0.9660\n",
            "Epoch 98/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0226 - accuracy: 0.9911 - val_loss: 0.2578 - val_accuracy: 0.9600\n",
            "Epoch 99/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0218 - accuracy: 0.9924 - val_loss: 0.2428 - val_accuracy: 0.9560\n",
            "Epoch 100/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.2723 - val_accuracy: 0.9560\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.9560\n",
            "Epoch 1/100\n",
            "141/141 [==============================] - 2s 6ms/step - loss: 0.6337 - accuracy: 0.8058 - val_loss: 0.3897 - val_accuracy: 0.8720\n",
            "Epoch 2/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2395 - accuracy: 0.9247 - val_loss: 0.2476 - val_accuracy: 0.9160\n",
            "Epoch 3/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.1268 - accuracy: 0.9620 - val_loss: 0.2389 - val_accuracy: 0.9300\n",
            "Epoch 4/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0807 - accuracy: 0.9749 - val_loss: 0.2099 - val_accuracy: 0.9400\n",
            "Epoch 5/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0375 - accuracy: 0.9907 - val_loss: 0.2361 - val_accuracy: 0.9260\n",
            "Epoch 6/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.2164 - val_accuracy: 0.9400\n",
            "Epoch 7/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 0.2040 - val_accuracy: 0.9500\n",
            "Epoch 8/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9540\n",
            "Epoch 9/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9540\n",
            "Epoch 10/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9480\n",
            "Epoch 11/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 9.4530e-04 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9520\n",
            "Epoch 12/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.9929e-04 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9520\n",
            "Epoch 13/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 6.9451e-04 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9520\n",
            "Epoch 14/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 6.1149e-04 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9520\n",
            "Epoch 15/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.5434e-04 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9520\n",
            "Epoch 16/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.0019e-04 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9520\n",
            "Epoch 17/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 4.5630e-04 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9520\n",
            "Epoch 18/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 4.2250e-04 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9520\n",
            "Epoch 19/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 3.9061e-04 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9520\n",
            "Epoch 20/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 3.6343e-04 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9520\n",
            "Epoch 21/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 3.4048e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9520\n",
            "Epoch 22/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 3.2087e-04 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9520\n",
            "Epoch 23/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 3.0120e-04 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9520\n",
            "Epoch 24/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 2.8579e-04 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9520\n",
            "Epoch 25/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2.7135e-04 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9520\n",
            "Epoch 26/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2.5794e-04 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9520\n",
            "Epoch 27/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2.4571e-04 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9520\n",
            "Epoch 28/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2.3464e-04 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9520\n",
            "Epoch 29/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2.2504e-04 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9520\n",
            "Epoch 30/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 2.1525e-04 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9520\n",
            "Epoch 31/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 2.0706e-04 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9520\n",
            "Epoch 32/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.9904e-04 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9520\n",
            "Epoch 33/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.9187e-04 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9520\n",
            "Epoch 34/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.8489e-04 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9520\n",
            "Epoch 35/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.7884e-04 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9520\n",
            "Epoch 36/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.7270e-04 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9520\n",
            "Epoch 37/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.6704e-04 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9520\n",
            "Epoch 38/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.6199e-04 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9520\n",
            "Epoch 39/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.5697e-04 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9520\n",
            "Epoch 40/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.5231e-04 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9520\n",
            "Epoch 41/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.4808e-04 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9520\n",
            "Epoch 42/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.4364e-04 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9520\n",
            "Epoch 43/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1.3983e-04 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9520\n",
            "Epoch 44/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1.3634e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9520\n",
            "Epoch 45/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1.3261e-04 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9520\n",
            "Epoch 46/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1.2916e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9520\n",
            "Epoch 47/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1.2610e-04 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9520\n",
            "Epoch 48/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1.2275e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9520\n",
            "Epoch 49/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1.2004e-04 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9520\n",
            "Epoch 50/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.1729e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9520\n",
            "Epoch 51/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.1458e-04 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9520\n",
            "Epoch 52/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.1211e-04 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9520\n",
            "Epoch 53/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.0953e-04 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9520\n",
            "Epoch 54/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.0725e-04 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9520\n",
            "Epoch 55/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.0498e-04 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9520\n",
            "Epoch 56/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.0287e-04 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9520\n",
            "Epoch 57/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 1.0080e-04 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9520\n",
            "Epoch 58/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 9.8786e-05 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9520\n",
            "Epoch 59/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 9.6882e-05 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9520\n",
            "Epoch 60/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 9.5067e-05 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9520\n",
            "Epoch 61/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 9.3327e-05 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9520\n",
            "Epoch 62/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 9.1579e-05 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9520\n",
            "Epoch 63/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 8.9936e-05 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9520\n",
            "Epoch 64/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 8.8336e-05 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9520\n",
            "Epoch 65/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 8.6720e-05 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9520\n",
            "Epoch 66/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 8.5301e-05 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9520\n",
            "Epoch 67/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 8.3829e-05 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9520\n",
            "Epoch 68/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 8.2432e-05 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9520\n",
            "Epoch 69/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 8.1021e-05 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9520\n",
            "Epoch 70/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.9795e-05 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9520\n",
            "Epoch 71/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.8537e-05 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9520\n",
            "Epoch 72/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.7337e-05 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9520\n",
            "Epoch 73/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.6097e-05 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9520\n",
            "Epoch 74/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.4911e-05 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9520\n",
            "Epoch 75/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.3826e-05 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9520\n",
            "Epoch 76/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.2728e-05 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9520\n",
            "Epoch 77/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.1582e-05 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9520\n",
            "Epoch 78/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 7.0662e-05 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9520\n",
            "Epoch 79/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 6.9614e-05 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9520\n",
            "Epoch 80/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 6.8692e-05 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9520\n",
            "Epoch 81/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 6.7707e-05 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9520\n",
            "Epoch 82/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 6.6817e-05 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9520\n",
            "Epoch 83/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 6.5887e-05 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9520\n",
            "Epoch 84/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 6.5008e-05 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9520\n",
            "Epoch 85/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 6.4178e-05 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9520\n",
            "Epoch 86/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 6.3327e-05 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9520\n",
            "Epoch 87/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 6.2499e-05 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.9520\n",
            "Epoch 88/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 6.1728e-05 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9520\n",
            "Epoch 89/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 6.0944e-05 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9520\n",
            "Epoch 90/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 6.0181e-05 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9520\n",
            "Epoch 91/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.9495e-05 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9520\n",
            "Epoch 92/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.8732e-05 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9520\n",
            "Epoch 93/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.8041e-05 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9520\n",
            "Epoch 94/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.7398e-05 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9520\n",
            "Epoch 95/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.6673e-05 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9520\n",
            "Epoch 96/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.6032e-05 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9520\n",
            "Epoch 97/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.5431e-05 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9520\n",
            "Epoch 98/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.4808e-05 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9520\n",
            "Epoch 99/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.4197e-05 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9520\n",
            "Epoch 100/100\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 5.3591e-05 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9520\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.9520\n",
            "Epoch 1/100\n",
            "282/282 [==============================] - 3s 7ms/step - loss: 0.7693 - accuracy: 0.7526 - val_loss: 0.3115 - val_accuracy: 0.9150\n",
            "Epoch 2/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.3865 - accuracy: 0.8809 - val_loss: 0.2634 - val_accuracy: 0.9240\n",
            "Epoch 3/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.3115 - accuracy: 0.9024 - val_loss: 0.2385 - val_accuracy: 0.9350\n",
            "Epoch 4/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.2634 - accuracy: 0.9217 - val_loss: 0.2077 - val_accuracy: 0.9470\n",
            "Epoch 5/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.2271 - accuracy: 0.9294 - val_loss: 0.2061 - val_accuracy: 0.9460\n",
            "Epoch 6/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1983 - accuracy: 0.9373 - val_loss: 0.1854 - val_accuracy: 0.9540\n",
            "Epoch 7/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1863 - accuracy: 0.9418 - val_loss: 0.1439 - val_accuracy: 0.9610\n",
            "Epoch 8/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1690 - accuracy: 0.9480 - val_loss: 0.1742 - val_accuracy: 0.9530\n",
            "Epoch 9/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1555 - accuracy: 0.9536 - val_loss: 0.1914 - val_accuracy: 0.9570\n",
            "Epoch 10/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.1471 - accuracy: 0.9538 - val_loss: 0.1536 - val_accuracy: 0.9570\n",
            "Epoch 11/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1167 - accuracy: 0.9648 - val_loss: 0.1652 - val_accuracy: 0.9590\n",
            "Epoch 12/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1299 - accuracy: 0.9580 - val_loss: 0.1593 - val_accuracy: 0.9610\n",
            "Epoch 13/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1122 - accuracy: 0.9650 - val_loss: 0.1728 - val_accuracy: 0.9540\n",
            "Epoch 14/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9641 - val_loss: 0.1445 - val_accuracy: 0.9610\n",
            "Epoch 15/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1098 - accuracy: 0.9649 - val_loss: 0.1408 - val_accuracy: 0.9620\n",
            "Epoch 16/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1149 - accuracy: 0.9629 - val_loss: 0.1394 - val_accuracy: 0.9620\n",
            "Epoch 17/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1041 - accuracy: 0.9696 - val_loss: 0.1539 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0857 - accuracy: 0.9751 - val_loss: 0.1499 - val_accuracy: 0.9720\n",
            "Epoch 19/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.0855 - accuracy: 0.9731 - val_loss: 0.1311 - val_accuracy: 0.9710\n",
            "Epoch 20/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.0785 - accuracy: 0.9767 - val_loss: 0.1314 - val_accuracy: 0.9720\n",
            "Epoch 21/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.0914 - accuracy: 0.9732 - val_loss: 0.1743 - val_accuracy: 0.9650\n",
            "Epoch 22/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0772 - accuracy: 0.9748 - val_loss: 0.1669 - val_accuracy: 0.9640\n",
            "Epoch 23/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0821 - accuracy: 0.9741 - val_loss: 0.1492 - val_accuracy: 0.9700\n",
            "Epoch 24/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0693 - accuracy: 0.9769 - val_loss: 0.1822 - val_accuracy: 0.9640\n",
            "Epoch 25/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0714 - accuracy: 0.9770 - val_loss: 0.1907 - val_accuracy: 0.9670\n",
            "Epoch 26/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0738 - accuracy: 0.9778 - val_loss: 0.1764 - val_accuracy: 0.9640\n",
            "Epoch 27/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0731 - accuracy: 0.9762 - val_loss: 0.1552 - val_accuracy: 0.9690\n",
            "Epoch 28/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0654 - accuracy: 0.9797 - val_loss: 0.1564 - val_accuracy: 0.9680\n",
            "Epoch 29/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0604 - accuracy: 0.9802 - val_loss: 0.1577 - val_accuracy: 0.9700\n",
            "Epoch 30/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0640 - accuracy: 0.9796 - val_loss: 0.1816 - val_accuracy: 0.9710\n",
            "Epoch 31/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0641 - accuracy: 0.9802 - val_loss: 0.1429 - val_accuracy: 0.9720\n",
            "Epoch 32/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0635 - accuracy: 0.9797 - val_loss: 0.1825 - val_accuracy: 0.9670\n",
            "Epoch 33/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0757 - accuracy: 0.9764 - val_loss: 0.1425 - val_accuracy: 0.9750\n",
            "Epoch 34/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0517 - accuracy: 0.9834 - val_loss: 0.1766 - val_accuracy: 0.9690\n",
            "Epoch 35/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - accuracy: 0.9829 - val_loss: 0.1726 - val_accuracy: 0.9700\n",
            "Epoch 36/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 0.1910 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0558 - accuracy: 0.9840 - val_loss: 0.1868 - val_accuracy: 0.9690\n",
            "Epoch 38/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 0.1785 - val_accuracy: 0.9700\n",
            "Epoch 39/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.1531 - val_accuracy: 0.9720\n",
            "Epoch 40/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0395 - accuracy: 0.9868 - val_loss: 0.1804 - val_accuracy: 0.9670\n",
            "Epoch 41/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0554 - accuracy: 0.9829 - val_loss: 0.1700 - val_accuracy: 0.9690\n",
            "Epoch 42/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0460 - accuracy: 0.9863 - val_loss: 0.1617 - val_accuracy: 0.9720\n",
            "Epoch 43/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0427 - accuracy: 0.9873 - val_loss: 0.1722 - val_accuracy: 0.9680\n",
            "Epoch 44/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0423 - accuracy: 0.9873 - val_loss: 0.1838 - val_accuracy: 0.9730\n",
            "Epoch 45/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0430 - accuracy: 0.9866 - val_loss: 0.1439 - val_accuracy: 0.9710\n",
            "Epoch 46/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.1904 - val_accuracy: 0.9700\n",
            "Epoch 47/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.1509 - val_accuracy: 0.9720\n",
            "Epoch 48/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.1755 - val_accuracy: 0.9740\n",
            "Epoch 49/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.1887 - val_accuracy: 0.9670\n",
            "Epoch 50/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0350 - accuracy: 0.9874 - val_loss: 0.1656 - val_accuracy: 0.9760\n",
            "Epoch 51/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0485 - accuracy: 0.9858 - val_loss: 0.2091 - val_accuracy: 0.9720\n",
            "Epoch 52/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9873 - val_loss: 0.1462 - val_accuracy: 0.9740\n",
            "Epoch 53/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.1935 - val_accuracy: 0.9720\n",
            "Epoch 54/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.9886 - val_loss: 0.1837 - val_accuracy: 0.9690\n",
            "Epoch 55/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.1878 - val_accuracy: 0.9680\n",
            "Epoch 56/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0432 - accuracy: 0.9876 - val_loss: 0.1893 - val_accuracy: 0.9650\n",
            "Epoch 57/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.1924 - val_accuracy: 0.9750\n",
            "Epoch 58/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.0295 - accuracy: 0.9914 - val_loss: 0.1772 - val_accuracy: 0.9700\n",
            "Epoch 59/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0305 - accuracy: 0.9902 - val_loss: 0.1680 - val_accuracy: 0.9650\n",
            "Epoch 60/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0386 - accuracy: 0.9891 - val_loss: 0.1817 - val_accuracy: 0.9700\n",
            "Epoch 61/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.1507 - val_accuracy: 0.9740\n",
            "Epoch 62/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 0.1836 - val_accuracy: 0.9730\n",
            "Epoch 63/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.1616 - val_accuracy: 0.9720\n",
            "Epoch 64/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9907 - val_loss: 0.1896 - val_accuracy: 0.9710\n",
            "Epoch 65/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0260 - accuracy: 0.9922 - val_loss: 0.1719 - val_accuracy: 0.9710\n",
            "Epoch 66/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.2217 - val_accuracy: 0.9680\n",
            "Epoch 67/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.1907 - val_accuracy: 0.9700\n",
            "Epoch 68/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 0.2100 - val_accuracy: 0.9640\n",
            "Epoch 69/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.1494 - val_accuracy: 0.9760\n",
            "Epoch 70/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.1525 - val_accuracy: 0.9760\n",
            "Epoch 71/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0189 - accuracy: 0.9930 - val_loss: 0.1768 - val_accuracy: 0.9740\n",
            "Epoch 72/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.1860 - val_accuracy: 0.9740\n",
            "Epoch 73/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.1694 - val_accuracy: 0.9740\n",
            "Epoch 74/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.1846 - val_accuracy: 0.9750\n",
            "Epoch 75/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.1461 - val_accuracy: 0.9750\n",
            "Epoch 76/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0174 - accuracy: 0.9932 - val_loss: 0.2011 - val_accuracy: 0.9730\n",
            "Epoch 77/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.2155 - val_accuracy: 0.9730\n",
            "Epoch 78/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.1788 - val_accuracy: 0.9690\n",
            "Epoch 79/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.2069 - val_accuracy: 0.9690\n",
            "Epoch 80/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.2138 - val_accuracy: 0.9690\n",
            "Epoch 81/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.1869 - val_accuracy: 0.9770\n",
            "Epoch 82/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.1984 - val_accuracy: 0.9740\n",
            "Epoch 83/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.2009 - val_accuracy: 0.9710\n",
            "Epoch 84/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.1908 - val_accuracy: 0.9750\n",
            "Epoch 85/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.2078 - val_accuracy: 0.9730\n",
            "Epoch 86/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.1635 - val_accuracy: 0.9740\n",
            "Epoch 87/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.1857 - val_accuracy: 0.9730\n",
            "Epoch 88/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.2107 - val_accuracy: 0.9680\n",
            "Epoch 89/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 0.2126 - val_accuracy: 0.9720\n",
            "Epoch 90/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.2054 - val_accuracy: 0.9700\n",
            "Epoch 91/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 0.1913 - val_accuracy: 0.9660\n",
            "Epoch 92/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.2173 - val_accuracy: 0.9700\n",
            "Epoch 93/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.1989 - val_accuracy: 0.9700\n",
            "Epoch 94/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.1880 - val_accuracy: 0.9720\n",
            "Epoch 95/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.1865 - val_accuracy: 0.9730\n",
            "Epoch 96/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.2218 - val_accuracy: 0.9680\n",
            "Epoch 97/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.3722 - val_accuracy: 0.9590\n",
            "Epoch 98/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.1681 - val_accuracy: 0.9740\n",
            "Epoch 99/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.1922 - val_accuracy: 0.9700\n",
            "Epoch 100/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.1947 - val_accuracy: 0.9720\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9720\n",
            "Epoch 1/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.4930 - accuracy: 0.8478 - val_loss: 0.2993 - val_accuracy: 0.9160\n",
            "Epoch 2/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1785 - accuracy: 0.9444 - val_loss: 0.1851 - val_accuracy: 0.9410\n",
            "Epoch 3/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1096 - accuracy: 0.9669 - val_loss: 0.1626 - val_accuracy: 0.9550\n",
            "Epoch 4/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 0.1702 - val_accuracy: 0.9590\n",
            "Epoch 5/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.0337 - accuracy: 0.9907 - val_loss: 0.1601 - val_accuracy: 0.9600\n",
            "Epoch 6/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.1632 - val_accuracy: 0.9640\n",
            "Epoch 7/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.1450 - val_accuracy: 0.9660\n",
            "Epoch 8/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.1386 - val_accuracy: 0.9720\n",
            "Epoch 9/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9720\n",
            "Epoch 10/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 6.7584e-04 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9710\n",
            "Epoch 11/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 4.8652e-04 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9720\n",
            "Epoch 12/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 3.8903e-04 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9710\n",
            "Epoch 13/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 3.3149e-04 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9700\n",
            "Epoch 14/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 2.8869e-04 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9710\n",
            "Epoch 15/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 2.5459e-04 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9700\n",
            "Epoch 16/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 2.3117e-04 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9700\n",
            "Epoch 17/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 2.0998e-04 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9710\n",
            "Epoch 18/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 1.9284e-04 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9720\n",
            "Epoch 19/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 1.7800e-04 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9700\n",
            "Epoch 20/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 1.6645e-04 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9720\n",
            "Epoch 21/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 1.5533e-04 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9720\n",
            "Epoch 22/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 1.4601e-04 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9710\n",
            "Epoch 23/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 1.3758e-04 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9710\n",
            "Epoch 24/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 1.3022e-04 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9710\n",
            "Epoch 25/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 1.2385e-04 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9720\n",
            "Epoch 26/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 1.1798e-04 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9720\n",
            "Epoch 27/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 1.1247e-04 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9720\n",
            "Epoch 28/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 1.0756e-04 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9720\n",
            "Epoch 29/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 1.0309e-04 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9720\n",
            "Epoch 30/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 9.8906e-05 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9720\n",
            "Epoch 31/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 9.5063e-05 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9710\n",
            "Epoch 32/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 9.1612e-05 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9720\n",
            "Epoch 33/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 8.8355e-05 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9720\n",
            "Epoch 34/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 8.5240e-05 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9720\n",
            "Epoch 35/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 8.2355e-05 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9720\n",
            "Epoch 36/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 7.9793e-05 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9720\n",
            "Epoch 37/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 7.7279e-05 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9720\n",
            "Epoch 38/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 7.4992e-05 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9720\n",
            "Epoch 39/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 7.2817e-05 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 0.9720\n",
            "Epoch 40/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 7.0718e-05 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9720\n",
            "Epoch 41/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 6.8727e-05 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9720\n",
            "Epoch 42/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 6.6951e-05 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9720\n",
            "Epoch 43/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 6.5217e-05 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9710\n",
            "Epoch 44/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 6.3544e-05 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9720\n",
            "Epoch 45/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 6.1959e-05 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9710\n",
            "Epoch 46/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 6.0474e-05 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9720\n",
            "Epoch 47/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 5.9070e-05 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9710\n",
            "Epoch 48/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 5.7722e-05 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9710\n",
            "Epoch 49/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 5.6391e-05 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9710\n",
            "Epoch 50/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 5.5177e-05 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9710\n",
            "Epoch 51/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 5.3984e-05 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9710\n",
            "Epoch 52/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 5.2858e-05 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9710\n",
            "Epoch 53/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 5.1781e-05 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9710\n",
            "Epoch 54/100\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 5.0730e-05 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9710\n",
            "Epoch 55/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 4.9766e-05 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9710\n",
            "Epoch 56/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 4.8769e-05 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9710\n",
            "Epoch 57/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 4.7850e-05 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9710\n",
            "Epoch 58/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 4.6975e-05 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9710\n",
            "Epoch 59/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 4.6124e-05 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9710\n",
            "Epoch 60/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 4.5266e-05 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9710\n",
            "Epoch 61/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 4.4496e-05 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9710\n",
            "Epoch 62/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 4.3703e-05 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9710\n",
            "Epoch 63/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 4.2985e-05 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9710\n",
            "Epoch 64/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 4.2281e-05 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9710\n",
            "Epoch 65/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 4.1576e-05 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9710\n",
            "Epoch 66/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 4.0889e-05 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9710\n",
            "Epoch 67/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 4.0243e-05 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9710\n",
            "Epoch 68/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.9628e-05 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9710\n",
            "Epoch 69/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.9038e-05 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9710\n",
            "Epoch 70/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.8442e-05 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9710\n",
            "Epoch 71/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.7872e-05 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9710\n",
            "Epoch 72/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 3.7320e-05 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9710\n",
            "Epoch 73/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 3.6778e-05 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9710\n",
            "Epoch 74/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 3.6260e-05 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9710\n",
            "Epoch 75/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 3.5749e-05 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9710\n",
            "Epoch 76/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.5264e-05 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9710\n",
            "Epoch 77/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.4775e-05 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9710\n",
            "Epoch 78/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.4327e-05 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9710\n",
            "Epoch 79/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 3.3859e-05 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9710\n",
            "Epoch 80/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.3441e-05 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9710\n",
            "Epoch 81/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.3005e-05 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9710\n",
            "Epoch 82/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 3.2586e-05 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9710\n",
            "Epoch 83/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 3.2175e-05 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9710\n",
            "Epoch 84/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 3.1785e-05 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9710\n",
            "Epoch 85/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 3.1396e-05 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9710\n",
            "Epoch 86/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 3.1013e-05 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9710\n",
            "Epoch 87/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 3.0648e-05 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9710\n",
            "Epoch 88/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 3.0287e-05 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9710\n",
            "Epoch 89/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 2.9937e-05 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9710\n",
            "Epoch 90/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 2.9599e-05 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9710\n",
            "Epoch 91/100\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 2.9266e-05 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9710\n",
            "Epoch 92/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 2.8944e-05 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9710\n",
            "Epoch 93/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 2.8622e-05 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9710\n",
            "Epoch 94/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 2.8315e-05 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9710\n",
            "Epoch 95/100\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 2.8008e-05 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9710\n",
            "Epoch 96/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 2.7720e-05 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9710\n",
            "Epoch 97/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 2.7423e-05 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9710\n",
            "Epoch 98/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 2.7140e-05 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9710\n",
            "Epoch 99/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 2.6860e-05 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9710\n",
            "Epoch 100/100\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 2.6587e-05 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9710\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1871 - accuracy: 0.9710\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.4487 - accuracy: 0.8595 - val_loss: 0.1747 - val_accuracy: 0.9482\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2407 - accuracy: 0.9300 - val_loss: 0.1365 - val_accuracy: 0.9594\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1921 - accuracy: 0.9439 - val_loss: 0.1216 - val_accuracy: 0.9642\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1653 - accuracy: 0.9509 - val_loss: 0.1088 - val_accuracy: 0.9668\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1497 - accuracy: 0.9554 - val_loss: 0.1574 - val_accuracy: 0.9508\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.1373 - accuracy: 0.9578 - val_loss: 0.0976 - val_accuracy: 0.9722\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1199 - accuracy: 0.9650 - val_loss: 0.0916 - val_accuracy: 0.9752\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.1160 - accuracy: 0.9657 - val_loss: 0.0863 - val_accuracy: 0.9738\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1075 - accuracy: 0.9680 - val_loss: 0.0779 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0973 - accuracy: 0.9702 - val_loss: 0.0789 - val_accuracy: 0.9778\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0948 - accuracy: 0.9714 - val_loss: 0.0837 - val_accuracy: 0.9762\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0909 - accuracy: 0.9714 - val_loss: 0.0861 - val_accuracy: 0.9776\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0853 - accuracy: 0.9729 - val_loss: 0.0779 - val_accuracy: 0.9776\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0855 - accuracy: 0.9744 - val_loss: 0.0781 - val_accuracy: 0.9780\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0806 - accuracy: 0.9747 - val_loss: 0.0742 - val_accuracy: 0.9810\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0711 - accuracy: 0.9787 - val_loss: 0.0757 - val_accuracy: 0.9796\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0708 - accuracy: 0.9790 - val_loss: 0.0692 - val_accuracy: 0.9816\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0663 - accuracy: 0.9797 - val_loss: 0.0684 - val_accuracy: 0.9822\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0641 - accuracy: 0.9802 - val_loss: 0.0710 - val_accuracy: 0.9808\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0620 - accuracy: 0.9813 - val_loss: 0.0703 - val_accuracy: 0.9788\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0608 - accuracy: 0.9804 - val_loss: 0.0652 - val_accuracy: 0.9836\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.0726 - val_accuracy: 0.9816\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0567 - accuracy: 0.9825 - val_loss: 0.0714 - val_accuracy: 0.9818\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0560 - accuracy: 0.9830 - val_loss: 0.0697 - val_accuracy: 0.9826\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.0621 - val_accuracy: 0.9824\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0485 - accuracy: 0.9845 - val_loss: 0.0697 - val_accuracy: 0.9812\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0457 - accuracy: 0.9862 - val_loss: 0.0659 - val_accuracy: 0.9818\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.0669 - val_accuracy: 0.9816\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.0742 - val_accuracy: 0.9816\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.0750 - val_accuracy: 0.9806\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0435 - accuracy: 0.9865 - val_loss: 0.0703 - val_accuracy: 0.9826\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0444 - accuracy: 0.9860 - val_loss: 0.0684 - val_accuracy: 0.9828\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.0667 - val_accuracy: 0.9832\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0684 - val_accuracy: 0.9826\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0406 - accuracy: 0.9866 - val_loss: 0.0763 - val_accuracy: 0.9820\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0377 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9826\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.0704 - val_accuracy: 0.9826\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.0697 - val_accuracy: 0.9814\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.0721 - val_accuracy: 0.9832\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 0.0689 - val_accuracy: 0.9828\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0339 - accuracy: 0.9891 - val_loss: 0.0659 - val_accuracy: 0.9838\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0344 - accuracy: 0.9889 - val_loss: 0.0723 - val_accuracy: 0.9814\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0282 - accuracy: 0.9902 - val_loss: 0.0659 - val_accuracy: 0.9836\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.0729 - val_accuracy: 0.9824\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 0.0770 - val_accuracy: 0.9844\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.0708 - val_accuracy: 0.9830\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.0753 - val_accuracy: 0.9812\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.0724 - val_accuracy: 0.9824\n",
            "Epoch 49/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.0647 - val_accuracy: 0.9854\n",
            "Epoch 50/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0689 - val_accuracy: 0.9836\n",
            "Epoch 51/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0698 - val_accuracy: 0.9842\n",
            "Epoch 52/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0257 - accuracy: 0.9917 - val_loss: 0.0671 - val_accuracy: 0.9830\n",
            "Epoch 53/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.0722 - val_accuracy: 0.9830\n",
            "Epoch 54/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.0688 - val_accuracy: 0.9838\n",
            "Epoch 55/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0778 - val_accuracy: 0.9832\n",
            "Epoch 56/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0691 - val_accuracy: 0.9836\n",
            "Epoch 57/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0688 - val_accuracy: 0.9846\n",
            "Epoch 58/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0757 - val_accuracy: 0.9824\n",
            "Epoch 59/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.0649 - val_accuracy: 0.9846\n",
            "Epoch 60/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.0748 - val_accuracy: 0.9832\n",
            "Epoch 61/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0663 - val_accuracy: 0.9836\n",
            "Epoch 62/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0724 - val_accuracy: 0.9840\n",
            "Epoch 63/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0731 - val_accuracy: 0.9832\n",
            "Epoch 64/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.0726 - val_accuracy: 0.9840\n",
            "Epoch 65/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0653 - val_accuracy: 0.9832\n",
            "Epoch 66/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0644 - val_accuracy: 0.9846\n",
            "Epoch 67/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.0706 - val_accuracy: 0.9834\n",
            "Epoch 68/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.0674 - val_accuracy: 0.9836\n",
            "Epoch 69/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.0661 - val_accuracy: 0.9858\n",
            "Epoch 70/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.0704 - val_accuracy: 0.9850\n",
            "Epoch 71/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0746 - val_accuracy: 0.9846\n",
            "Epoch 72/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.0706 - val_accuracy: 0.9844\n",
            "Epoch 73/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0693 - val_accuracy: 0.9832\n",
            "Epoch 74/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0712 - val_accuracy: 0.9832\n",
            "Epoch 75/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0732 - val_accuracy: 0.9844\n",
            "Epoch 76/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.0729 - val_accuracy: 0.9850\n",
            "Epoch 77/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0774 - val_accuracy: 0.9836\n",
            "Epoch 78/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.0732 - val_accuracy: 0.9842\n",
            "Epoch 79/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0717 - val_accuracy: 0.9852\n",
            "Epoch 80/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0691 - val_accuracy: 0.9860\n",
            "Epoch 81/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.0706 - val_accuracy: 0.9846\n",
            "Epoch 82/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0672 - val_accuracy: 0.9856\n",
            "Epoch 83/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0711 - val_accuracy: 0.9848\n",
            "Epoch 84/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0685 - val_accuracy: 0.9864\n",
            "Epoch 85/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0699 - val_accuracy: 0.9852\n",
            "Epoch 86/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.0750 - val_accuracy: 0.9842\n",
            "Epoch 87/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0721 - val_accuracy: 0.9848\n",
            "Epoch 88/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.0727 - val_accuracy: 0.9832\n",
            "Epoch 89/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0674 - val_accuracy: 0.9852\n",
            "Epoch 90/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0654 - val_accuracy: 0.9860\n",
            "Epoch 91/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0795 - val_accuracy: 0.9838\n",
            "Epoch 92/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0788 - val_accuracy: 0.9846\n",
            "Epoch 93/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0763 - val_accuracy: 0.9842\n",
            "Epoch 94/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0730 - val_accuracy: 0.9856\n",
            "Epoch 95/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0775 - val_accuracy: 0.9856\n",
            "Epoch 96/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0660 - val_accuracy: 0.9862\n",
            "Epoch 97/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0700 - val_accuracy: 0.9856\n",
            "Epoch 98/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0740 - val_accuracy: 0.9850\n",
            "Epoch 99/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0735 - val_accuracy: 0.9844\n",
            "Epoch 100/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0716 - val_accuracy: 0.9848\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.0716 - accuracy: 0.9848\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2388 - accuracy: 0.9266 - val_loss: 0.1328 - val_accuracy: 0.9614\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0909 - accuracy: 0.9722 - val_loss: 0.1107 - val_accuracy: 0.9646\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0578 - accuracy: 0.9820 - val_loss: 0.1086 - val_accuracy: 0.9686\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0380 - accuracy: 0.9883 - val_loss: 0.0956 - val_accuracy: 0.9718\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0970 - val_accuracy: 0.9740\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.0920 - val_accuracy: 0.9778\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.0852 - val_accuracy: 0.9798\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.1028 - val_accuracy: 0.9772\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0921 - val_accuracy: 0.9812\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0909 - val_accuracy: 0.9820\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 9.4467e-04 - accuracy: 0.9998 - val_loss: 0.0899 - val_accuracy: 0.9822\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 6.2093e-04 - accuracy: 0.9999 - val_loss: 0.1081 - val_accuracy: 0.9798\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0894 - val_accuracy: 0.9822\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7755e-04 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9838\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6935e-04 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9830\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0550e-04 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9828\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 6.3500e-05 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9830\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 5.2371e-05 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9832\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 4.6173e-05 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9832\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 4.1716e-05 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9832\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 3.8210e-05 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9836\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 3.5306e-05 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9834\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 3.2893e-05 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9834\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 3.0913e-05 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9834\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 2.9105e-05 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9834\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 2.7554e-05 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9834\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 2.6207e-05 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9834\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 2.4977e-05 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9834\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3856e-05 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9834\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 2.2885e-05 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9834\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 2.1963e-05 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9834\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 2.1155e-05 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9834\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 2.0375e-05 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9836\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9669e-05 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9836\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9036e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9838\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8447e-05 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9836\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7881e-05 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9838\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7378e-05 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9838\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6884e-05 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9838\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6438e-05 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9838\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6017e-05 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9838\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5617e-05 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9838\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5233e-05 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9838\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4888e-05 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9840\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4549e-05 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9842\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4232e-05 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9840\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3939e-05 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9840\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3650e-05 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9842\n",
            "Epoch 49/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3381e-05 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9842\n",
            "Epoch 50/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3119e-05 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9842\n",
            "Epoch 51/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2870e-05 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9842\n",
            "Epoch 52/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2643e-05 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9842\n",
            "Epoch 53/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2422e-05 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9842\n",
            "Epoch 54/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2207e-05 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9842\n",
            "Epoch 55/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1999e-05 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9842\n",
            "Epoch 56/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1807e-05 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9842\n",
            "Epoch 57/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1617e-05 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 0.9842\n",
            "Epoch 58/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1439e-05 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9842\n",
            "Epoch 59/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1265e-05 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9842\n",
            "Epoch 60/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1100e-05 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9842\n",
            "Epoch 61/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0941e-05 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9842\n",
            "Epoch 62/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0789e-05 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9842\n",
            "Epoch 63/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0639e-05 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9842\n",
            "Epoch 64/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0498e-05 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9842\n",
            "Epoch 65/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0359e-05 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9842\n",
            "Epoch 66/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0229e-05 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9842\n",
            "Epoch 67/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0101e-05 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9842\n",
            "Epoch 68/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 9.9756e-06 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9842\n",
            "Epoch 69/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 9.8595e-06 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9842\n",
            "Epoch 70/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 9.7433e-06 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9840\n",
            "Epoch 71/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 9.6322e-06 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9840\n",
            "Epoch 72/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 9.5221e-06 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9840\n",
            "Epoch 73/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 9.4199e-06 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9840\n",
            "Epoch 74/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 9.3184e-06 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9840\n",
            "Epoch 75/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 9.2201e-06 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9840\n",
            "Epoch 76/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 9.1255e-06 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9840\n",
            "Epoch 77/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 9.0323e-06 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9840\n",
            "Epoch 78/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 8.9429e-06 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9840\n",
            "Epoch 79/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 8.8557e-06 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9840\n",
            "Epoch 80/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 8.7717e-06 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9840\n",
            "Epoch 81/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 8.6894e-06 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9840\n",
            "Epoch 82/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 8.6091e-06 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9840\n",
            "Epoch 83/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 8.5303e-06 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9840\n",
            "Epoch 84/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 8.4557e-06 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9842\n",
            "Epoch 85/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 8.3825e-06 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9842\n",
            "Epoch 86/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 8.3110e-06 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9842\n",
            "Epoch 87/100\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 8.2409e-06 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9842\n",
            "Epoch 88/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 8.1734e-06 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9842\n",
            "Epoch 89/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 8.1070e-06 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9842\n",
            "Epoch 90/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 8.0427e-06 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9842\n",
            "Epoch 91/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 7.9784e-06 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9842\n",
            "Epoch 92/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 7.9189e-06 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9842\n",
            "Epoch 93/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 7.8589e-06 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9842\n",
            "Epoch 94/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 7.7999e-06 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9842\n",
            "Epoch 95/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 7.7440e-06 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9842\n",
            "Epoch 96/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 7.6882e-06 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9842\n",
            "Epoch 97/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 7.6338e-06 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9842\n",
            "Epoch 98/100\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 7.5807e-06 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9842\n",
            "Epoch 99/100\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 7.5293e-06 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9842\n",
            "Epoch 100/100\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 7.4789e-06 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9842\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.1104 - accuracy: 0.9842\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}